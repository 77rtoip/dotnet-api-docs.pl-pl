<Type Name="PromptBuilder" FullName="System.Speech.Synthesis.PromptBuilder">
  <Metadata><Meta Name="ms.openlocfilehash" Value="4e9d96985ede8bb133a6bcfbe2ace5a338e201e7" /><Meta Name="ms.sourcegitcommit" Value="756d085f27705e86604f1bba5f2086ee23761acf" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="pl-PL" /><Meta Name="ms.lasthandoff" Value="01/30/2019" /><Meta Name="ms.locfileid" Value="55383890" /></Metadata><TypeSignature Language="C#" Value="public class PromptBuilder" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit PromptBuilder extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Synthesis.PromptBuilder" />
  <TypeSignature Language="VB.NET" Value="Public Class PromptBuilder" />
  <TypeSignature Language="C++ CLI" Value="public ref class PromptBuilder" />
  <TypeSignature Language="F#" Value="type PromptBuilder = class" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute>
      <AttributeName>System.Serializable</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Tworzy pustą <see cref="T:System.Speech.Synthesis.Prompt" /> obiektu i zawiera metody służące do dodawania zawartości, wybierając głosów, kontrolowania atrybuty głosu i kontrolowanie Wymowa wypowiadanych słów.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Za pomocą <xref:System.Speech.Synthesis.PromptBuilder>, Dodaj różne typy zawartości do wiersza, w tym zwykłego tekstu, SSML znaczników (jako ciąg lub pliku), rejestrowane audio, lub nawet inny <xref:System.Speech.Synthesis.PromptBuilder> obiektu.  
  
 Aby dołączyć tekst do <xref:System.Speech.Synthesis.PromptBuilder> obiekt oraz opcjonalnie kontrolować głosu atrybutów, takich jak wyróżnienia, szybkości i wolumin, użyj jednej z <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> metody.  Można również sterować atrybuty głosu jako grupa o <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> i <xref:System.Speech.Synthesis.PromptBuilder.EndStyle%2A> metody.  
  
 Możesz dołączyć tekst i kontrolować wypowiadanych lub, w jaki sposób są wymawiane, za pomocą <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithAlias%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithPronunciation%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A>, lub <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> metody.  
  
 Zmień obecnie wybranego głosu wypowiedzi w wierszu polecenia przy użyciu jednej z przeciążonych <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> metod, nazwy określonego głosu do użycia lub określenie wymagane właściwości głosowych, takich jak wieku oraz płci.  
  
 Na potrzeby generowania mowy z <xref:System.Speech.Synthesis.PromptBuilder> obiektu przekazywanej jako argument do <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> metody.  
  
 Aby uzyskać więcej informacji, zobacz [konstruowania złożonych monitu](https://docs.microsoft.com/previous-versions/office/developer/speech-technologies/hh361616(v%3doffice.14)).  
  
 ]]></format>
    </remarks>
  </Docs>
  <Members>
    <MemberGroup MemberName=".ctor">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Tworzy nowe wystąpienie klasy <see cref="T:System.Speech.Synthesis.PromptBuilder" /> klasy.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public PromptBuilder ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; PromptBuilder();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>Tworzy nowe wystąpienie klasy <see cref="T:System.Speech.Synthesis.PromptBuilder" /> klasy.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Poniższy przykład tworzy nowy <xref:System.Speech.Synthesis.PromptBuilder> wystąpieniu oraz dodaje ciąg tekstowy do niego.  
  
```csharp  
using System.Speech.Synthesis;  
  
public void MySimpleText ()  
{  
    PromptBuilder builder = new PromptBuilder ();  
    builder.AppendText("Hello world!");  
}  
```  
  
 Następujący kod Pokazuje odpowiednik w mowy syntezy Markup Language (SSML), (`xml:lang` jest wymaganego atrybutu `speak` elementu):  
  
```xml  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="en-US">  
  Hello world!  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public PromptBuilder (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.#ctor(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; PromptBuilder(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="new System.Speech.Synthesis.PromptBuilder : System.Globalization.CultureInfo -&gt; System.Speech.Synthesis.PromptBuilder" Usage="new System.Speech.Synthesis.PromptBuilder culture" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Zawiera informacje dotyczące określonej kultury, takie jak jego język, nazwa kultury, system pisma, kalendarz używany i sposób formatowania dat i sortowania ciągów.</param>
        <summary>Tworzy nowe wystąpienie klasy <see cref="T:System.Speech.Synthesis.PromptBuilder" /> klasy i określa kulturę.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ten konstruktor ustawia wartość <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> właściwości. <xref:System.Speech.Synthesis.SpeechSynthesizer> Obiektu będzie podejmować próby Wybierz zainstalowany głos, obsługujący język określony przez `culture` parametru do przetwarzania w wierszu polecenia. Jeśli zostanie znaleziony głosu przy użyciu określonej kultury, będzie on używany. Jeśli nie można odnaleźć głosu przy użyciu określonej kultury, głos domyślny będą używane.  
  
 Poprawnie Wymowa słów w języku określonym przez `culture` parametru, aparat syntezy (zamiana tekstu na mowę lub TTS) mowy, który obsługuje język musi być zainstalowany. Zainstalowane aparatu TTS nosi nazwę głosu. Aby uzyskać informacje o tym, które są zainstalowane głosów dla określonej kultury, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metody.  
  
 Program Microsoft Windows i interfejsu API System.Speech Zaakceptuj wszystkie prawidłowe kody krajów języka jako wartości dla `culture`. Aparaty TTS, które są dostarczane z programem Windows 7 obsługują następujące kody krajów języka:  
  
-   en-US. Angielski (Stany Zjednoczone)  
  
-   zh-CN. Chiński (Chiny)  
  
-   zh-TW. Chiński (Tajwan)  
  
 Kody dwuliterowych języków, takich jak "en", również są dozwolone.  
  
   
  
## Examples  
 Tworzy w poniższym przykładzie <xref:System.Speech.Synthesis.PromptBuilder> wystąpienia i określa jej <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A>.  
  
```csharp  
using System.Speech.Synthesis;  
  
public void MySimpleText ()  
{  
    PromptBuilder builder = new PromptBuilder(new System.Globalization.CultureInfo("en-US"));  
    builder.AppendText("Hello world!");  
}  
```  
  
 Następujący kod przedstawia równoważne SSML:  
  
```xml  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="en-US">  
  Hello world!  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendAudio">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Dołącza określony plik dźwiękowy do <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendAudio">
      <MemberSignature Language="C#" Value="public void AppendAudio (string path);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendAudio(string path) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendAudio(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendAudio (path As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendAudio(System::String ^ path);" />
      <MemberSignature Language="F#" Value="member this.AppendAudio : string -&gt; unit" Usage="promptBuilder.AppendAudio path" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="path" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="path">W pełni kwalifikowana ścieżka do pliku audio.</param>
        <summary>Dołącza określony plik dźwiękowy do <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendAudio">
      <MemberSignature Language="C#" Value="public void AppendAudio (Uri audioFile);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendAudio(class System.Uri audioFile) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendAudio(System.Uri)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendAudio (audioFile As Uri)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendAudio(Uri ^ audioFile);" />
      <MemberSignature Language="F#" Value="member this.AppendAudio : Uri -&gt; unit" Usage="promptBuilder.AppendAudio audioFile" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audioFile" Type="System.Uri" />
      </Parameters>
      <Docs>
        <param name="audioFile">Identyfikator URI dla pliku audio.</param>
        <summary>Dołącza plik dźwiękowy na określony identyfikator URI do <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Poniższy przykład inicjuje nowe wystąpienie klasy <xref:System.Speech.Synthesis.PromptBuilder> klasy, a następnie dodaje tekst do niego, a następnie plik audio.  
  
```csharp  
using System.Speech.PromptBuilder;  
  
public void SimpleConcatenation()  
{  
    // Add a prompt fragment from a .wav file.  
    PromptBuilder builder = new PromptBuilder ();  
    builder.AppendText("How are you today?");  
    builder.AppendAudio(new Uri ("http://www.speech.microsoft.com/ding.wav"));  
}  
```  
  
 Następujący kod przedstawia równoważne znaczników SSML.  
  
```xml  
<speak xmlns="http://www.w3.org/2001/10/synthesis"  
       xmlns:ms="http://www.microsoft.com/speech/synthesis" xml:lang="en">  
  
  How are you today?  
  <audio src="http://www.speech.microsoft.com/ding.wav" />  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendAudio">
      <MemberSignature Language="C#" Value="public void AppendAudio (Uri audioFile, string alternateText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendAudio(class System.Uri audioFile, string alternateText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendAudio(System.Uri,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendAudio (audioFile As Uri, alternateText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendAudio(Uri ^ audioFile, System::String ^ alternateText);" />
      <MemberSignature Language="F#" Value="member this.AppendAudio : Uri * string -&gt; unit" Usage="promptBuilder.AppendAudio (audioFile, alternateText)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audioFile" Type="System.Uri" />
        <Parameter Name="alternateText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="audioFile">Identyfikator URI dla pliku audio.</param>
        <param name="alternateText">Ciąg zawierający tekst zastępczy reprezentujący audio.</param>
        <summary>Dołącza określony plik audio i tekst alternatywny do <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aparat synteza mowy będzie odtwarzać tekst alternatywny, jeśli nie można odtworzyć plik audio.  
  
   
  
## Examples  
 Poniższy przykład dodaje plik dźwiękowy do <xref:System.Speech.Synthesis.PromptBuilder> wystąpienia i określa tekst mówić, jeśli nie można odtworzyć plik audio.  
  
```csharp  
using System.Speech.PromptBuilder;  
  
public void SimpleConcatenation()  
{  
  
    // Concatenate a prompt fragment from a .wav file.  
    PromptBuilder builder = new PromptBuilder ();  
    builder.AppendAudio(new Uri ("C:\\OnHold.wav"), "Your call will be answered in the order it was received");  
}  
```  
  
 Następujący kod przedstawia równoważne znaczników SSML.  
  
```xml  
<speak xmlns="http://www.w3.org/2001/10/synthesis"  
       xmlns:ms="http://www.microsoft.com/speech/synthesis" xml:lang="en">  
  
  <audio src="C:\OnHold.wav"> Your call will be answered in the order it was received. </audio>  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendBookmark">
      <MemberSignature Language="C#" Value="public void AppendBookmark (string bookmarkName);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBookmark(string bookmarkName) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBookmark(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBookmark (bookmarkName As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBookmark(System::String ^ bookmarkName);" />
      <MemberSignature Language="F#" Value="member this.AppendBookmark : string -&gt; unit" Usage="promptBuilder.AppendBookmark bookmarkName" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="bookmarkName" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="bookmarkName">Ciąg zawierający nazwę dołączonych zakładki.</param>
        <summary>Dołącza zakładkę do <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Generuje aparatu synteza mowy <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached> zdarzeń, jeśli wykryje nieważną ust monit przy użyciu dowolnej z zakładki <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A>, lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> metody.  
  
   
  
## Examples  
 Poniższy przykład tworzy wiersza, która zawiera dwa zakładek i wysyła dane wyjściowe do pliku do odtwarzania WAV. Obsługa <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached> zdarzeń zapisuje nazwy zakładki i położenia w strumienia audio, gdy zdarzenia zostało podniesione do konsoli.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\weather.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\weather.wav");  
  
        // Build a prompt and append bookmarks.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "The weather forecast for today is partly cloudy with some sun breaks.");  
        builder.AppendBookmark("Daytime forecast");  
        builder.AppendText(  
          "Tonight's weather will be cloudy with a 30% chance of showers.");  
        builder.AppendBookmark("Nightime forecast");  
  
        // Add a handler for the BookmarkReached event.  
        synth.BookmarkReached +=  
          new EventHandler<BookmarkReachedEventArgs>(synth_BookmarkReached);  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Write the name and position of the bookmark to the console.  
    static void synth_BookmarkReached(object sender, BookmarkReachedEventArgs e)  
    {  
      Console.WriteLine("Bookmark ({0}) reached at: {1} ",  
        e.Bookmark, e.AudioPosition);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendBreak">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Wstawia podział (Wstrzymaj) w treści <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendBreak">
      <MemberSignature Language="C#" Value="public void AppendBreak ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBreak() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBreak" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBreak ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBreak();" />
      <MemberSignature Language="F#" Value="member this.AppendBreak : unit -&gt; unit" Usage="promptBuilder.AppendBreak " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Dołącza break, aby <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ta metoda nie określa czas trwania przerwy. <xref:System.Speech.Synthesis.SpeechSynthesizer> Określi, że wartość czasu trwania na podstawie kontekstu językowego.  
  
   
  
## Examples  
 Poniższy przykład tworzy wiersz zawierający dwa zdania rozdzielonych przez podziały i mówi po wyświetleniu monitu domyślne urządzenie audio na komputerze.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Build a prompt with two sentences separated by a break.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 8:45.");  
        builder.AppendBreak();  
        builder.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:30, and 9:15.");  
  
        // Speak the prompt.  
        synth.Speak(builder);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendBreak">
      <MemberSignature Language="C#" Value="public void AppendBreak (System.Speech.Synthesis.PromptBreak strength);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBreak(valuetype System.Speech.Synthesis.PromptBreak strength) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBreak(System.Speech.Synthesis.PromptBreak)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBreak (strength As PromptBreak)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBreak(System::Speech::Synthesis::PromptBreak strength);" />
      <MemberSignature Language="F#" Value="member this.AppendBreak : System.Speech.Synthesis.PromptBreak -&gt; unit" Usage="promptBuilder.AppendBreak strength" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="strength" Type="System.Speech.Synthesis.PromptBreak" />
      </Parameters>
      <Docs>
        <param name="strength">Wskazuje czas trwania przerwy, z następującymi wartościami zwiększa:</param>
        <summary>Dołącza break, aby <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu oraz określa jego siły (czas trwania).</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Wartości w <xref:System.Speech.Synthesis.PromptBreak> wyliczenie reprezentują szeroką gamę separacji interwałów (wstrzymuje się) między granicami programu word. Aparat synteza mowy określa dokładny czas trwania interwału. Jeśli wymagane są podziału, jedną z następujących wartości są przekazywane do aparatu zamiany tekstu na mowę (TTS), który zawiera mapowania między te wartości i odpowiadające im wartości podziału milisekundach.  
  
   
  
## Examples  
 Poniższy przykład tworzy wiersz zawierający dwa zdania rozdzielonych przez podziały i wysyła dane wyjściowe do pliku WAV do odtwarzania.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\weather.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\weather.wav");  
  
        // Build a prompt with two sentences separated by a break.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 8:45");  
        builder.AppendBreak(PromptBreak.Medium);  
        builder.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:15, and 9:15");  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendBreak">
      <MemberSignature Language="C#" Value="public void AppendBreak (TimeSpan duration);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBreak(valuetype System.TimeSpan duration) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBreak(System.TimeSpan)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBreak (duration As TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBreak(TimeSpan duration);" />
      <MemberSignature Language="F#" Value="member this.AppendBreak : TimeSpan -&gt; unit" Usage="promptBuilder.AppendBreak duration" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="duration" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="duration">Czas w dziesięciomilionowych częściach sekundy, gdzie jeden znaczników jest równa 100 nanosekund.</param>
        <summary>Dołącza podziału przez określony czas na <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Podział może służyć do kontrolowania, wstrzymuje lub innych akcent granice między wyrazami. Podział jest opcjonalne. Jeśli nie ma podziału, Syntezator określa przerwy między wyrazami, w zależności od kontekstu językowego.  
  
   
  
## Examples  
 Poniższy przykład tworzy wiersz zawierający dwa zdania rozdzielonych przez podziały taktów 15000000 (1,5 s), a wybór wiersza do domyślnego urządzenia audio na komputerze.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Build a prompt with two sentences separated by a break.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 8:45");  
        builder.AppendBreak(new TimeSpan(15000000));  
        builder.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:15, and 9:15");  
  
        // Speak the prompt.  
        synth.Speak(builder);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendPromptBuilder">
      <MemberSignature Language="C#" Value="public void AppendPromptBuilder (System.Speech.Synthesis.PromptBuilder promptBuilder);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendPromptBuilder(class System.Speech.Synthesis.PromptBuilder promptBuilder) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendPromptBuilder(System.Speech.Synthesis.PromptBuilder)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendPromptBuilder(System::Speech::Synthesis::PromptBuilder ^ promptBuilder);" />
      <MemberSignature Language="F#" Value="member this.AppendPromptBuilder : System.Speech.Synthesis.PromptBuilder -&gt; unit" Usage="promptBuilder.AppendPromptBuilder promptBuilder" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="promptBuilder" Type="System.Speech.Synthesis.PromptBuilder" />
      </Parameters>
      <Docs>
        <param name="promptBuilder">Zawartość do dołączenia.</param>
        <summary>Dołącza <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu do drugiego <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 W poniższym przykładzie tworzy dwa <xref:System.Speech.Synthesis.PromptBuilder> wystąpień i dołącza je do innego <xref:System.Speech.Synthesis.PromptBuilder>.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\showtimes.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\showtimes.wav");  
  
        // Build child prompts.  
        PromptBuilder theatreA = new PromptBuilder();  
        theatreA.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 9:30");  
        theatreA.AppendBreak(PromptBreak.Large);  
        PromptBuilder theatreB = new PromptBuilder();  
        theatreB.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:15, and 9:15");  
  
        // Build the parent prompt and append the two child prompts.  
        PromptBuilder showTimes = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        showTimes.AppendText(  
          "The following are the show times for tonight's movies:");  
        showTimes.AppendPromptBuilder(theatreA);  
        showTimes.AppendPromptBuilder(theatreB);  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(showTimes);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendSsml">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Dołącza plik SSML do <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendSsml">
      <MemberSignature Language="C#" Value="public void AppendSsml (string path);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsml(string path) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsml(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsml (path As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsml(System::String ^ path);" />
      <MemberSignature Language="F#" Value="member this.AppendSsml : string -&gt; unit" Usage="promptBuilder.AppendSsml path" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="path" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="path">W pełni kwalifikowana ścieżka do pliku SSML do dołączenia.</param>
        <summary>Dołącza plik SSML w określonej ścieżce na <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Plik SSML musi być plikiem formatu XML, który jest zgodny z [mowy syntezy Markup Language (SSML) w wersji 1.0](https://go.microsoft.com/fwlink/?LinkId=201763) specyfikacji.  
  
 Można także dołączyć znacznik SSML jako ciąg za pośrednictwem <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>.  
  
   
  
## Examples  
 Tworzy w poniższym przykładzie <xref:System.Speech.Synthesis.PromptBuilder> obiektu i dołącza zawartość pliku SSML przy użyciu <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A> metody.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and append a file that defines an SSML prompt.  
        PromptBuilder ssmlFile = new PromptBuilder();  
        ssmlFile.AppendSsml("c:\\test\\Weather.ssml");  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(ssmlFile);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 Poniżej znajduje się plik SSML, który odwołuje się do poprzedniego przykładu.  
  
```xml  
<?xml version="1.0" encoding="ISO-8859-1"?>  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis"  
 xml:lang="en-US">  
  
  <s> The weather forecast for today is partly cloudy with some sun breaks. </s>  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendSsml">
      <MemberSignature Language="C#" Value="public void AppendSsml (Uri ssmlFile);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsml(class System.Uri ssmlFile) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsml(System.Uri)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsml (ssmlFile As Uri)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsml(Uri ^ ssmlFile);" />
      <MemberSignature Language="F#" Value="member this.AppendSsml : Uri -&gt; unit" Usage="promptBuilder.AppendSsml ssmlFile" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="ssmlFile" Type="System.Uri" />
      </Parameters>
      <Docs>
        <param name="ssmlFile">W pełni kwalifikowany identyfikator URI pliku SSML do dołączenia.</param>
        <summary>Dołącza plik SSML na określony identyfikator URI do <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Plik SSML musi być plikiem formatu XML, który jest zgodny z [mowy syntezy Markup Language (SSML) w wersji 1.0](https://www.w3.org/TR/speech-synthesis/) specyfikacji.  
  
 Można także dołączyć znacznik SSML jako ciąg za pośrednictwem <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>.  
  
   
  
## Examples  
 Tworzy w poniższym przykładzie <xref:System.Speech.Synthesis.PromptBuilder> obiektu i dołącza zawartość pliku SSML przy użyciu <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A> metody.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and append a file that defines an SSML prompt.  
        PromptBuilder ssmlFile = new PromptBuilder();  
        ssmlFile.AppendSsml(new Uri("c:\\test\\Weather.ssml"));  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(ssmlFile);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 Poniżej znajduje się plik SSML, który odwołuje się do poprzedniego przykładu.  
  
```xml  
<?xml version="1.0" encoding="ISO-8859-1"?>  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis"  
 xml:lang="en-US">  
  
  <s> The weather forecast for today is partly cloudy with some sun breaks. </s>  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendSsml">
      <MemberSignature Language="C#" Value="public void AppendSsml (System.Xml.XmlReader ssmlFile);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsml(class System.Xml.XmlReader ssmlFile) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsml(System.Xml.XmlReader)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsml (ssmlFile As XmlReader)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsml(System::Xml::XmlReader ^ ssmlFile);" />
      <MemberSignature Language="F#" Value="member this.AppendSsml : System.Xml.XmlReader -&gt; unit" Usage="promptBuilder.AppendSsml ssmlFile" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="ssmlFile" Type="System.Xml.XmlReader" />
      </Parameters>
      <Docs>
        <param name="ssmlFile">Pełna nazwa pliku XML do dołączenia.</param>
        <summary>Dołącza <c>XMLReader</c> obiektu, który odwołuje się do SSML monit o <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Plik SSML musi być plikiem formatu XML, który jest zgodny z [mowy syntezy Markup Language (SSML) w wersji 1.0](https://www.w3.org/TR/speech-synthesis/) specyfikacji.  
  
 Można także dołączyć znacznik SSML jako ciąg za pośrednictwem <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>.  
  
   
  
## Examples  
 Poniższy przykład tworzy <xref:System.Speech.Synthesis.PromptBuilder> obiektu z <xref:System.Xml.XmlReader> obiektu, który odwołuje się do pliku zawierającego znaczników mowy syntezy Markup Language (SSML).  
  
```csharp  
using System;  
using System.Xml;  
using System.IO;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\weather.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\weather.wav");  
  
        // Create the path to the SSML file.  
        string weatherFile = Path.GetFullPath("c:\\test\\Weather.xml");  
        PromptBuilder builder = null;  
  
        // Create an XML Reader from the file, create a PromptBuilder and   
        // append the XmlReader.  
        if (File.Exists(weatherFile))  
        {  
          XmlReader reader = XmlReader.Create(weatherFile);  
          builder = new PromptBuilder();  
          builder.AppendSsml(reader);  
          reader.Close();  
        }  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendSsmlMarkup">
      <MemberSignature Language="C#" Value="public void AppendSsmlMarkup (string ssmlMarkup);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsmlMarkup(string ssmlMarkup) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsmlMarkup (ssmlMarkup As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsmlMarkup(System::String ^ ssmlMarkup);" />
      <MemberSignature Language="F#" Value="member this.AppendSsmlMarkup : string -&gt; unit" Usage="promptBuilder.AppendSsmlMarkup ssmlMarkup" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>System.ComponentModel.EditorBrowsable(System.ComponentModel.EditorBrowsableState.Advanced)</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="ssmlMarkup" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="ssmlMarkup">Ciąg zawierający SSML znaczników.</param>
        <summary>Dołącza określony ciąg zawierający SSML znaczników w celu <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Podczas dołączania SSML znaczników, należy użyć znaków ucieczki odpowiednie. Należy zauważyć, ze starszymi wersjami ukośników poprzedzających znaki cudzysłowu, otaczający wartość `interpret-as` atrybutu w następującym przykładzie:  
  
```csharp  
builder.AppendSsmlMarkup("<say-as interpret-as = \"characters\"> chair </say-as>");  
```  
  
> [!NOTE]
>  Ciąg używany jako argument do <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> nie może zawierać `speak` elementu.  
  
 Korzystając z <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> do określenia wymowy wbudowanego w `phoneme` elementu, można użyć telefony z dowolnego z następujących alfabety fonetyczny, pod warunkiem, aparat rozpoznawania mowy w bieżącym obsługuje ona:  
  
-   Międzynarodowy alfabet fonetyczny (IPA)  
  
-   Zestaw Universal Phone (UPS)  
  
-   Zestaw Phone nieokreślone  
  
 Wszystkie zgodne SSML aparatu rozpoznawania mowy będzie odtwarzać telefony z IPA.  
  
 Można także dołączyć plik zawierający znaczników SSML przy użyciu jednej z <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A> metody. Aby dołączyć wymawianie tekstu, który nie jest sformatowany w języku znaczników, użyj jednej z <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithAlias%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint%2A>, lub <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithPronunciation%2A> metody.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendText">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Dołącza tekst <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string -&gt; unit" Usage="promptBuilder.AppendText textToSpeak" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Ciąg zawierający tekst, który ma być używany.</param>
        <summary>Określa tekst do dołączenia do <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aby dołączyć tekst, który jest sformatowany jako język znaczników SSML, należy użyć <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>.  
  
   
  
## Examples  
 Tworzy w poniższym przykładzie <xref:System.Speech.Synthesis.PromptBuilder> obiektu i dołącza ciąg tekstu za pomocą <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> metody.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and append a text string.  
        PromptBuilder speakText = new PromptBuilder();  
        speakText.AppendText("Say the name of the song you want to hear");  
  
        // Speak the contents of the prompt.  
        synth.Speak(speakText);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak, System.Speech.Synthesis.PromptEmphasis emphasis);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak, valuetype System.Speech.Synthesis.PromptEmphasis emphasis) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String,System.Speech.Synthesis.PromptEmphasis)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String, emphasis As PromptEmphasis)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak, System::Speech::Synthesis::PromptEmphasis emphasis);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string * System.Speech.Synthesis.PromptEmphasis -&gt; unit" Usage="promptBuilder.AppendText (textToSpeak, emphasis)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="emphasis" Type="System.Speech.Synthesis.PromptEmphasis" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Ciąg zawierający tekst, który ma być używany.</param>
        <param name="emphasis">Wartość dla wyróżnienia lub obciążenia do zastosowania w tekście.</param>
        <summary>Dołącza tekst <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu i określa stopień wyróżnienia do tekstu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aparaty synteza mowy w Windows obsługuje parametru nacisk w tej chwili. Ustawianie wartości dla parametru wyróżnienia dadzą bez dźwiękowych zmian w danych wyjściowych syntezatora mowy.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak, System.Speech.Synthesis.PromptRate rate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak, valuetype System.Speech.Synthesis.PromptRate rate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String,System.Speech.Synthesis.PromptRate)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String, rate As PromptRate)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak, System::Speech::Synthesis::PromptRate rate);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string * System.Speech.Synthesis.PromptRate -&gt; unit" Usage="promptBuilder.AppendText (textToSpeak, rate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="rate" Type="System.Speech.Synthesis.PromptRate" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Ciąg zawierający tekst, który ma być używany.</param>
        <param name="rate">Wartość wypowiedzi stopa dyskontowa stosowana do tekstu.</param>
        <summary>Dołącza tekst <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu i określa szybkość wypowiedzi w tekście.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Poniższy przykład tworzy <xref:System.Speech.Synthesis.PromptBuilder> obiektu i dołącza ciągów tekstowych. W przykładzie użyto <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> metodę, aby określić powolne wypowiedzi szybkości dla ciągu dodawane, które wylicza zawartości zamówienia.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content.  
        PromptBuilder speakRate = new PromptBuilder();  
        speakRate.AppendText("Your order for");  
        speakRate.AppendText("one kitchen sink and one faucet", PromptRate.Slow);  
        speakRate.AppendText("has been confirmed.");  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(speakRate);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak, System.Speech.Synthesis.PromptVolume volume);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak, valuetype System.Speech.Synthesis.PromptVolume volume) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String,System.Speech.Synthesis.PromptVolume)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String, volume As PromptVolume)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak, System::Speech::Synthesis::PromptVolume volume);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string * System.Speech.Synthesis.PromptVolume -&gt; unit" Usage="promptBuilder.AppendText (textToSpeak, volume)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="volume" Type="System.Speech.Synthesis.PromptVolume" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Ciąg zawierający tekst, który ma być używany.</param>
        <param name="volume">Wartość dla woluminu wypowiedzi (parametrów akustycznych) do zastosowania w tekście.</param>
        <summary>Dołącza tekst <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu i określa woluminu, który ma mowy na tekst.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Synthesis.PromptVolume.Default> Ustawienie <xref:System.Speech.Synthesis.PromptVolume> jest pełnym woluminie, która jest taka sama jak <xref:System.Speech.Synthesis.PromptVolume.ExtraLoud>. Inne ustawienia zmniejszenie ilości mowie względem całego woluminu.  
  
   
  
## Examples  
 W poniższym przykładzie użyto <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> metodę, aby określić ustawienia woluminu, <xref:System.Speech.Synthesis.SpeechSynthesizer> dotyczą mowie.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Build a prompt that applies different volume settings.  
        PromptBuilder builder = new PromptBuilder();  
        builder.AppendText("This is the default speaking volume.", PromptVolume.Default);  
        builder.AppendBreak();  
        builder.AppendText("This is the extra loud speaking volume.", PromptVolume.ExtraLoud);  
        builder.AppendBreak();  
        builder.AppendText("This is the medium speaking volume.", PromptVolume.Medium);  
  
        // Speak the prompt.  
        synth.Speak(builder);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendTextWithAlias">
      <MemberSignature Language="C#" Value="public void AppendTextWithAlias (string textToSpeak, string substitute);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithAlias(string textToSpeak, string substitute) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithAlias(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendTextWithAlias (textToSpeak As String, substitute As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithAlias(System::String ^ textToSpeak, System::String ^ substitute);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithAlias : string * string -&gt; unit" Usage="promptBuilder.AppendTextWithAlias (textToSpeak, substitute)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="substitute" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Ciąg zawierający reprezentację tekstową.</param>
        <param name="substitute">Ciąg zawierający tekst, który ma być używany.</param>
        <summary>Dołącza tekst <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu i określa tekst alias wymawiane zamiast dołączony tekst.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Dzięki temu dokumentu prowadzone i formę tekstową pojawił się monit. Na przykład w formie pisemnej może być akronim, takich jak nieokreślone, i mówionej formy może być rozwinięty tekst akronim, w tym przypadków mowy Application Programming Interface.  
  
   
  
## Examples  
 Poniższy przykład dołącza ciąg tekstowy ("mowy syntezy Markup Language") i jego aliasu ("SSML") do <xref:System.Speech.Synthesis.PromptBuilder> obiektu. Syntezator będzie Wypowiedz "S S M L".  
  
```  
PromptBuilder alias = new PromptBuilder();  
alias.AppendTextWithAlias("Speech Synthesis Markup Language","SSML");   
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendTextWithHint">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Dołącza tekst <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu i określa typ zawartości tekstu.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendTextWithHint">
      <MemberSignature Language="C#" Value="public void AppendTextWithHint (string textToSpeak, System.Speech.Synthesis.SayAs sayAs);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithHint(string textToSpeak, valuetype System.Speech.Synthesis.SayAs sayAs) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint(System.String,System.Speech.Synthesis.SayAs)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithHint(System::String ^ textToSpeak, System::Speech::Synthesis::SayAs sayAs);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithHint : string * System.Speech.Synthesis.SayAs -&gt; unit" Usage="promptBuilder.AppendTextWithHint (textToSpeak, sayAs)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="sayAs" Type="System.Speech.Synthesis.SayAs" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Ciąg zawierający tekst, który ma być używany.</param>
        <param name="sayAs">Typ zawartości tekstu.</param>
        <summary>Dołącza tekst <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu i określa typ zawartości przy użyciu członkiem <see cref="T:System.Speech.Synthesis.SayAs" /> wyliczenia.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Typ zawartości, określony przez `sayAs` może stanowić wskazówkę dla aparatu synteza mowy o Wymowa zawartość `textToSpeak`.  
  
   
  
## Examples  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and define the data types for some of the added strings.  
        PromptBuilder sayAs = new PromptBuilder();  
        sayAs.AppendText("Your");  
        sayAs.AppendTextWithHint("1st", SayAs.NumberOrdinal);  
        sayAs.AppendText("request was for");  
        sayAs.AppendTextWithHint("1", SayAs.NumberCardinal);  
        sayAs.AppendText("room, on");  
        sayAs.AppendTextWithHint("10/19/2012,", SayAs.MonthDayYear);  
        sayAs.AppendText("with early arrival at");  
        sayAs.AppendTextWithHint("12:35pm", SayAs.Time12);  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(sayAs);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendTextWithHint">
      <MemberSignature Language="C#" Value="public void AppendTextWithHint (string textToSpeak, string sayAs);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithHint(string textToSpeak, string sayAs) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendTextWithHint (textToSpeak As String, sayAs As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithHint(System::String ^ textToSpeak, System::String ^ sayAs);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithHint : string * string -&gt; unit" Usage="promptBuilder.AppendTextWithHint (textToSpeak, sayAs)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="sayAs" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Ciąg zawierający tekst, który ma być używany.</param>
        <param name="sayAs">Typ zawartości tekstu.</param>
        <summary>Dołącza tekst <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu i <see cref="T:System.String" /> , który określa typ zawartości tekstu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ta metoda służy do określania typu zawartości, która nie jest uwzględniony w <xref:System.Speech.Synthesis.SayAs> wyliczenia. Jednak aparatu TTS musi obsługiwać parametr, który określisz.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendTextWithPronunciation">
      <MemberSignature Language="C#" Value="public void AppendTextWithPronunciation (string textToSpeak, string pronunciation);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithPronunciation(string textToSpeak, string pronunciation) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithPronunciation(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendTextWithPronunciation (textToSpeak As String, pronunciation As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithPronunciation(System::String ^ textToSpeak, System::String ^ pronunciation);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithPronunciation : string * string -&gt; unit" Usage="promptBuilder.AppendTextWithPronunciation (textToSpeak, pronunciation)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="pronunciation" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Ciąg zawierający formę tekstową programu word za pomocą konwencjonalnych alfabetu dla języka.</param>
        <param name="pronunciation">Ciąg zawierający telefony wymawiane z międzynarodowy alfabet fonetyczny (IPA).</param>
        <summary>Dołącza tekst <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu i określa Wymowa tekstu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Syntezator mówi zawartość `pronunciation` parametr, nie ich zawartość `textToSpeak` parametru.  
  
 Wymowy określone w jednej linii monity mają zastosowanie tylko do poszczególnych wystąpień wyrazu i zastąpić wymowy aparatu rozpoznawania mowy, lub dowolnego z jego lexicons aktualnie aktywne. Zazwyczaj użyjesz wymowy wbudowanych niestandardowych wymowy istniejących słów lub Wymowa nietypowe słów, takich jak poprawne nazwy, które aparat synteza mowy może nie Wypowiedz, a także oczekiwano.  
  
 Wbudowane wymowy musi być określona za pomocą telefony z międzynarodowy alfabet fonetyczny (IPA). Telefon jest literą lub znakiem, który reprezentuje niejawnego dźwięk mowy. Aparatów rozpoznawania mowy, które są zgodne z [mowy syntezy Markup Language (SSML) w wersji 1.0](https://go.microsoft.com/fwlink/?LinkId=201763) specyfikacji będzie Wypowiedz telefony z IPA. Aby określić wymowy tekście przy użyciu innych alfabety fonetyczny, zobacz <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>.  
  
 Publikuje IPA [wykresu](https://go.microsoft.com/fwlink/?LinkId=58362) , wyświetla listę swoich telefonach i mapuje je cyfry Unicode.  
  
 Niektórych telefonach w alfabecie IPA ma tej samej reprezentacji jako litery alfabetu łacińskiego. W takich przypadkach istnieje możliwość wpisz znaków łacińskich, a ma reprezentacji odpowiednich dla telefonu. Ponieważ znaki alfabetu łacińskiego, jak często używane w tekście mogą reprezentować kilka telefony zestawu IPA telefonu, po prostu wpisując znaków łacińskich może nie spowodować dokładne phone IPA żądanego. Inne telefony IPA alfabetu konieczność jest reprezentowana w kodzie jako znak odwołania składający się z handlowe "i" (&), znak numeru (#), a to liczba Unicode dla żądanego telefonu w formacie szesnastkowym lub decimal, wszystkie następuje średnik (;). Na przykład schwa (&\#x0259;) jest przedstawiany przez `&#x0259;`.  
  
 Aby dodać nowe lub niestandardowe wymowy wiele słów, na przykład dialekty express regionalne lub dodać prawidłowe nazwy lub słownictwa, które są specyficzne dla dyscypliny edukacyjnych lub medyczne, twórz leksykonu i dodać go do <xref:System.Speech.Synthesis.SpeechSynthesizer> przy użyciu <xref:System.Speech.Synthesis.SpeechSynthesizer.AddLexicon%2A>.  
  
   
  
## Examples  
 Poniższy przykład inicjuje nowe wystąpienie klasy <xref:System.Speech.Synthesis.PromptBuilder> klasy. Go następnie dołącza ciąg tekstowy "Moja nazwa to" do wystąpienia. Na koniec dołącza ciąg zawierający poprawnej nazwy "DuBois" i określa Wymowa nazwy.  
  
```csharp  
public void ProperName()  
{  
    PromptBuilder builder = new PromptBuilder();  
    builder.AppendText("My name is");  
  
    // Add a proper name and its pronunciation.  
    builder.AppendTextWithPronunciation("DuBois", "duˈbwɑ");     
}  
```  
  
 Poniższy kod przedstawia SSML że <xref:System.Speech.Synthesis.PromptBuilder> generuje obiekt.  
  
```xml  
<speak xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="en-us">  
  My name is <phoneme ph="duˈbwɑ"> DuBois </phoneme>  
</speak>  
```  
  
 ]]></format>
        </remarks>
        <related type="ExternalDocumentation" href="https://go.microsoft.com/fwlink/?LinkId=58363">Międzynarodowe Stowarzyszenie fonetycznych</related>
      </Docs>
    </Member>
    <Member MemberName="ClearContent">
      <MemberSignature Language="C#" Value="public void ClearContent ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void ClearContent() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.ClearContent" />
      <MemberSignature Language="VB.NET" Value="Public Sub ClearContent ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void ClearContent();" />
      <MemberSignature Language="F#" Value="member this.ClearContent : unit -&gt; unit" Usage="promptBuilder.ClearContent " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Czyści zawartość z <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Culture">
      <MemberSignature Language="C#" Value="public System.Globalization.CultureInfo Culture { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Globalization.CultureInfo Culture" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.PromptBuilder.Culture" />
      <MemberSignature Language="VB.NET" Value="Public Property Culture As CultureInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Globalization::CultureInfo ^ Culture { System::Globalization::CultureInfo ^ get(); void set(System::Globalization::CultureInfo ^ value); };" />
      <MemberSignature Language="F#" Value="member this.Culture : System.Globalization.CultureInfo with get, set" Usage="System.Speech.Synthesis.PromptBuilder.Culture" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Globalization.CultureInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera lub ustawia informacje dotyczące kultury dla <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <value>To be added.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Synthesis.SpeechSynthesizer> Obiektu będzie podejmować próby Wybierz zainstalowany głos, obsługujący język określony przez <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> właściwości do przetwarzania w wierszu polecenia. Jeśli zostanie znaleziony głosu przy użyciu określonej kultury, będzie on używany. Jeśli nie można odnaleźć głosu przy użyciu określonej kultury, głos domyślny będą używane.  
  
 Kultura może zostać określony w wierszu dla niejawnego części zawartości przy użyciu <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A>, <xref:System.Speech.Synthesis.PromptBuilder.StartParagraph%2A>, i <xref:System.Speech.Synthesis.PromptBuilder.StartSentence%2A> metody. Kultura określona dla fragmentu zawartości przy użyciu jednej z powyższych metod spowoduje przesłonięcie <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> właściwości, a w efekcie i <xref:System.Speech.Synthesis.SpeechSynthesizer> podejmie próbę Wybierz zainstalowany głos, obsługujący język określony przez `culture` Parametr metody.  
  
 Poprawnie Wymowa słów w języku określonym przez <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> właściwość, aparat syntezy (zamiana tekstu na mowę lub TTS) mowy, który obsługuje język musi być zainstalowany. Zainstalowane aparatu TTS nosi nazwę głosu. Aby uzyskać informacje o tym, które są zainstalowane głosów dla określonej kultury, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metody.  
  
 Program Microsoft Windows i interfejsu API System.Speech Zaakceptuj wszystkie prawidłowe kody krajów języka jako wartości dla `culture`. Aparaty TTS, które są dostarczane z programem Windows 7 obsługują następujące kody krajów języka:  
  
-   en-US. Angielski (Stany Zjednoczone)  
  
-   zh-CN. Chiński (Chiny)  
  
-   zh-TW. Chiński (Tajwan)  
  
 Kody dwuliterowych języków, takich jak "en", również są dozwolone.  Zobacz [stałe identyfikator języka i ciągi](https://msdn.microsoft.com/library/dd318693\(VS.85\).aspx) Aby uzyskać pełną listę kodów języków.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndParagraph">
      <MemberSignature Language="C#" Value="public void EndParagraph ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndParagraph() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndParagraph" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndParagraph ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndParagraph();" />
      <MemberSignature Language="F#" Value="member this.EndParagraph : unit -&gt; unit" Usage="promptBuilder.EndParagraph " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Określa koniec akapitu w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Długie monity może być renderowany bardziej jak ludzkiej mowy, jeśli są one podzielone na zdania i akapitach. Zobacz <xref:System.Speech.Synthesis.PromptBuilder.StartParagraph%2A> przykład.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndSentence">
      <MemberSignature Language="C#" Value="public void EndSentence ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndSentence() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndSentence" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndSentence ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndSentence();" />
      <MemberSignature Language="F#" Value="member this.EndSentence : unit -&gt; unit" Usage="promptBuilder.EndSentence " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Określa koniec zdania w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Długie monity może być renderowany bardziej jak ludzkiej mowy, jeśli są one podzielone na zdania i akapitach. Zobacz <xref:System.Speech.Synthesis.PromptBuilder.StartSentence%2A> przykład.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndStyle">
      <MemberSignature Language="C#" Value="public void EndStyle ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndStyle() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndStyle" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndStyle ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndStyle();" />
      <MemberSignature Language="F#" Value="member this.EndStyle : unit -&gt; unit" Usage="promptBuilder.EndStyle " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Określa koniec stylu w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Synthesis.PromptBuilder.EndStyle%2A> Metoda Zatrzymuje bieżący styl wypowiedzi. Stylu wypowiedzi przywraca ustawienie, które zostało obowiązywać przed <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> metoda zainicjowano nowy styl wypowiedzi. Zobacz <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> przykład.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndVoice">
      <MemberSignature Language="C#" Value="public void EndVoice ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndVoice() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndVoice" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndVoice ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndVoice();" />
      <MemberSignature Language="F#" Value="member this.EndVoice : unit -&gt; unit" Usage="promptBuilder.EndVoice " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Określa koniec użytkowania głosu w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A> Metoda zatrzymuje użytek mowie bieżącego głosu. Głos przywraca ustawienie, które zostało obowiązywać przed <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> metoda zainicjowano nowy głos.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="IsEmpty">
      <MemberSignature Language="C#" Value="public bool IsEmpty { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool IsEmpty" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.PromptBuilder.IsEmpty" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property IsEmpty As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool IsEmpty { bool get(); };" />
      <MemberSignature Language="F#" Value="member this.IsEmpty : bool" Usage="System.Speech.Synthesis.PromptBuilder.IsEmpty" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera czy <see cref="T:System.Speech.Synthesis.PromptBuilder" /> jest pusty.</summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="StartParagraph">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Określa początek akapitu w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiekt oraz opcjonalnie określa język.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Długie monity może być renderowany bardziej jak ludzkiej mowy, jeśli są one podzielone na zdania i akapitach.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="StartParagraph">
      <MemberSignature Language="C#" Value="public void StartParagraph ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartParagraph() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartParagraph" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartParagraph ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartParagraph();" />
      <MemberSignature Language="F#" Value="member this.StartParagraph : unit -&gt; unit" Usage="promptBuilder.StartParagraph " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Określa początek akapitu w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Długie monity może być renderowany bardziej jak ludzkiej mowy, jeśli są one podzielone na zdania i akapitach.  
  
   
  
## Examples  
 Poniższy przykład tworzy <xref:System.Speech.Synthesis.PromptBuilder> obiektu, dołącza zawartość i organizuje zawartości w akapitów i zdania.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content as paragraphs and sentences.  
        PromptBuilder parSent = new PromptBuilder();  
        parSent.StartParagraph();  
        parSent.StartSentence();  
        parSent.AppendText("Introducing the sentence element.");  
        parSent.EndSentence();  
        parSent.StartSentence();  
        parSent.AppendText("You can use it to mark individual sentences.");  
        parSent.EndSentence();  
        parSent.EndParagraph();  
        parSent.StartParagraph();  
        parSent.AppendText("Another simple paragraph. Sentence structure in this paragraph" +  
          "is not explicitly marked.");  
        parSent.EndParagraph();  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(parSent);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartParagraph">
      <MemberSignature Language="C#" Value="public void StartParagraph (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartParagraph(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartParagraph(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartParagraph (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartParagraph(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.StartParagraph : System.Globalization.CultureInfo -&gt; unit" Usage="promptBuilder.StartParagraph culture" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Zawiera informacje dotyczące określonej kultury, takie jak język, nazwa kultury, system pisma, kalendarz używany i sposób formatowania dat i sortowania ciągów.</param>
        <summary>Określa początek akapitu w określonej kultury w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Długie monity może być renderowany bardziej jak ludzkiej mowy, jeśli są one podzielone na zdania i akapitach.  
  
 `culture` Parametr akapitu może być inna niż <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> właściwość <xref:System.Speech.Synthesis.PromptBuilder> obiekt, który go zawiera. W efekcie otrzymało wartość `culture` spowoduje zastąpienie parametru <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> właściwości. <xref:System.Speech.Synthesis.SpeechSynthesizer> Podejmie próbę Wybierz zainstalowany głos, obsługujący język określony przez `culture` parametru, aby porozmawiać akapitu. Jeśli zostanie znaleziony głosu przy użyciu określonej kultury, będzie on używany. Jeśli nie można odnaleźć głosu przy użyciu określonej kultury, głos domyślny będą używane. Aby zatrzymać, korzystając z funkcji głosowych, określony przez <xref:System.Speech.Synthesis.PromptBuilder.StartParagraph%2A>, wywołaj <xref:System.Speech.Synthesis.PromptBuilder.EndParagraph%2A>.  
  
 Poprawnie Wymowa słów w języku określonym przez `culture` parametru, aparat syntezy (zamiana tekstu na mowę lub TTS) mowy, który obsługuje język musi być zainstalowany. Zainstalowane aparatu TTS nosi nazwę głosu. Aby uzyskać informacje o tym, które są zainstalowane głosów dla określonej kultury, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metody.  
  
 Program Microsoft Windows i interfejsu API System.Speech Zaakceptuj wszystkie prawidłowe kody krajów języka jako wartości dla `culture`. Aparaty TTS, które są dostarczane z programem Windows 7 obsługują następujące kody krajów języka:  
  
-   en-US. Angielski (Stany Zjednoczone)  
  
-   zh-CN. Chiński (Chiny)  
  
-   zh-TW. Chiński (Tajwan)  
  
 Kody dwuliterowych języków, takich jak "en", również są dozwolone.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="StartSentence">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Określa początek zdanie w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiekt oraz opcjonalnie określa język.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Długie monity może być renderowany bardziej jak ludzkiej mowy, jeśli są one podzielone na zdania i akapitach.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="StartSentence">
      <MemberSignature Language="C#" Value="public void StartSentence ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartSentence() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartSentence" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartSentence ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartSentence();" />
      <MemberSignature Language="F#" Value="member this.StartSentence : unit -&gt; unit" Usage="promptBuilder.StartSentence " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Określa początek zdanie w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Długie monity może być renderowany bardziej jak ludzkiej mowy, jeśli są one podzielone na zdania i akapitach.  
  
   
  
## Examples  
 Poniższy przykład tworzy <xref:System.Speech.Synthesis.PromptBuilder> obiektu, dołącza zawartość i organizuje zawartości w akapitów i zdania.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content as paragraphs and sentences.  
        PromptBuilder parSent = new PromptBuilder();  
        parSent.StartParagraph();  
        parSent.StartSentence();  
        parSent.AppendText("Introducing the sentence element.");  
        parSent.EndSentence();  
        parSent.StartSentence();  
        parSent.AppendText("You can use it to mark individual sentences.");  
        parSent.EndSentence();  
        parSent.EndParagraph();  
        parSent.StartParagraph();  
        parSent.AppendText("Another simple paragraph. Sentence structure in this paragraph" +  
          "is not explicitly marked.");  
        parSent.EndParagraph();  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(parSent);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartSentence">
      <MemberSignature Language="C#" Value="public void StartSentence (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartSentence(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartSentence(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartSentence (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartSentence(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.StartSentence : System.Globalization.CultureInfo -&gt; unit" Usage="promptBuilder.StartSentence culture" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Zawiera informacje dotyczące określonej kultury, takie jak język, nazwa kultury, system pisma, kalendarz używany i sposób formatowania dat i sortowania ciągów.</param>
        <summary>Określa początek zdania w określonej kultury w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Długie monity może być renderowany bardziej jak ludzkiej mowy, jeśli są one podzielone na zdania i akapitach.  
  
 `culture` Parametr zdanie, może być inna niż `culture` parametr akapit, który zawiera zdania lub <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> właściwość <xref:System.Speech.Synthesis.PromptBuilder> obiektu, który je zawiera.  
  
 W efekcie otrzymało wartość `culture` spowoduje zastąpienie parametru <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> właściwości i `culture` parametr akapit, który zawiera zdanie. <xref:System.Speech.Synthesis.SpeechSynthesizer> Podejmie próbę Wybierz zainstalowany głos, obsługujący język określony przez `culture` parametru, aby porozmawiać zdanie. Jeśli zostanie znaleziony głosu przy użyciu określonej kultury, będzie on używany. Jeśli nie można odnaleźć głosu przy użyciu określonej kultury, głos domyślny będą używane. Aby zatrzymać, korzystając z funkcji głosowych, określony przez <xref:System.Speech.Synthesis.PromptBuilder.StartSentence%2A>, wywołaj <xref:System.Speech.Synthesis.PromptBuilder.EndSentence%2A>.  
  
 Poprawnie Wymowa słów w języku określonym przez `culture` parametru, aparat syntezy (zamiana tekstu na mowę lub TTS) mowy, który obsługuje język musi być zainstalowany. Zainstalowane aparatu TTS nosi nazwę głosu. Aby uzyskać informacje o tym, które są zainstalowane głosów dla określonej kultury, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metody.  
  
 Program Microsoft Windows i interfejsu API System.Speech Zaakceptuj wszystkie prawidłowe kody krajów języka jako wartości dla `culture`. Aparaty TTS, które są dostarczane z programem Windows 7 obsługują następujące kody krajów języka:  
  
-   en-US. Angielski (Stany Zjednoczone)  
  
-   zh-CN. Chiński (Chiny)  
  
-   zh-TW. Chiński (Tajwan)  
  
 Kody dwuliterowych języków, takich jak "en", również są dozwolone.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartStyle">
      <MemberSignature Language="C#" Value="public void StartStyle (System.Speech.Synthesis.PromptStyle style);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartStyle(class System.Speech.Synthesis.PromptStyle style) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartStyle(System.Speech.Synthesis.PromptStyle)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartStyle (style As PromptStyle)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartStyle(System::Speech::Synthesis::PromptStyle ^ style);" />
      <MemberSignature Language="F#" Value="member this.StartStyle : System.Speech.Synthesis.PromptStyle -&gt; unit" Usage="promptBuilder.StartStyle style" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="style" Type="System.Speech.Synthesis.PromptStyle" />
      </Parameters>
      <Docs>
        <param name="style">Styl do uruchomienia.</param>
        <summary>Określa początek stylu w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> Metoda przyjmuje <xref:System.Speech.Synthesis.PromptStyle> obiekt jako argumentu. Można użyć właściwości <xref:System.Speech.Synthesis.PromptStyle> obiektu w celu ustawienia szczególnym wypowiedzi szybkości i woluminów (parametrów akustycznych) do zastosowania do rozpoznawania mowy, dane wyjściowe stylu w czasie działania. Aby zatrzymać, przy użyciu bieżącego stylu, należy wywołać <xref:System.Speech.Synthesis.PromptBuilder.EndStyle%2A> metody.  
  
> [!NOTE]
> -   Aparaty synteza mowy w Windows obsługuje parametru nacisk w tej chwili. Ustawianie wartości dla parametru wyróżnienia dadzą bez dźwiękowych zmian w danych wyjściowych syntezatora mowy.  
> -   <xref:System.Speech.Synthesis.PromptVolume.Default> Ustawienie <xref:System.Speech.Synthesis.PromptVolume> jest pełnym woluminie, która jest taka sama jak <xref:System.Speech.Synthesis.PromptVolume.ExtraLoud>. Inne ustawienia zmniejszenie ilości mowie względem całego woluminu.  
  
   
  
## Examples  
 Poniższy przykład tworzy <xref:System.Speech.Synthesis.PromptBuilder> obiektu i dołącza ciągów tekstowych. W przykładzie użyto <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> metodę, aby określić powolne wypowiedzi szybkości dla ciągu dodawane, które wylicza zawartości zamówienia.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content.  
        PromptBuilder style = new PromptBuilder();  
        style.AppendText("Your order for");  
        style.StartStyle(new PromptStyle(PromptRate.Slow));  
        style.AppendText("one kitchen sink and one faucet");  
        style.EndStyle();  
        style.AppendText("has been confirmed.");  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(style);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="StartVoice">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Powoduje, że Syntezator, aby zmienić głosu w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Głosu reprezentuje aparat TTS zainstalowane. Użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metod i <xref:System.Speech.Synthesis.VoiceInfo> klasy w celu uzyskania nazwy i atrybuty zainstalowane głosów zamiany tekstu na mowę (TTS), które można wybrać.  
  
 Kiedy aplikacja wywołuje <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, ta metoda sprawdza, czy każdy głosów znajdzie się w rejestrze spełnia niektóre minimalne kryteria. Niepowodzenia weryfikacji, na dowolnym głos <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> ustawia jego <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwość `False`. Aplikacja nie może wywoływać dowolną z <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> metod głosu którego <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwość `False`. Zazwyczaj aplikacje nie ustawi głosu <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwości.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Globalization.CultureInfo -&gt; unit" Usage="promptBuilder.StartVoice culture" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Zawiera informacje dotyczące określonej kultury, takie jak język, nazwa kultury, system pisma, kalendarz używany i sposób formatowania dat i sortowania ciągów.</param>
        <summary>Powoduje, że Syntezator, aby zmienić głosu w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu i określa kulturę głosu do użycia.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 `culture` Parametr <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> może być inna niż <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> właściwość <xref:System.Speech.Synthesis.PromptBuilder> obiekt, który go zawiera.  W efekcie otrzymało wartość `culture` spowoduje zastąpienie parametru <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> właściwości. <xref:System.Speech.Synthesis.SpeechSynthesizer> Podejmie próbę Wybierz zainstalowany głos, obsługujący język określony przez `culture` parametru, aby porozmawiać zawartości umieszczonej w <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> i <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>. Jeśli zostanie znaleziony głosu przy użyciu określonej kultury, będzie on używany. Jeśli nie można odnaleźć głosu przy użyciu określonej kultury, głos domyślny będą używane. Aby zatrzymać, korzystając z funkcji głosowych, określony przez <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A>, wywołaj <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 Poprawnie Wymowa słów w języku określonym przez `culture` parametru, aparat syntezy (zamiana tekstu na mowę lub TTS) mowy, który obsługuje język musi być zainstalowany. Zainstalowane aparatu TTS nosi nazwę głosu. Aby uzyskać informacje o tym, które są zainstalowane głosów dla określonej kultury, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metody.  
  
 Program Microsoft Windows i interfejsu API System.Speech Zaakceptuj wszystkie prawidłowe kody krajów języka jako wartości dla `culture`. Aparaty TTS, które są dostarczane z programem Windows 7 obsługują następujące kody krajów języka:  
  
-   en-US. Angielski (Stany Zjednoczone)  
  
-   zh-CN. Chiński (Chiny)  
  
-   zh-TW. Chiński (Tajwan)  
  
 Kody dwuliterowych języków, takich jak "en", również są dozwolone.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceGender gender);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(valuetype System.Speech.Synthesis.VoiceGender gender) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (gender As VoiceGender)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceGender gender);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceGender -&gt; unit" Usage="promptBuilder.StartVoice gender" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
      </Parameters>
      <Docs>
        <param name="gender">Płeć głosu do użycia.</param>
        <summary>Powoduje, że Syntezator, aby zmienić głosu w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu i określa płeć głosu do użycia.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metod i <xref:System.Speech.Synthesis.VoiceInfo> klasy w celu uzyskania nazwy i atrybuty zainstalowane głosów zamiany tekstu na mowę (TTS), które można wybrać.  
  
 Aby zatrzymać, korzystając z funkcji głosowych, określony przez <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> wywołania <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceInfo voice);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(class System.Speech.Synthesis.VoiceInfo voice) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (voice As VoiceInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceInfo ^ voice);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceInfo -&gt; unit" Usage="promptBuilder.StartVoice voice" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="voice" Type="System.Speech.Synthesis.VoiceInfo" />
      </Parameters>
      <Docs>
        <param name="voice">Kryteria głosu do użycia.</param>
        <summary>Powoduje, że Syntezator, aby zmienić głosu w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu i określa kryteria nowy głos.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metod i <xref:System.Speech.Synthesis.VoiceInfo> klasy w celu uzyskania nazwy i atrybuty zainstalowane głosów zamiany tekstu na mowę (TTS), które można wybrać.  
  
 Aby zatrzymać, korzystając z funkcji głosowych, określony przez <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> wywołania <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (string name);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(string name) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (name As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::String ^ name);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : string -&gt; unit" Usage="promptBuilder.StartVoice name" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="name">Nazwa głosu do użycia.</param>
        <summary>Powoduje, że Syntezator, aby zmienić głosu w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu i określa nazwę głosu do użycia.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aby uzyskać informacje o tym, które są zainstalowane głosów, użyj jednej z <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metody.  
  
 Aby zatrzymać, korzystając z funkcji głosowych, określony przez <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> wywołania <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceGender gender, System.Speech.Synthesis.VoiceAge age);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(valuetype System.Speech.Synthesis.VoiceGender gender, valuetype System.Speech.Synthesis.VoiceAge age) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (gender As VoiceGender, age As VoiceAge)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceGender gender, System::Speech::Synthesis::VoiceAge age);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceGender * System.Speech.Synthesis.VoiceAge -&gt; unit" Usage="promptBuilder.StartVoice (gender, age)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
        <Parameter Name="age" Type="System.Speech.Synthesis.VoiceAge" />
      </Parameters>
      <Docs>
        <param name="gender">Płeć nowy głos do użycia.</param>
        <param name="age">Wiek głosu do użycia.</param>
        <summary>Powoduje, że Syntezator, aby zmienić głosu w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu i określa, płeć i wieku nowy głos.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metod i <xref:System.Speech.Synthesis.VoiceInfo> klasy w celu uzyskania nazwy i atrybuty zainstalowane głosów zamiany tekstu na mowę (TTS), które można wybrać.  
  
 Aby zatrzymać, korzystając z funkcji głosowych, określony przez <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> wywołania <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceGender gender, System.Speech.Synthesis.VoiceAge age, int voiceAlternate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(valuetype System.Speech.Synthesis.VoiceGender gender, valuetype System.Speech.Synthesis.VoiceAge age, int32 voiceAlternate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (gender As VoiceGender, age As VoiceAge, voiceAlternate As Integer)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceGender gender, System::Speech::Synthesis::VoiceAge age, int voiceAlternate);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceGender * System.Speech.Synthesis.VoiceAge * int -&gt; unit" Usage="promptBuilder.StartVoice (gender, age, voiceAlternate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
        <Parameter Name="age" Type="System.Speech.Synthesis.VoiceAge" />
        <Parameter Name="voiceAlternate" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="gender">Płeć głosu do użycia.</param>
        <param name="age">Wiek głosu do użycia.</param>
        <param name="voiceAlternate">Liczba całkowita, która określa preferowany głosowych, gdy jest zgodna z więcej niż jeden głos <paramref name="gender" /> i <paramref name="age" /> parametrów.</param>
        <summary>Powoduje, że Syntezator, aby zmienić głosu w <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu oraz określa jego płeć, wiek i preferowaną głosowej, odpowiadający określonej płci i wieku.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aparat synteza mowy liczby dopasowań znajdzie dla określonych parametrów i zwraca głosu w przypadku, gdy liczba jest równa `voiceAlternate` parametru.  
  
 Użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metod i <xref:System.Speech.Synthesis.VoiceInfo> klasy w celu uzyskania nazwy i atrybuty zainstalowane głosów zamiany tekstu na mowę (TTS), które można wybrać.  
  
 Aby zatrzymać, korzystając z funkcji głosowych, określony przez <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> wywołania <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge)" />
      </Docs>
    </Member>
    <Member MemberName="ToXml">
      <MemberSignature Language="C#" Value="public string ToXml ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance string ToXml() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.ToXml" />
      <MemberSignature Language="VB.NET" Value="Public Function ToXml () As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::String ^ ToXml();" />
      <MemberSignature Language="F#" Value="member this.ToXml : unit -&gt; string" Usage="promptBuilder.ToXml " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Zwraca SSML wygenerowany na podstawie <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <returns>Zwraca SSML wygenerowany na podstawie <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu jako jeden wiersz.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Synthesis.PromptBuilder.ToXml%2A> Metody sprawia, że próba formatowanie zwróconego SSML w dowolny sposób.  
  
   
  
## Examples  
 Poniższy przykład tworzy <xref:System.Speech.Synthesis.PromptBuilder> obiektu, który dołącza tekstu, a następnie zapisuje odpowiednik SSML w wierszu polecenia programu do konsoli, przed wypowiedzi zawartość wiersza.  
  
```csharp  
  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content.  
        PromptBuilder style = new PromptBuilder();  
        style.AppendText("Your order for");  
        style.StartStyle(new PromptStyle(PromptRate.Slow));  
        style.AppendText("one kitchen sink and one faucet");  
        style.EndStyle();  
        style.AppendText("has been confirmed.");  
  
        // Write the contents of the PromptBuilder object to the console as  
        // an SSML-compatible XML file.  
        string myXml = style.ToXml();  
        Console.WriteLine("This is the SSML equivalent of the PromptBuilder: \n\n" + myXml);  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(style);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>