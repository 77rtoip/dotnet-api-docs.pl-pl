<Type Name="SpeechSynthesizer" FullName="System.Speech.Synthesis.SpeechSynthesizer">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="f6eea2486684c6537e9648cd89b039296eecf220" />
    <Meta Name="ms.sourcegitcommit" Value="6a0b904069161bbaec4ffd02aa7d9cf38c61e72e" />
    <Meta Name="ms.translationtype" Value="MT" />
    <Meta Name="ms.contentlocale" Value="pl-PL" />
    <Meta Name="ms.lasthandoff" Value="06/24/2018" />
    <Meta Name="ms.locfileid" Value="36408624" />
  </Metadata>
  <TypeSignature Language="C#" Value="public sealed class SpeechSynthesizer : IDisposable" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed beforefieldinit SpeechSynthesizer extends System.Object implements class System.IDisposable" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Synthesis.SpeechSynthesizer" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class SpeechSynthesizer&#xA;Implements IDisposable" />
  <TypeSignature Language="C++ CLI" Value="public ref class SpeechSynthesizer sealed : IDisposable" />
  <TypeSignature Language="F#" Value="type SpeechSynthesizer = class&#xA;    interface IDisposable" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces>
    <Interface>
      <InterfaceName>System.IDisposable</InterfaceName>
    </Interface>
  </Interfaces>
  <Docs>
    <summary>Zapewnia dostęp do funkcji aparatu syntezy zainstalowanych mowy.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Podczas tworzenia nowego <xref:System.Speech.Synthesis.SpeechSynthesizer> obiektu, używa głos systemu domyślny. Aby skonfigurować <xref:System.Speech.Synthesis.SpeechSynthesizer> użycia jednej z zainstalowanych mowy głosy syntezie (tekst na mowę), użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> metody. Aby uzyskać informacje o tym, które głosy są zainstalowane, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> — metoda i <xref:System.Speech.Synthesis.VoiceInfo> klasy.  
  
 Ta klasa udostępnia także kontrolować następujące aspekty syntezy mowy:  
  
-   Aby skonfigurować dane wyjściowe dla <xref:System.Speech.Synthesis.SpeechSynthesizer> obiektów, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A>, i <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile%2A> metody.  
  
-   Aby wygenerować mowy, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A>, lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> metody. <xref:System.Speech.Synthesis.SpeechSynthesizer> Może utworzyć mowy z pliku tekstowego, <xref:System.Speech.Synthesis.Prompt> lub <xref:System.Speech.Synthesis.PromptBuilder> obiekt, lub z [mowy syntezy Markup Language (SSML) w wersji 1.0](http://go.microsoft.com/fwlink/?LinkId=201763).  
  
-   Aby wstrzymać lub wznowić syntezy mowy, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.Pause%2A> i <xref:System.Speech.Synthesis.SpeechSynthesizer.Resume%2A> metody.  
  
-   Aby dodać lub usunąć leksykonów, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.AddLexicon%2A> i <xref:System.Speech.Synthesis.SpeechSynthesizer.RemoveLexicon%2A> metody. <xref:System.Speech.Synthesis.SpeechSynthesizer> Można użyć co najmniej jeden leksykonów prowadzące jego wymowy słowa.  
  
-   Aby zmodyfikować dostarczania mowie, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.Rate%2A> i <xref:System.Speech.Synthesis.SpeechSynthesizer.Volume%2A> właściwości.  
  
 <xref:System.Speech.Synthesis.SpeechSynthesizer> Informuje o zdarzeniach po napotkaniu pewnych funkcji w monity: (<xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached>, <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached>, <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached>, i <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress>). Zgłasza zdarzenia, które należy sporządzić raport na początku (<xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted>) i końcowych (<xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted>) z mowy operacji i po zmianie delikatnego głosu (<xref:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange>).  
  
> [!NOTE]
>  Wywoływanie zawsze <xref:System.Speech.Synthesis.SpeechSynthesizer.Dispose%2A> przed zwolnieniem ostatniego odwołania do <xref:System.Speech.Synthesis.SpeechSynthesizer>. W przeciwnym razie używa zasobów nie zostanie zwolniona do wywołania modułu zbierającego elementy bezużyteczne <xref:System.Speech.Synthesis.SpeechSynthesizer> obiektu <xref:System.Object.Finalize%2A> metody.  
  
   
  
## Examples  
 Poniższy przykład jest częścią aplikacji konsoli, która inicjuje <xref:System.Speech.Synthesis.SpeechSynthesizer> obiektu i mówi ciąg.  
  
```csharp  
  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Speak a string.  
      synth.Speak("This example demonstrates a basic use of Speech Synthesizer");  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Synthesis.InstalledVoice" />
    <altmember cref="T:System.Speech.Synthesis.Prompt" />
    <altmember cref="T:System.Speech.Synthesis.PromptBuilder" />
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechSynthesizer ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SpeechSynthesizer();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>Inicjuje nowe wystąpienie klasy <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> klasy.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Podczas inicjowania nowy <xref:System.Speech.Synthesis.SpeechSynthesizer> wystąpienia, używa głos systemu domyślny. Aby skonfigurować <xref:System.Speech.Synthesis.SpeechSynthesizer> użycia jednej z zainstalowanych mowy głosy syntezie (tekst na mowę), użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> metody. Aby uzyskać informacje o tym, które głosy są zainstalowane, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> — metoda i <xref:System.Speech.Synthesis.VoiceInfo> klasy.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.InstalledVoice" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints(System.Speech.Synthesis.VoiceGender)" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices" />
      </Docs>
    </Member>
    <Member MemberName="AddLexicon">
      <MemberSignature Language="C#" Value="public void AddLexicon (Uri uri, string mediaType);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AddLexicon(class System.Uri uri, string mediaType) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.AddLexicon(System.Uri,System.String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AddLexicon(Uri ^ uri, System::String ^ mediaType);" />
      <MemberSignature Language="F#" Value="member this.AddLexicon : Uri * string -&gt; unit" Usage="speechSynthesizer.AddLexicon (uri, mediaType)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="uri" Type="System.Uri" />
        <Parameter Name="mediaType" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="uri">Lokalizacja danych słownika.</param>
        <param name="mediaType">Typ nośnika leksykonie. Wartości typu nośnika nie jest uwzględniana.</param>
        <summary>Dodaje słownika do <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Leksykonie wymowy jest kolekcją słów ani fraz wraz z ich wymowy, które składają się z liter i znaków z obsługiwanych alfabet fonetyczny. Leksykonie służy do określania niestandardowej wymowy specjalistycznego słownictwa w aplikacji.  
  
 Określone w pliku zewnętrznego słownika wymowy mają pierwszeństwo przed wymowy leksykonie wewnętrzny lub słownik syntezatorów mowy. Jednak wymowy określony wbudowany w monity utworzone za pomocą dowolnego z <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithPronunciation%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>, lub <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A> metody mają pierwszeństwo przed wymowy określone w dowolnym leksykonie. Wbudowany wymowy mają zastosowanie tylko do pojedynczego wystąpienia wyrazu. Zobacz [leksykonów i małych liter fonetyczny](http://msdn.microsoft.com/library/435e3c6f-6834-4e5a-b0f6-c17b2275dc51) Aby uzyskać więcej informacji.  
  
 Można dodać wiele leksykonów do <xref:System.Speech.Synthesis.SpeechSynthesizer> obiektu. Dwie wartości są obecnie obsługiwane dla `mediaType` parametru:  
  
-   Wartość `application/pls+xml` wskazuje, że odpowiada leksykonie [wymowy leksykonie specyfikacji (PLS) w wersji 1.0](http://go.microsoft.com/fwlink/?LinkId=201766). Jest to preferowany formatu do użycia.  
  
-   Wartość `application/vdn.ms-sapi-lex` oznacza, że format leksykonie nieskompresowanych słownika, czyli formatu Microsoft zastrzeżonych. Jest to starszy format i zalecane jest użycie formatu PLS opisane powyżej.  
  
   
  
## Examples  
 Poniższy przykład ilustruje efekt Dodawanie i usuwanie słownika, zawierający niestandardowe wymowy dla słowa "blue". Leksykonie definiuje Wymowa "blue", aby brzmiał jak "bleep". Podczas leksykonie syntezatorów mowy używa wymowy zdefiniowane w leksykonie.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Speak the prompt.  
        synth.Speak("My favorite color is blue.");  
  
        // Add a lexicon that changes the pronunciation of "blue".  
        synth.AddLexicon(new Uri("C:\\test\\Blue.pls"), "application/pls+xml");  
  
        // Speak the prompt.  
        synth.Speak("My favorite color is blue.");  
  
        // Remove the lexicon.  
        synth.RemoveLexicon(new Uri("C:\\test\\Blue.pls"));  
  
        // Speak the prompt.  
        synth.Speak("My favorite color is blue.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 Zawartość pliku leksykonie Blue.pls są następujące:  
  
```xml  
<?xml version="1.0" encoding="UTF-8"?>  
  
<lexicon version="1.0"   
      xmlns="http://www.w3.org/2005/01/pronunciation-lexicon"  
      alphabet="x-microsoft-ups" xml:lang="en-US">  
  
  <lexeme>  
    <grapheme> blue </grapheme>  
    <phoneme> B L I P </phoneme>  
  </lexeme>  
  
</lexicon>  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.RemoveLexicon(System.Uri)" />
      </Docs>
    </Member>
    <Member MemberName="BookmarkReached">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.BookmarkReachedEventArgs&gt; BookmarkReached;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.BookmarkReachedEventArgs&gt; BookmarkReached" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event BookmarkReached As EventHandler(Of BookmarkReachedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::BookmarkReachedEventArgs ^&gt; ^ BookmarkReached;" />
      <MemberSignature Language="F#" Value="member this.BookmarkReached : EventHandler&lt;System.Speech.Synthesis.BookmarkReachedEventArgs&gt; " Usage="member this.BookmarkReached : System.EventHandler&lt;System.Speech.Synthesis.BookmarkReachedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.BookmarkReachedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Wywoływane, gdy <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> napotka zakładki w wierszu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Synthesis.SpeechSynthesizer> Zgłasza tego zdarzenia podczas przetwarzania wszystkich <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A>, lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> metody. Aby uzyskać informacje o dane skojarzone ze zdarzeniem, zobacz <xref:System.Speech.Synthesis.BookmarkReachedEventArgs>.  
  
 Można dodać zakładki przy użyciu <xref:System.Speech.Synthesis.PromptBuilder.AppendBookmark%2A> metody.  
  
   
  
## Examples  
 Poniższy przykład tworzy wiersz zawiera dwa zakładek i wysyła dane wyjściowe do pliku WAV przy odtwarzaniu. Program obsługi dla <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached> zdarzeń zapisuje nazwę zakładki i położenia w strumieniem audio po zdarzeniu został zgłoszony do konsoli.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\weather.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\weather.wav");  
  
        // Build a prompt and append bookmarks.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "The weather forecast for today is partly cloudy with some sun breaks.");  
        builder.AppendBookmark("Daytime forecast");  
        builder.AppendText(  
          "Tonight's weather will be cloudy with a 30% chance of showers.");  
        builder.AppendBookmark("Nightime forecast");  
  
        // Add a handler for the BookmarkReached event.  
        synth.BookmarkReached +=  
          new EventHandler<BookmarkReachedEventArgs>(synth_BookmarkReached);  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Write the name and position of the bookmark to the console.  
    static void synth_BookmarkReached(object sender, BookmarkReachedEventArgs e)  
    {  
      Console.WriteLine("Bookmark ({0}) reached at: {1} ",  
        e.Bookmark, e.AudioPosition);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="public void Dispose ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance void Dispose() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.Dispose" />
      <MemberSignature Language="VB.NET" Value="Public Sub Dispose ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; virtual void Dispose();" />
      <MemberSignature Language="F#" Value="abstract member Dispose : unit -&gt; unit&#xA;override this.Dispose : unit -&gt; unit" Usage="speechSynthesizer.Dispose " />
      <MemberType>Method</MemberType>
      <Implements>
        <InterfaceMember>M:System.IDisposable.Dispose</InterfaceMember>
      </Implements>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Usuwa <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiektu i zwalnia zasoby używane w podczas sesji.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Finalize">
      <MemberSignature Language="C#" Value="~SpeechSynthesizer ();" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig virtual instance void Finalize() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.Finalize" />
      <MemberSignature Language="VB.NET" Value="Finalize ()" />
      <MemberSignature Language="C++ CLI" Value="!SpeechSynthesizer ()" />
      <MemberSignature Language="F#" Value="override this.Finalize : unit -&gt; unit" Usage="speechSynthesizer.Finalize " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Działa ze względów bezpieczeństwa, aby wyczyścić zasoby w przypadku gdy <see cref="M:System.Speech.Synthesis.SpeechSynthesizer.Dispose" /> nie jest wywoływana metoda.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="GetCurrentlySpokenPrompt">
      <MemberSignature Language="C#" Value="public System.Speech.Synthesis.Prompt GetCurrentlySpokenPrompt ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Synthesis.Prompt GetCurrentlySpokenPrompt() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.GetCurrentlySpokenPrompt" />
      <MemberSignature Language="VB.NET" Value="Public Function GetCurrentlySpokenPrompt () As Prompt" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Synthesis::Prompt ^ GetCurrentlySpokenPrompt();" />
      <MemberSignature Language="F#" Value="member this.GetCurrentlySpokenPrompt : unit -&gt; System.Speech.Synthesis.Prompt" Usage="speechSynthesizer.GetCurrentlySpokenPrompt " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Synthesis.Prompt</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Pobiera monit, który <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> jest czytanie.</summary>
        <returns>Zwraca obiekt monit, który jest aktualnie używany.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
  
```csharp  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <MemberGroup MemberName="GetInstalledVoices">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Zwraca kolekcję mowy (tekst na mowę) głosy syntezie, które są aktualnie zainstalowane w systemie.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Gdy aplikacja wywołuje <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, ta metoda sprawdza, czy każdy z głosy (aparaty tekstu na mowę) znalezione w spełnia rejestru pewne minimalne kryteria. Wszelkie głosu Niepowodzenie weryfikacji <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> ustawia jego <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwości `False`. Aplikacji nie można wybrać głosu których <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> jest właściwość `False`. Zwykle, aplikacje nie ustawi głosu <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwości.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="GetInstalledVoices">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Synthesis.InstalledVoice&gt; GetInstalledVoices ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Synthesis.InstalledVoice&gt; GetInstalledVoices() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices" />
      <MemberSignature Language="VB.NET" Value="Public Function GetInstalledVoices () As ReadOnlyCollection(Of InstalledVoice)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Synthesis::InstalledVoice ^&gt; ^ GetInstalledVoices();" />
      <MemberSignature Language="F#" Value="member this.GetInstalledVoices : unit -&gt; System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Synthesis.InstalledVoice&gt;" Usage="speechSynthesizer.GetInstalledVoices " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Synthesis.InstalledVoice&gt;</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Zwraca wszystkie zainstalowane mowy głosy syntezie (tekst na mowę).</summary>
        <returns>Zwraca kolekcję tylko do odczytu głosy aktualnie zainstalowane w systemie.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Głos jest aparatem syntezy mowy (tekst na mowę lub TTS), który jest zainstalowany w systemie.  
  
   
  
## Examples  
 Poniższy przykład jest częścią aplikacji konsoli, która inicjuje <xref:System.Speech.Synthesis.SpeechSynthesizer> obiektu i dane wyjściowe konsoli listę zainstalowanych głosów (silników syntezy mowy) i przedstawiono informacje, które są dostępne dla każdego głosu.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
using System.Speech.AudioFormat;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Output information about all of the installed voices.   
        Console.WriteLine("Installed voices -");  
        foreach (InstalledVoice voice in synth.GetInstalledVoices())  
        {  
          VoiceInfo info = voice.VoiceInfo;  
          string AudioFormats = "";  
          foreach (SpeechAudioFormatInfo fmt in info.SupportedAudioFormats)  
          {  
            AudioFormats += String.Format("{0}\n",  
            fmt.EncodingFormat.ToString());  
          }  
  
          Console.WriteLine(" Name:          " + info.Name);  
          Console.WriteLine(" Culture:       " + info.Culture);  
          Console.WriteLine(" Age:           " + info.Age);  
          Console.WriteLine(" Gender:        " + info.Gender);  
          Console.WriteLine(" Description:   " + info.Description);  
          Console.WriteLine(" ID:            " + info.Id);  
          Console.WriteLine(" Enabled:       " + voice.Enabled);  
          if (info.SupportedAudioFormats.Count != 0)  
          {  
            Console.WriteLine( " Audio formats: " + AudioFormats);  
          }  
          else  
          {  
            Console.WriteLine(" No supported audio formats found");  
          }  
  
          string AdditionalInfo = "";  
          foreach (string key in info.AdditionalInfo.Keys)  
          {  
            AdditionalInfo += String.Format("  {0}: {1}\n", key, info.AdditionalInfo[key]);  
          }  
  
          Console.WriteLine(" Additional Info - " + AdditionalInfo);  
          Console.WriteLine();  
        }  
      }  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.InstalledVoice" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
        <altmember cref="Overload:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints" />
        <altmember cref="Overload:System.Speech.Synthesis.PromptBuilder.StartVoice" />
      </Docs>
    </Member>
    <Member MemberName="GetInstalledVoices">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Synthesis.InstalledVoice&gt; GetInstalledVoices (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Synthesis.InstalledVoice&gt; GetInstalledVoices(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Function GetInstalledVoices (culture As CultureInfo) As ReadOnlyCollection(Of InstalledVoice)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Synthesis::InstalledVoice ^&gt; ^ GetInstalledVoices(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.GetInstalledVoices : System.Globalization.CultureInfo -&gt; System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Synthesis.InstalledVoice&gt;" Usage="speechSynthesizer.GetInstalledVoices culture" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Synthesis.InstalledVoice&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Ustawienia regionalne muszą obsługiwać głosu.</param>
        <summary>Zwraca wszystkie zainstalowane mowy głosy syntezie (tekst na mowę), które obsługuje określonych ustawień regionalnych.</summary>
        <returns>Zwraca kolekcję tylko do odczytu głosy aktualnie zainstalowane w systemie, które obsługują określone ustawienia regionalne.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Jeśli żaden z zainstalowanych głosów obsługi określonych ustawień regionalnych, ta metoda zwraca pustą kolekcję.  
  
 Microsoft Windows i interfejsu API System.Speech zaakceptować wszystkie prawidłowe kody języka kraju. Aby wykonać przy użyciu języka określonego we właściwości kultury tekst na mowę, aparat syntezy mowy, który obsługuje kod kraju języka musi być zainstalowany. Aparaty syntezy dostarczonych z programem Microsoft Windows 7 pracować z następujących kodów kraju języka:  
  
-   en-US. Angielski (Stany Zjednoczone)  
  
-   zh-CN. Chiński (Chiny)  
  
-   zh-TW. Chiński (Tajwan)  
  
 Dozwolone są również kodów dwuliterowych języka na przykład "en".  
  
   
  
## Examples  
 Poniższy przykład jest częścią aplikacji konsoli, która inicjuje <xref:System.Speech.Synthesis.SpeechSynthesizer> obiektu i dane wyjściowe konsoli listę zainstalowanych głosów, które obsługują ustawień regionalnych pl pl.  
  
```csharp  
using System;  
using System.Globalization;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the speech synthesizer.  
      using (SpeechSynthesizer synthesizer = new SpeechSynthesizer())  
      {  
  
        // Output information about all of the installed voices that  
        // support the en-US locacale.   
        Console.WriteLine("Installed voices for the en-US locale:");  
        foreach (InstalledVoice voice in  
          synthesizer.GetInstalledVoices(new CultureInfo("en-US")))  
        {  
          VoiceInfo info = voice.VoiceInfo;  
          OutputVoiceInfo(info);  
        }  
  
        // Output information about the current voice.  
        Console.WriteLine();  
        Console.WriteLine("Current voice:");  
        OutputVoiceInfo(synthesizer.Voice);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Display information about a synthesizer voice.  
    private static void OutputVoiceInfo(VoiceInfo info)  
    {  
      Console.WriteLine("  Name: {0}, culture: {1}, gender: {2}, age: {3}.",  
        info.Name, info.Culture, info.Gender, info.Age);  
      Console.WriteLine("    Description: {0}", info.Description);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.InstalledVoice" />
      </Docs>
    </Member>
    <Member MemberName="Pause">
      <MemberSignature Language="C#" Value="public void Pause ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void Pause() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.Pause" />
      <MemberSignature Language="VB.NET" Value="Public Sub Pause ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void Pause();" />
      <MemberSignature Language="F#" Value="member this.Pause : unit -&gt; unit" Usage="speechSynthesizer.Pause " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Wstrzymuje <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiektu.</summary>
        <remarks>To be added.</remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.Resume" />
        <altmember cref="P:System.Speech.Synthesis.SpeechSynthesizer.State" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.StateChanged" />
      </Docs>
    </Member>
    <Member MemberName="PhonemeReached">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.PhonemeReachedEventArgs&gt; PhonemeReached;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.PhonemeReachedEventArgs&gt; PhonemeReached" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event PhonemeReached As EventHandler(Of PhonemeReachedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::PhonemeReachedEventArgs ^&gt; ^ PhonemeReached;" />
      <MemberSignature Language="F#" Value="member this.PhonemeReached : EventHandler&lt;System.Speech.Synthesis.PhonemeReachedEventArgs&gt; " Usage="member this.PhonemeReached : System.EventHandler&lt;System.Speech.Synthesis.PhonemeReachedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.PhonemeReachedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Wywoływane, gdy zostanie osiągnięty phoneme.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Phoneme jest podstawowym składnikiem napisane języka, zwykle litery alfabetu (lub kombinacja dwie litery), która reprezentuje jeden lub więcej dźwięków distinct. Na przykład litera "c" jest phoneme, który może dźwięk, takich jak "s" w "cinder" lub "k" w "catch". Word zapisany jest łączenia się podzasobów fonemów. Zmiany słów phoneme zmieni jego pisowni.  
  
 A <xref:System.Speech.Synthesis.SpeechSynthesizer> generuje wystąpienia <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached> zdarzenia dla każdej części programu word, który stanowi phoneme. Na przykład dla słowa "motywu" powoduje wygenerowanie trzy <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached> zdarzenia; dla dźwięk "th", jeden dźwięku "e", a drugi dźwięku "m" (me).  
  
 Na przykład i informacje o danych skojarzone ze zdarzeniem, zobacz <xref:System.Speech.Synthesis.PhonemeReachedEventArgs>.  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="Rate">
      <MemberSignature Language="C#" Value="public int Rate { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 Rate" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.SpeechSynthesizer.Rate" />
      <MemberSignature Language="VB.NET" Value="Public Property Rate As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int Rate { int get(); void set(int value); };" />
      <MemberSignature Language="F#" Value="member this.Rate : int with get, set" Usage="System.Speech.Synthesis.SpeechSynthesizer.Rate" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera lub ustawia współczynnik wymowy <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiektu.</summary>
        <value>Zwraca stopę wymowy <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiektu, od -10 do 10.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Poniższy przykład mówi ciąg ze wskaźnikiem wymowy ustawioną -2.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Set a value for the speaking rate.  
      synth.Rate = -2;  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Speak a text string synchronously.  
      synth.Speak("This example speaks a string with the speaking rate set to -2.");  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }     
  }    
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.PromptStyle" />
        <altmember cref="T:System.Speech.Synthesis.PromptRate" />
      </Docs>
    </Member>
    <Member MemberName="RemoveLexicon">
      <MemberSignature Language="C#" Value="public void RemoveLexicon (Uri uri);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RemoveLexicon(class System.Uri uri) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.RemoveLexicon(System.Uri)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RemoveLexicon(Uri ^ uri);" />
      <MemberSignature Language="F#" Value="member this.RemoveLexicon : Uri -&gt; unit" Usage="speechSynthesizer.RemoveLexicon uri" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="uri" Type="System.Uri" />
      </Parameters>
      <Docs>
        <param name="uri">Lokalizacja dokumentu leksykonie.</param>
        <summary>Usuwa słownika z <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Zobacz <xref:System.Speech.Synthesis.SpeechSynthesizer.AddLexicon%2A> przykład.  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.AddLexicon(System.Uri,System.String)" />
      </Docs>
    </Member>
    <Member MemberName="Resume">
      <MemberSignature Language="C#" Value="public void Resume ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void Resume() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.Resume" />
      <MemberSignature Language="VB.NET" Value="Public Sub Resume ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void Resume();" />
      <MemberSignature Language="F#" Value="member this.Resume : unit -&gt; unit" Usage="speechSynthesizer.Resume " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Wznawia <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiektu po jego wstrzymaniu.</summary>
        <remarks>To be added.</remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.Pause" />
        <altmember cref="P:System.Speech.Synthesis.SpeechSynthesizer.State" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.StateChanged" />
      </Docs>
    </Member>
    <Member MemberName="SelectVoice">
      <MemberSignature Language="C#" Value="public void SelectVoice (string name);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SelectVoice(string name) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SelectVoice (name As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SelectVoice(System::String ^ name);" />
      <MemberSignature Language="F#" Value="member this.SelectVoice : string -&gt; unit" Usage="speechSynthesizer.SelectVoice name" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="name">Nazwa głosu, aby wybrać.</param>
        <summary>Wybiera określonego głosu według nazwy.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> — metoda i <xref:System.Speech.Synthesis.VoiceInfo> klasy można uzyskać nazwy zainstalowany głosy tekst na mowę (TTS), które można wybrać. Aby wybrać głosu, Przekaż całą zawartość <xref:System.Speech.Synthesis.VoiceInfo.Name%2A> właściwość jako argument dla <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> metody. <xref:System.Speech.Synthesis.SpeechSynthesizer> Obiektu wybiera pierwszy zainstalowany głos zawierający `name` przy użyciu głosu <xref:System.Speech.Synthesis.VoiceInfo.Name%2A?displayProperty=nameWithType> właściwości. <xref:System.Speech.Synthesis.SpeechSynthesizer> Wykonuje z uwzględnieniem wielkości liter, porównanie podciąg do określenia, czy głos zgodne `name`.  
  
 Gdy aplikacja wywołuje <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, ta metoda sprawdza, czy każdy głosy znajdzie się w rejestrze spełnia określone kryteria minimalne. Wszelkie głosu Niepowodzenie weryfikacji <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> ustawia jego <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwości `False`. Aplikacji nie można wybrać głosu których <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> jest właściwość `False`. Zwykle, aplikacje nie ustawi głosu <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwości.  
  
 Aby wybrać głosu według płci, wieku lub ustawień regionalnych, użyj jednej z <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> metody.  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints(System.Speech.Synthesis.VoiceGender)" />
      </Docs>
    </Member>
    <MemberGroup MemberName="SelectVoiceByHints">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Wybiera głosu o określonej charakterystyce.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> — metoda i <xref:System.Speech.Synthesis.VoiceInfo> klasy można uzyskać nazwy zainstalowany głosy tekst na mowę (TTS), które można wybrać. <xref:System.Speech.Synthesis.SpeechSynthesizer> Obiektu wybiera pierwszy zainstalowany głos odpowiadający określonej właściwości.  
  
 Gdy aplikacja wywołuje <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, ta metoda sprawdza, czy każdy głosy znajdzie się w rejestrze spełnia określone kryteria minimalne. Wszelkie głosu Niepowodzenie weryfikacji <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> ustawia jego <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwości `False`. Aplikacji nie można wybrać głosu których <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> jest właściwość `False`. Zwykle, aplikacje nie ustawi głosu <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwości.  
  
 Aby wybrać głosu według nazwy, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> — metoda  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="SelectVoiceByHints">
      <MemberSignature Language="C#" Value="public void SelectVoiceByHints (System.Speech.Synthesis.VoiceGender gender);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SelectVoiceByHints(valuetype System.Speech.Synthesis.VoiceGender gender) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints(System.Speech.Synthesis.VoiceGender)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SelectVoiceByHints (gender As VoiceGender)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SelectVoiceByHints(System::Speech::Synthesis::VoiceGender gender);" />
      <MemberSignature Language="F#" Value="member this.SelectVoiceByHints : System.Speech.Synthesis.VoiceGender -&gt; unit" Usage="speechSynthesizer.SelectVoiceByHints gender" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
      </Parameters>
      <Docs>
        <param name="gender">Płeć głosu, aby wybrać.</param>
        <summary>Wybiera głosu z określonych płci.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> — metoda i <xref:System.Speech.Synthesis.VoiceInfo> klasy można uzyskać nazwy zainstalowany głosy tekst na mowę (TTS), które można wybrać. <xref:System.Speech.Synthesis.SpeechSynthesizer> Obiektu wybiera pierwszy zainstalowany głosu których <xref:System.Speech.Synthesis.VoiceInfo.Gender%2A> dopasowania właściwości `gender` parametru.  
  
 Gdy aplikacja wywołuje <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, ta metoda sprawdza, czy każdy głosy znajdzie się w rejestrze spełnia określone kryteria minimalne. Wszelkie głosu Niepowodzenie weryfikacji <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> ustawia jego <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwości `False`. Aplikacji nie można wybrać głosu których <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> jest właściwość `False`. Zwykle, aplikacje nie ustawi głosu <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwości.  
  
 Aby wybrać na podstawie innych charakterystyk głosu, zobacz drugi <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> metody.  
  
 Aby wybrać głosu według nazwy, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> metody.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.VoiceGender" />
        <altmember cref="T:System.Speech.Synthesis.VoiceInfo" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
      </Docs>
    </Member>
    <Member MemberName="SelectVoiceByHints">
      <MemberSignature Language="C#" Value="public void SelectVoiceByHints (System.Speech.Synthesis.VoiceGender gender, System.Speech.Synthesis.VoiceAge age);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SelectVoiceByHints(valuetype System.Speech.Synthesis.VoiceGender gender, valuetype System.Speech.Synthesis.VoiceAge age) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SelectVoiceByHints (gender As VoiceGender, age As VoiceAge)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SelectVoiceByHints(System::Speech::Synthesis::VoiceGender gender, System::Speech::Synthesis::VoiceAge age);" />
      <MemberSignature Language="F#" Value="member this.SelectVoiceByHints : System.Speech.Synthesis.VoiceGender * System.Speech.Synthesis.VoiceAge -&gt; unit" Usage="speechSynthesizer.SelectVoiceByHints (gender, age)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
        <Parameter Name="age" Type="System.Speech.Synthesis.VoiceAge" />
      </Parameters>
      <Docs>
        <param name="gender">Płeć głosu, aby wybrać.</param>
        <param name="age">Wiek głosu, aby wybrać.</param>
        <summary>Wybiera głosu z określonych płci i wiek.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> — metoda i <xref:System.Speech.Synthesis.VoiceInfo> klasy można uzyskać nazwy zainstalowany głosy tekst na mowę (TTS), które można wybrać. <xref:System.Speech.Synthesis.SpeechSynthesizer> Obiektu wybiera pierwszy zainstalowany głosu których <xref:System.Speech.Synthesis.VoiceInfo.Gender%2A> i <xref:System.Speech.Synthesis.VoiceInfo.Age%2A> dopasowania właściwości `gender` i `age` parametrów.  
  
 Gdy aplikacja wywołuje <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, ta metoda sprawdza, czy każdy głosy znajdzie się w rejestrze spełnia określone kryteria minimalne. Wszelkie głosu Niepowodzenie weryfikacji <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> ustawia jego <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwości `False`. Aplikacji nie można wybrać głosu których <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> jest właściwość `False`. Zwykle, aplikacje nie ustawi głosu <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwości.  
  
 Aby wybrać na podstawie innych charakterystyk głosu, zobacz drugi <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> metody.  
  
 Aby wybrać głosu według nazwy, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> metody.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.VoiceAge" />
        <altmember cref="T:System.Speech.Synthesis.VoiceGender" />
        <altmember cref="T:System.Speech.Synthesis.VoiceInfo" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
      </Docs>
    </Member>
    <Member MemberName="SelectVoiceByHints">
      <MemberSignature Language="C#" Value="public void SelectVoiceByHints (System.Speech.Synthesis.VoiceGender gender, System.Speech.Synthesis.VoiceAge age, int voiceAlternate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SelectVoiceByHints(valuetype System.Speech.Synthesis.VoiceGender gender, valuetype System.Speech.Synthesis.VoiceAge age, int32 voiceAlternate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SelectVoiceByHints (gender As VoiceGender, age As VoiceAge, voiceAlternate As Integer)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SelectVoiceByHints(System::Speech::Synthesis::VoiceGender gender, System::Speech::Synthesis::VoiceAge age, int voiceAlternate);" />
      <MemberSignature Language="F#" Value="member this.SelectVoiceByHints : System.Speech.Synthesis.VoiceGender * System.Speech.Synthesis.VoiceAge * int -&gt; unit" Usage="speechSynthesizer.SelectVoiceByHints (gender, age, voiceAlternate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
        <Parameter Name="age" Type="System.Speech.Synthesis.VoiceAge" />
        <Parameter Name="voiceAlternate" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="gender">Płeć głosu, aby wybrać.</param>
        <param name="age">Wiek głosu, aby wybrać.</param>
        <param name="voiceAlternate">Pozycja głosu, aby wybrać.</param>
        <summary>Wybiera głosu z określonych płci i wiek, na podstawie położenia, w którym głosy są uporządkowane.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> — metoda i <xref:System.Speech.Synthesis.VoiceInfo> klasy można uzyskać nazwy zainstalowany głosy tekst na mowę (TTS), które można wybrać. <xref:System.Speech.Synthesis.SpeechSynthesizer> Obiekt voices wyszukuje zainstalowane, którego <xref:System.Speech.Synthesis.VoiceInfo.Gender%2A> i <xref:System.Speech.Synthesis.VoiceInfo.Age%2A> dopasowania właściwości `gender` i `age` parametrów. <xref:System.Speech.Synthesis.SpeechSynthesizer> Liczby dopasowań wyszukuje i zwraca głosu, gdy liczba jest równa `voiceAlternate` parametru.  
  
 Gdy aplikacja wywołuje <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, ta metoda sprawdza, czy każdy głosy znajdzie się w rejestrze spełnia określone kryteria minimalne. Wszelkie głosu Niepowodzenie weryfikacji <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> ustawia jego <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwości `False`. Aplikacji nie można wybrać głosu których <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> jest właściwość `False`. Zwykle, aplikacje nie ustawi głosu <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwości.  
  
 Aby wybrać na podstawie innych charakterystyk głosu, zobacz drugi <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> przeciążenia.  
  
 Aby wybrać głosu według nazwy, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> metody.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.VoiceAge" />
        <altmember cref="T:System.Speech.Synthesis.VoiceGender" />
        <altmember cref="T:System.Speech.Synthesis.VoiceInfo" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
      </Docs>
    </Member>
    <Member MemberName="SelectVoiceByHints">
      <MemberSignature Language="C#" Value="public void SelectVoiceByHints (System.Speech.Synthesis.VoiceGender gender, System.Speech.Synthesis.VoiceAge age, int voiceAlternate, System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SelectVoiceByHints(valuetype System.Speech.Synthesis.VoiceGender gender, valuetype System.Speech.Synthesis.VoiceAge age, int32 voiceAlternate, class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge,System.Int32,System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SelectVoiceByHints (gender As VoiceGender, age As VoiceAge, voiceAlternate As Integer, culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SelectVoiceByHints(System::Speech::Synthesis::VoiceGender gender, System::Speech::Synthesis::VoiceAge age, int voiceAlternate, System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.SelectVoiceByHints : System.Speech.Synthesis.VoiceGender * System.Speech.Synthesis.VoiceAge * int * System.Globalization.CultureInfo -&gt; unit" Usage="speechSynthesizer.SelectVoiceByHints (gender, age, voiceAlternate, culture)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
        <Parameter Name="age" Type="System.Speech.Synthesis.VoiceAge" />
        <Parameter Name="voiceAlternate" Type="System.Int32" />
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="gender">Płeć głosu, aby wybrać.</param>
        <param name="age">Wiek głosu, aby wybrać.</param>
        <param name="voiceAlternate">Pozycja głosu, aby wybrać.</param>
        <param name="culture">Ustawienia regionalne głosu, aby wybrać.</param>
        <summary>Wybiera głosu określonych płci, wieku i ustawień regionalnych, na podstawie położenia, w którym głosy są uporządkowane.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Synthesis.SpeechSynthesizer> Obiektu znajduje voices, którego <xref:System.Speech.Synthesis.VoiceInfo.Gender%2A>, <xref:System.Speech.Synthesis.VoiceInfo.Age%2A>, i <xref:System.Speech.Synthesis.VoiceInfo.Culture%2A> dopasowania właściwości `gender`, `age`, i `culture` parametrów. <xref:System.Speech.Synthesis.SpeechSynthesizer> Liczby dopasowań wyszukuje i zwraca głosu, gdy liczba jest równa `voiceAlternate` parametru.  
  
 Microsoft Windows i interfejsu API System.Speech zaakceptować wszystkie prawidłowe kody języka kraju. Aby wykonać tekst na mowę, przy użyciu języka określonego w `culture` parametr, aparat syntezy mowy, który obsługuje kod kraju język musi być zainstalowany. Aparaty syntezy dostarczonych z programem Microsoft Windows 7 pracować z następujących kodów kraju języka:  
  
-   en-US. Angielski (Stany Zjednoczone)  
  
-   zh-CN. Chiński (Chiny)  
  
-   zh-TW. Chiński (Tajwan)  
  
 Dozwolone są również kodów dwuliterowych języka na przykład "en".  
  
 Gdy aplikacja wywołuje <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, ta metoda sprawdza, czy każdy głosy znajdzie się w rejestrze spełnia określone kryteria minimalne. Wszelkie głosu Niepowodzenie weryfikacji <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> ustawia jego <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwości `False`. Aplikacji nie można wybrać głosu których <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> jest właściwość `False`. Zwykle, aplikacje nie ustawi głosu <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> właściwości.  
  
 Aby wybrać na podstawie innych charakterystyk głosu, zobacz drugi <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> przeciążenia.  
  
 Aby wybrać głosu według nazwy, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> metody.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Globalization.CultureInfo" />
        <altmember cref="T:System.Speech.Synthesis.VoiceAge" />
        <altmember cref="T:System.Speech.Synthesis.VoiceGender" />
        <altmember cref="T:System.Speech.Synthesis.VoiceInfo" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
      </Docs>
    </Member>
    <Member MemberName="SetOutputToAudioStream">
      <MemberSignature Language="C#" Value="public void SetOutputToAudioStream (System.IO.Stream audioDestination, System.Speech.AudioFormat.SpeechAudioFormatInfo formatInfo);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetOutputToAudioStream(class System.IO.Stream audioDestination, class System.Speech.AudioFormat.SpeechAudioFormatInfo formatInfo) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetOutputToAudioStream (audioDestination As Stream, formatInfo As SpeechAudioFormatInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetOutputToAudioStream(System::IO::Stream ^ audioDestination, System::Speech::AudioFormat::SpeechAudioFormatInfo ^ formatInfo);" />
      <MemberSignature Language="F#" Value="member this.SetOutputToAudioStream : System.IO.Stream * System.Speech.AudioFormat.SpeechAudioFormatInfo -&gt; unit" Usage="speechSynthesizer.SetOutputToAudioStream (audioDestination, formatInfo)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audioDestination" Type="System.IO.Stream" />
        <Parameter Name="formatInfo" Type="System.Speech.AudioFormat.SpeechAudioFormatInfo" />
      </Parameters>
      <Docs>
        <param name="audioDestination">Strumień, do którego jest dołączany syntezy danych wyjściowych.</param>
        <param name="formatInfo">Format danych wyjściowych syntezy.</param>
        <summary>Konfiguruje <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiekt można dołączyć dane wyjściowe do strumienia audio.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Wywołanie <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A> zwolnienia <xref:System.Speech.Synthesis.SpeechSynthesizer>przez odwołanie do strumienia.  
  
 Dla opcji konfiguracji, zobacz <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile%2A>, i <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream%2A> metody.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="SetOutputToDefaultAudioDevice">
      <MemberSignature Language="C#" Value="public void SetOutputToDefaultAudioDevice ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetOutputToDefaultAudioDevice() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetOutputToDefaultAudioDevice ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetOutputToDefaultAudioDevice();" />
      <MemberSignature Language="F#" Value="member this.SetOutputToDefaultAudioDevice : unit -&gt; unit" Usage="speechSynthesizer.SetOutputToDefaultAudioDevice " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Konfiguruje <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiekt do wysyłania danych wyjściowych do domyślnego urządzenia audio.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Można użyć **dźwięk** okna w systemie Windows **Panelu sterowania** do konfigurowania domyślnego urządzenia audio dla komputera.  
  
 Dla opcji konfiguracji, zobacz <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile%2A>, i <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream%2A> metody.  
  
   
  
## Examples  
 W poniższym przykładzie użyto Syntezator porozmawiać frazę do domyślnego wyjścia audio.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the speech synthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the synthesizer to send output to the default audio device.  
        synth.SetOutputToDefaultAudioDevice();  
  
        // Speak a phrase.  
        synth.Speak("This is sample text-to-speech output.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="SetOutputToNull">
      <MemberSignature Language="C#" Value="public void SetOutputToNull ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetOutputToNull() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetOutputToNull ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetOutputToNull();" />
      <MemberSignature Language="F#" Value="member this.SetOutputToNull : unit -&gt; unit" Usage="speechSynthesizer.SetOutputToNull " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Konfiguruje <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiekt, aby nie wysyłał danych wyjściowych z operacji syntezy do urządzenia, pliku lub strumienia.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ta metoda służy do wersji <xref:System.Speech.Synthesis.SpeechSynthesizer> przez odwołanie do pliku lub strumienia. Zobacz <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream%2A> przykład.  
  
 Dla opcji konfiguracji, zobacz <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile%2A>, i <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream%2A> metody.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="SetOutputToWaveFile">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Konfiguruje <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiekt, aby dołączyć dane wyjściowe do pliku fali audio format.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aby zwolnić <xref:System.Speech.Synthesis.SpeechSynthesizer>przez odwołanie do pliku, należy ponownie skonfigurować <xref:System.Speech.Synthesis.SpeechSynthesizer>danych wyjściowych, na przykład wywołując <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A>.  
  
 Dla opcji konfiguracji, zobacz <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A>, i <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream%2A> metody.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="SetOutputToWaveFile">
      <MemberSignature Language="C#" Value="public void SetOutputToWaveFile (string path);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetOutputToWaveFile(string path) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetOutputToWaveFile (path As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetOutputToWaveFile(System::String ^ path);" />
      <MemberSignature Language="F#" Value="member this.SetOutputToWaveFile : string -&gt; unit" Usage="speechSynthesizer.SetOutputToWaveFile path" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="path" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="path">Ścieżka do pliku.</param>
        <summary>Konfiguruje <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiekt, aby dołączyć dane wyjściowe do pliku, który zawiera fali format audio.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aby skonfigurować dane wyjściowe oraz określić audio format, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile%2A> metody.  
  
   
  
## Examples  
 W poniższym przykładzie użyto wystąpienia <xref:System.Media.SoundPlayer> do wiersza, który został dane wyjściowe do pliku wav odtwarzania. Ponieważ <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> wywołanie jest asynchroniczne, <xref:System.Media.SoundPlayer> jest tworzone wystąpienie (i <xref:System.Media.SoundPlayer.Play%2A> metoda wywoływana) dla programu obsługi <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted> zdarzeń.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToWaveFile(@"C:\Test\Sample.wav");  
  
      // Register for the SpeakCompleted event.  
      synth.SpeakCompleted += new EventHandler<SpeakCompletedEventArgs>(synth_SpeakCompleted);  
  
      // Build a prompt.  
      PromptBuilder builder = new PromptBuilder();  
      builder.AppendText("This sample asynchronously speaks a prompt to a WAVE file.");  
  
      // Speak the string asynchronously.  
      synth.SpeakAsync(builder);  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeakCompleted event.  
    static void synth_SpeakCompleted(object sender, SpeakCompletedEventArgs e)  
    {  
  
      // Create a SoundPlayer instance to play the output audio file.  
      System.Media.SoundPlayer m_SoundPlayer =  
        new System.Media.SoundPlayer(@"C:\Test\Sample.wav");  
  
      //  Play the output file.  
      m_SoundPlayer.Play();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream(System.IO.Stream)" />
      </Docs>
    </Member>
    <Member MemberName="SetOutputToWaveFile">
      <MemberSignature Language="C#" Value="public void SetOutputToWaveFile (string path, System.Speech.AudioFormat.SpeechAudioFormatInfo formatInfo);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetOutputToWaveFile(string path, class System.Speech.AudioFormat.SpeechAudioFormatInfo formatInfo) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile(System.String,System.Speech.AudioFormat.SpeechAudioFormatInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetOutputToWaveFile (path As String, formatInfo As SpeechAudioFormatInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetOutputToWaveFile(System::String ^ path, System::Speech::AudioFormat::SpeechAudioFormatInfo ^ formatInfo);" />
      <MemberSignature Language="F#" Value="member this.SetOutputToWaveFile : string * System.Speech.AudioFormat.SpeechAudioFormatInfo -&gt; unit" Usage="speechSynthesizer.SetOutputToWaveFile (path, formatInfo)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="path" Type="System.String" />
        <Parameter Name="formatInfo" Type="System.Speech.AudioFormat.SpeechAudioFormatInfo" />
      </Parameters>
      <Docs>
        <param name="path">Ścieżka do pliku.</param>
        <param name="formatInfo">Informacje audio format.</param>
        <summary>Konfiguruje <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiekt, aby dołączyć dane wyjściowe do pliku fali audio format w określonym formacie.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Poniższy przykład określa format danych wyjściowych syntezy mowy i wysyła je do pliku WAV.  
  
```csharp  
using System;  
using System.IO;  
using System.Speech.Synthesis;  
using System.Speech.AudioFormat;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\temp\test.wav",   
          new SpeechAudioFormatInfo(32000, AudioBitsPerSample.Sixteen, AudioChannel.Mono));  
  
        // Create a SoundPlayer instance to play output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =   
          new System.Media.SoundPlayer(@"C:\temp\test.wav");  
  
        // Build a prompt.  
        PromptBuilder builder = new PromptBuilder();  
        builder.AppendText("This is sample output to a WAVE file.");  
  
        // Speak the prompt.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream(System.IO.Stream)" />
      </Docs>
    </Member>
    <Member MemberName="SetOutputToWaveStream">
      <MemberSignature Language="C#" Value="public void SetOutputToWaveStream (System.IO.Stream audioDestination);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetOutputToWaveStream(class System.IO.Stream audioDestination) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream(System.IO.Stream)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetOutputToWaveStream (audioDestination As Stream)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetOutputToWaveStream(System::IO::Stream ^ audioDestination);" />
      <MemberSignature Language="F#" Value="member this.SetOutputToWaveStream : System.IO.Stream -&gt; unit" Usage="speechSynthesizer.SetOutputToWaveStream audioDestination" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audioDestination" Type="System.IO.Stream" />
      </Parameters>
      <Docs>
        <param name="audioDestination">Strumień, do którego jest dołączany syntezy danych wyjściowych.</param>
        <summary>Konfiguruje <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiekt, aby dołączyć dane wyjściowe do strumienia, który zawiera fali format audio.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aby zwolnić <xref:System.Speech.Synthesis.SpeechSynthesizer>przez odwołanie w strumieniu ponownej konfiguracji Syntezator danych wyjściowych, na przykład wywołując <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A>.  
  
 Dla opcji konfiguracji, zobacz <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A>, i <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile%2A> metody.  
  
   
  
## Examples  
 Poniższy przykład danych wyjściowych frazę do strumienia WAV.  
  
```csharp  
using System;  
using System.IO;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the speech synthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      using (MemoryStream stream = new MemoryStream())  
      {  
  
        // Create a SoundPlayer instance to play the output audio file.  
        MemoryStream streamAudio = new MemoryStream();  
        System.Media.SoundPlayer m_SoundPlayer = new System.Media.SoundPlayer();  
  
        // Configure the synthesizer to output to an audio stream.  
        synth.SetOutputToWaveStream(streamAudio);  
  
        // Speak a phrase.  
        synth.Speak("This is sample text-to-speech output.");  
        streamAudio.Position = 0;  
        m_SoundPlayer.Stream = streamAudio;  
        m_SoundPlayer.Play();  
  
        // Set the synthesizer output to null to release the stream.   
        synth.SetOutputToNull();  
  
        // Insert code to persist or process the stream contents here.  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="Speak">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Generuje mowie synchronicznie z ciągu, <see cref="T:System.Speech.Synthesis.Prompt" /> obiekt, lub <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> Metody generują mowy synchronicznie. Dopóki zawartość nie mają metod <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> całkowicie wymawiany instancji. Jest to najprostszy sposób generowania mowy. Jednak jeśli aplikacja wymaga do wykonywania zadań podczas trwania mowy, na przykład wyróżnianie tekstu, paint animacji, formanty monitora lub innych zadań, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> metody lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> do generowania mowy asynchronicznie.  
  
 Podczas wywoływania tej metody <xref:System.Speech.Synthesis.SpeechSynthesizer> może wiązać się z następujących zdarzeń:  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.StateChanged>. Uruchamiany po zmianie stanu syntezatora mowy.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted>. Wywoływane, gdy rozpoczyna syntezatora mowy generowania.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached>. Wywoływane zawsze, gdy osiągnie Syntezator literą lub kombinacją liter stanowią niejawnego dźwięk mowy w języku.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress>. Podnoszony, zawsze Syntezator kończy się mówiąc wyrazu.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached>. Wywoływane każdorazowo rozmowy dane wyjściowe wymaga zmiany w położeniu ujścia lub mięśni twarzy użyta do wyprodukowania mowy.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached>. Wywoływane, gdy praca syntezatora napotka zakładki w wierszu.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange>. Wywoływane, gdy zmienia się delikatnego głosu dla Syntezator.  
  
 <xref:System.Speech.Synthesis.SpeechSynthesizer> Nie zgłaszał <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted> zdarzenia podczas przetwarzania wszystkich <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> metody.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="Speak">
      <MemberSignature Language="C#" Value="public void Speak (System.Speech.Synthesis.Prompt prompt);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void Speak(class System.Speech.Synthesis.Prompt prompt) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.Speak(System.Speech.Synthesis.Prompt)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void Speak(System::Speech::Synthesis::Prompt ^ prompt);" />
      <MemberSignature Language="F#" Value="member this.Speak : System.Speech.Synthesis.Prompt -&gt; unit" Usage="speechSynthesizer.Speak prompt" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="prompt" Type="System.Speech.Synthesis.Prompt" />
      </Parameters>
      <Docs>
        <param name="prompt">Zawartość do mowy.</param>
        <summary>Synchronicznie mówi zawartość <see cref="T:System.Speech.Synthesis.Prompt" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Asynchronicznie porozmawiać zawartość <xref:System.Speech.Synthesis.Prompt> obiektów, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A>.  
  
   
  
## Examples  
 Poniższy przykład tworzy <xref:System.Speech.Synthesis.Prompt> obiekt z ciągu i przekazuje obiekt jako argument <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> metody.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a prompt from a string.  
        Prompt color = new Prompt("What is your favorite color?");  
  
        // Speak the contents of the prompt synchronously.  
        synth.Speak(color);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="Speak">
      <MemberSignature Language="C#" Value="public void Speak (System.Speech.Synthesis.PromptBuilder promptBuilder);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void Speak(class System.Speech.Synthesis.PromptBuilder promptBuilder) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.Speak(System.Speech.Synthesis.PromptBuilder)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void Speak(System::Speech::Synthesis::PromptBuilder ^ promptBuilder);" />
      <MemberSignature Language="F#" Value="member this.Speak : System.Speech.Synthesis.PromptBuilder -&gt; unit" Usage="speechSynthesizer.Speak promptBuilder" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="promptBuilder" Type="System.Speech.Synthesis.PromptBuilder" />
      </Parameters>
      <Docs>
        <param name="promptBuilder">Zawartość do mowy.</param>
        <summary>Synchronicznie mówi zawartość <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Asynchronicznie porozmawiać zawartość <xref:System.Speech.Synthesis.PromptBuilder> obiektów, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A>.  
  
   
  
## Examples  
 Poniższy przykład tworzy <xref:System.Speech.Synthesis.PromptBuilder> obiekt z ciągu i przekazuje obiekt jako argument <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> metody.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and append a text string.  
        PromptBuilder song = new PromptBuilder();  
        song.AppendText("Say the name of the song you want to hear");  
  
        // Speak the contents of the prompt synchronously.  
        synth.Speak(song);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="Speak">
      <MemberSignature Language="C#" Value="public void Speak (string textToSpeak);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void Speak(string textToSpeak) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.Speak(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub Speak (textToSpeak As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void Speak(System::String ^ textToSpeak);" />
      <MemberSignature Language="F#" Value="member this.Speak : string -&gt; unit" Usage="speechSynthesizer.Speak textToSpeak" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Tekst, który mowy.</param>
        <summary>Synchronicznie mówi zawartość ciągu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aby synchronicznie mowy ciąg, który zawiera SSML znaczników, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A> metody. Asynchronicznie porozmawiać zawartość ciągu, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> metody.  
  
   
  
## Examples  
 Jak pokazano w poniższym przykładzie <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> metoda zapewnia najprostszy sposób generowania danych wyjściowych synchronicznie mowy.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Speak a string synchronously.  
        synth.Speak("What is your favorite color?");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <MemberGroup MemberName="SpeakAsync">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Asynchronicznie generuje mowie z ciągu, <see cref="T:System.Speech.Synthesis.Prompt" /> obiekt, lub <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> Metody generują mowy asynchronicznie. Metody zwrócić się natychmiast bez oczekiwania na zawartość <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> obiekt, aby zakończyć, mówiąc. Użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> Jeśli aplikacja wymaga wykonywać zadania podczas trwania mowy, zaznacz tekst, na przykład, malowanie animacji, formanty monitora lub innych zadań.  
  
 Podczas wywoływania tej metody <xref:System.Speech.Synthesis.SpeechSynthesizer> może wiązać się z następujących zdarzeń:  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.StateChanged>. Uruchamiany po zmianie stanu syntezatora mowy.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted>. Wywoływane, gdy rozpoczyna syntezatora mowy generowania.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached>. Wywoływane zawsze, gdy osiągnie Syntezator literą lub kombinacją liter stanowią niejawnego dźwięk mowy w języku.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress>. Podnoszony, zawsze Syntezator kończy się mówiąc wyrazu.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached>. Wywoływane każdorazowo rozmowy dane wyjściowe wymaga zmiany w położeniu ujścia lub mięśni twarzy użyta do wyprodukowania mowy.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached>. Wywoływane, gdy praca syntezatora napotka zakładki w wierszu.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange>. Wywoływane, gdy zmienia się delikatnego głosu dla Syntezator.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted>. Wywoływane, gdy praca syntezatora zakończy <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> operacji.  
  
 Jeśli aplikacja nie trzeba wykonywać zadań podczas trwania mowy, możesz użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> metody lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A> do generowania mowy synchronicznie.  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.StateChanged" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange" />
      </Docs>
    </MemberGroup>
    <Member MemberName="SpeakAsync">
      <MemberSignature Language="C#" Value="public void SpeakAsync (System.Speech.Synthesis.Prompt prompt);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SpeakAsync(class System.Speech.Synthesis.Prompt prompt) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync(System.Speech.Synthesis.Prompt)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SpeakAsync(System::Speech::Synthesis::Prompt ^ prompt);" />
      <MemberSignature Language="F#" Value="member this.SpeakAsync : System.Speech.Synthesis.Prompt -&gt; unit" Usage="speechSynthesizer.SpeakAsync prompt" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="prompt" Type="System.Speech.Synthesis.Prompt" />
      </Parameters>
      <Docs>
        <param name="prompt">Zawartość do mowy.</param>
        <summary>Asynchronicznie mówi zawartość <see cref="T:System.Speech.Synthesis.Prompt" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Możesz anulować asynchroniczne mówiąc monitu o <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancel%2A> lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancelAll%2A> metody.  
  
 Synchronicznie porozmawiać zawartość <xref:System.Speech.Synthesis.Prompt> obiektów, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A>.  
  
   
  
## Examples  
 Poniższy przykład tworzy <xref:System.Speech.Synthesis.Prompt> obiekt z ciągu i przekazuje obiekt jako argument <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> metody.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Create a prompt from a string.  
      Prompt color = new Prompt("What is your favorite color?");  
  
      // Speak the contents of the prompt asynchronously.  
      synth.SpeakAsync(color);  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="SpeakAsync">
      <MemberSignature Language="C#" Value="public System.Speech.Synthesis.Prompt SpeakAsync (System.Speech.Synthesis.PromptBuilder promptBuilder);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Synthesis.Prompt SpeakAsync(class System.Speech.Synthesis.PromptBuilder promptBuilder) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync(System.Speech.Synthesis.PromptBuilder)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Synthesis::Prompt ^ SpeakAsync(System::Speech::Synthesis::PromptBuilder ^ promptBuilder);" />
      <MemberSignature Language="F#" Value="member this.SpeakAsync : System.Speech.Synthesis.PromptBuilder -&gt; System.Speech.Synthesis.Prompt" Usage="speechSynthesizer.SpeakAsync promptBuilder" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Synthesis.Prompt</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="promptBuilder" Type="System.Speech.Synthesis.PromptBuilder" />
      </Parameters>
      <Docs>
        <param name="promptBuilder">Zawartość do mowy.</param>
        <summary>Asynchronicznie mówi zawartość <see cref="T:System.Speech.Synthesis.PromptBuilder" /> obiektu.</summary>
        <returns>Zwraca obiekt, który zawiera zawartość do mowy.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Synchronicznie porozmawiać zawartość <xref:System.Speech.Synthesis.PromptBuilder> obiektów, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A>.  
  
   
  
## Examples  
 Poniższy przykład tworzy <xref:System.Speech.Synthesis.PromptBuilder> obiekt z ciągu i przekazuje obiekt jako argument <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> metody.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Create a PromptBuilder object and append a text string.  
      PromptBuilder song = new PromptBuilder();  
      song.AppendText("Say the name of the song you want to hear");  
  
      // Speak the contents of the prompt asynchronously.  
      synth.SpeakAsync(song);  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="SpeakAsync">
      <MemberSignature Language="C#" Value="public System.Speech.Synthesis.Prompt SpeakAsync (string textToSpeak);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Synthesis.Prompt SpeakAsync(string textToSpeak) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Function SpeakAsync (textToSpeak As String) As Prompt" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Synthesis::Prompt ^ SpeakAsync(System::String ^ textToSpeak);" />
      <MemberSignature Language="F#" Value="member this.SpeakAsync : string -&gt; System.Speech.Synthesis.Prompt" Usage="speechSynthesizer.SpeakAsync textToSpeak" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Synthesis.Prompt</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Tekst, który mowy.</param>
        <summary>Asynchronicznie mówi zawartość ciągu.</summary>
        <returns>Zwraca obiekt, który zawiera zawartość do mowy.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Asynchronicznie porozmawiać ciąg, który zawiera SSML znaczników, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> metody. Synchronicznie porozmawiać zawartość ciągu, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> metody. Możesz anulować asynchroniczne mówiąc monitu o <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancel%2A> lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancelAll%2A> metody.  
  
   
  
## Examples  
 Jak pokazano w poniższym przykładzie <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> metoda zapewnia najprostszy sposób generowania danych wyjściowych asynchronicznie mowy.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Speak a string asynchronously.  
      synth.SpeakAsync("What is your favorite color?");  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="Overload:System.Speech.Synthesis.SpeechSynthesizer.Speak" />
      </Docs>
    </Member>
    <Member MemberName="SpeakAsyncCancel">
      <MemberSignature Language="C#" Value="public void SpeakAsyncCancel (System.Speech.Synthesis.Prompt prompt);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SpeakAsyncCancel(class System.Speech.Synthesis.Prompt prompt) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancel(System.Speech.Synthesis.Prompt)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SpeakAsyncCancel(System::Speech::Synthesis::Prompt ^ prompt);" />
      <MemberSignature Language="F#" Value="member this.SpeakAsyncCancel : System.Speech.Synthesis.Prompt -&gt; unit" Usage="speechSynthesizer.SpeakAsyncCancel prompt" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="prompt" Type="System.Speech.Synthesis.Prompt" />
      </Parameters>
      <Docs>
        <param name="prompt">Zawartość, do których chcesz anulować operację speak.</param>
        <summary>Anuluje operację asynchroniczną syntezy dla wiersza w kolejce.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ta metoda również służy do anulowania asynchronicznego mowy operacji dla następujących:  
  
-   Zawartość <xref:System.String> określonego przez <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A?displayProperty=nameWithType> metody.  
  
-   Zawartość <xref:System.Speech.Synthesis.PromptBuilder> określonego przez <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A?displayProperty=nameWithType> metody.  
  
-   Zawartość <xref:System.String> zawierających określony przez SSML <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> metody.  
  
 Podczas wywoływania <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A?displayProperty=nameWithType>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A?displayProperty=nameWithType>, lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A>, tworzy System.Speech <xref:System.Speech.Synthesis.Prompt> obiektu i wypełnia zawartość parametru metody i zwraca <xref:System.Speech.Synthesis.Prompt> obiektu. Aby zachować kopię zwróconego <xref:System.Speech.Synthesis.Prompt>, można przekazać go do <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancel%2A> anulować wymowy zawartości określonych w <xref:System.String> lub <xref:System.Speech.Synthesis.PromptBuilder> obiektu.  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="SpeakAsyncCancelAll">
      <MemberSignature Language="C#" Value="public void SpeakAsyncCancelAll ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SpeakAsyncCancelAll() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancelAll" />
      <MemberSignature Language="VB.NET" Value="Public Sub SpeakAsyncCancelAll ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SpeakAsyncCancelAll();" />
      <MemberSignature Language="F#" Value="member this.SpeakAsyncCancelAll : unit -&gt; unit" Usage="speechSynthesizer.SpeakAsyncCancelAll " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Umożliwia anulowanie operacji syntezy wszystkich umieszczonych w kolejce, asynchroniczny, mowy.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Poniższy przykład Pokaż korzystanie z <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancelAll%2A> anulować asynchroniczne mówiąc wiersza, tak, aby może być wymawiane nowego wiersza. Należy pamiętać, że <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted> Zdarzenie uruchamiane w przypadku <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> operacja została anulowana.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
using System.Threading;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Subscribe to the StateChanged event.  
      synth.StateChanged += new EventHandler<StateChangedEventArgs>(synth_StateChanged);  
  
      // Subscribe to the SpeakProgress event.  
      synth.SpeakProgress += new EventHandler<SpeakProgressEventArgs>(synth_SpeakProgress);  
  
      // Subscribe to the SpeakCompleted event.  
      synth.SpeakCompleted += new EventHandler<SpeakCompletedEventArgs>(synth_SpeakCompleted);  
  
      // Begin speaking a text string asynchronously.  
      synth.SpeakAsync("Speech is an effective and natural way for people to interact with applications, " +  
        "complementing or even replacing the use of mice, keyboards, controllers, and gestures.");  
  
      // Speak for four seconds.  
      Thread.Sleep(4000);  
  
      // Cancel the SpeakAsync operation and wait one second.  
      synth.SpeakAsyncCancelAll();  
      Thread.Sleep(1000);  
  
      // Speak a new text string.  
      synth.Speak("An urgent email message has arrived. Do you want to hear it?");  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Write to the console when the SpeakAsync operation has been cancelled.  
    static void synth_SpeakCompleted(object sender, SpeakCompletedEventArgs e)  
    {  
      Console.WriteLine("\nThe SpeakAsync operation was cancelled!!");  
    }  
  
    // When it changes, write the state of the SpeechSynthesizer to the console.  
    static void synth_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      Console.WriteLine("\nSynthesizer State: {0}    Previous State: {1}\n", e.State, e.PreviousState);  
    }  
  
    // Write the text being spoken by the SpeechSynthesizer to the console.  
    static void synth_SpeakProgress(object sender, SpeakProgressEventArgs e)  
    {  
      Console.WriteLine(e.Text);  
    }      
  }    
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="SpeakCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.SpeakCompletedEventArgs&gt; SpeakCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.SpeakCompletedEventArgs&gt; SpeakCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeakCompleted As EventHandler(Of SpeakCompletedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::SpeakCompletedEventArgs ^&gt; ^ SpeakCompleted;" />
      <MemberSignature Language="F#" Value="member this.SpeakCompleted : EventHandler&lt;System.Speech.Synthesis.SpeakCompletedEventArgs&gt; " Usage="member this.SpeakCompleted : System.EventHandler&lt;System.Speech.Synthesis.SpeakCompletedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.SpeakCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Wywoływane, gdy <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> zakończeniu mówiąc monit.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Synthesis.SpeechSynthesizer> Zgłasza <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted> zdarzeń po zakończeniu tych <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> metody.  
  
 <xref:System.Speech.Synthesis.SpeakCompletedEventArgs> Klasa nie ma właściwości i zwraca dane z <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted> zdarzeń. Umożliwia autorom aplikacji do obsługi zdarzeń dla zapisu jest podana <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted> zdarzeń.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.SpeakCompletedEventArgs" />
      </Docs>
    </Member>
    <Member MemberName="SpeakProgress">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.SpeakProgressEventArgs&gt; SpeakProgress;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.SpeakProgressEventArgs&gt; SpeakProgress" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeakProgress As EventHandler(Of SpeakProgressEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::SpeakProgressEventArgs ^&gt; ^ SpeakProgress;" />
      <MemberSignature Language="F#" Value="member this.SpeakProgress : EventHandler&lt;System.Speech.Synthesis.SpeakProgressEventArgs&gt; " Usage="member this.SpeakProgress : System.EventHandler&lt;System.Speech.Synthesis.SpeakProgressEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.SpeakProgressEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Zgłoszono po <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> mówi każdego pojedynczego wyrazu monit.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Synthesis.SpeechSynthesizer> Zgłasza to zdarzenie dla każdego nowego wyrazu, który obsługuje monit przy użyciu dowolnego <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A>, lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> metody. Na przykład i więcej informacji na temat dane skojarzone ze zdarzeniem, zobacz <xref:System.Speech.Synthesis.SpeakProgressEventArgs>.  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="SpeakSsml">
      <MemberSignature Language="C#" Value="public void SpeakSsml (string textToSpeak);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SpeakSsml(string textToSpeak) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SpeakSsml (textToSpeak As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SpeakSsml(System::String ^ textToSpeak);" />
      <MemberSignature Language="F#" Value="member this.SpeakSsml : string -&gt; unit" Usage="speechSynthesizer.SpeakSsml textToSpeak" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Ciąg SSML mowy.</param>
        <summary>Synchronicznie mówi <see cref="T:System.String" /> zawierający znaczników SSML.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Zawartość `textToSpeak` musi zawierać parametr `speak` element i musi być zgodna z [mowy syntezy Markup Language (SSML) w wersji 1.0](http://go.microsoft.com/fwlink/?LinkId=201763). Aby uzyskać więcej informacji, zobacz [mowy syntezy Markup Language Reference](http://msdn.microsoft.com/library/0c51279e-84d2-4f73-a924-8832039abf94).  
  
 Asynchronicznie porozmawiać ciąg, który zawiera SSML znaczników, użyj <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> metody. Można użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> zainicjować synchroniczne mówiąc ciągu, który nie zawiera znacznika SSML.  
  
 Podczas wywoływania tej metody <xref:System.Speech.Synthesis.SpeechSynthesizer> może wiązać się z następujących zdarzeń:  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.StateChanged>. Uruchamiany po zmianie stanu syntezatora mowy.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted>. Wywoływane, gdy rozpoczyna syntezatora mowy generowania.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached>. Wywoływane zawsze, gdy osiągnie Syntezator literą lub kombinacją liter stanowią niejawnego dźwięk mowy w języku.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress>. Podnoszony, zawsze Syntezator kończy się mówiąc wyrazu.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached>. Wywoływane każdorazowo rozmowy dane wyjściowe wymaga zmiany w położeniu ujścia lub mięśni twarzy użyta do wyprodukowania mowy.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached>. Wywoływane, gdy praca syntezatora napotka zakładki w wierszu.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange>. Wywoływane, gdy zmienia się delikatnego głosu dla Syntezator.  
  
 <xref:System.Speech.Synthesis.SpeechSynthesizer> Nie zgłaszał <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted> zdarzenia podczas przetwarzania <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A> metody.  
  
   
  
## Examples  
 Poniższy przykład powoduje daty 1/29/2009 jako data, miesiąc, dzień, kolejności roku.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Build an SSML prompt in a string.  
      string str = "<speak version=\"1.0\"";  
      str += " xmlns=\"http://www.w3.org/2001/10/synthesis\"";  
      str += " xml:lang=\"en-US\">";  
      str += "<say-as type=\"date:mdy\"> 1/29/2009 </say-as>";  
      str += "</speak>";  
  
      // Speak the contents of the prompt asynchronously.  
      synth.SpeakSsml(str);  
  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="SpeakSsmlAsync">
      <MemberSignature Language="C#" Value="public System.Speech.Synthesis.Prompt SpeakSsmlAsync (string textToSpeak);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Synthesis.Prompt SpeakSsmlAsync(string textToSpeak) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Function SpeakSsmlAsync (textToSpeak As String) As Prompt" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Synthesis::Prompt ^ SpeakSsmlAsync(System::String ^ textToSpeak);" />
      <MemberSignature Language="F#" Value="member this.SpeakSsmlAsync : string -&gt; System.Speech.Synthesis.Prompt" Usage="speechSynthesizer.SpeakSsmlAsync textToSpeak" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Synthesis.Prompt</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Kod znaczników SMML mowy.</param>
        <summary>Asynchronicznie mówi <see cref="T:System.String" /> zawierający znaczników SSML.</summary>
        <returns>To be added.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Zawartość `textToSpeak` musi zawierać parametr `speak` element i musi być zgodna z [mowy syntezy Markup Language (SSML) w wersji 1.0](http://go.microsoft.com/fwlink/?LinkId=201763). Aby uzyskać więcej informacji, zobacz [mowy syntezy Markup Language Reference](http://msdn.microsoft.com/library/0c51279e-84d2-4f73-a924-8832039abf94).  
  
 Aby synchronicznie mowy ciąg, który zawiera SSML znaczników, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A> metody. Można użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> zainicjować asynchronicznego mówiąc ciągu, który nie zawiera znacznika SSML.  
  
 Podczas wywoływania tej metody <xref:System.Speech.Synthesis.SpeechSynthesizer> może wiązać się z następujących zdarzeń:  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.StateChanged>. Uruchamiany po zmianie stanu syntezatora mowy.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted>. Wywoływane, gdy rozpoczyna syntezatora mowy generowania.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached>. Wywoływane zawsze, gdy osiągnie Syntezator literą lub kombinacją liter stanowią niejawnego dźwięk mowy w języku.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress>. Podnoszony, zawsze Syntezator kończy się mówiąc wyrazu.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached>. Wywoływane każdorazowo rozmowy dane wyjściowe wymaga zmiany w położeniu ujścia lub mięśni twarzy użyta do wyprodukowania mowy.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached>. Wywoływane, gdy praca syntezatora napotka zakładki w wierszu.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange>. Wywoływane, gdy zmienia się delikatnego głosu dla Syntezator.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted>. Wywoływane, gdy praca syntezatora zakończy przetwarzanie <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> operacji.  
  
 Jeśli Twoje dos aplikacji nie trzeba wykonywać zadań podczas trwania mowy, możesz użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A> do generowania mowy synchronicznie.  
  
   
  
## Examples  
  
```  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Build an SSML prompt in a string.  
      string str = "<speak version=\"1.0\"";  
      str += " xmlns=\"http://www.w3.org/2001/10/synthesis\"";  
      str += " xml:lang=\"en-US\">";  
      str += "<say-as type=\"date:mdy\"> 1/29/2009 </say-as>";  
      str += "</speak>";  
  
      // Speak the contents of the prompt asynchronously.  
      synth.SpeakSsmlAsync(str);  
  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="SpeakStarted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.SpeakStartedEventArgs&gt; SpeakStarted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.SpeakStartedEventArgs&gt; SpeakStarted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeakStarted As EventHandler(Of SpeakStartedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::SpeakStartedEventArgs ^&gt; ^ SpeakStarted;" />
      <MemberSignature Language="F#" Value="member this.SpeakStarted : EventHandler&lt;System.Speech.Synthesis.SpeakStartedEventArgs&gt; " Usage="member this.SpeakStarted : System.EventHandler&lt;System.Speech.Synthesis.SpeakStartedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.SpeakStartedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Wywoływane, gdy <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> rozpoczyna się mówiąc monit.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Synthesis.SpeechSynthesizer> Zgłasza tego zdarzenia, kiedy rozpoczyna przetwarzanie monit przy użyciu dowolnego <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A>, lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> metody.  
  
 <xref:System.Speech.Synthesis.SpeakStartedEventArgs> Klasa nie ma właściwości i zwraca dane z <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted> zdarzeń. Umożliwia autorom aplikacji do obsługi zdarzeń dla zapisu jest podana <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted> zdarzeń.  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="State">
      <MemberSignature Language="C#" Value="public System.Speech.Synthesis.SynthesizerState State { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Synthesis.SynthesizerState State" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.SpeechSynthesizer.State" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property State As SynthesizerState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Synthesis::SynthesizerState State { System::Speech::Synthesis::SynthesizerState get(); };" />
      <MemberSignature Language="F#" Value="member this.State : System.Speech.Synthesis.SynthesizerState" Usage="System.Speech.Synthesis.SpeechSynthesizer.State" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Synthesis.SynthesizerState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera bieżący stan mówiąc <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiektu.</summary>
        <value>Zwraca bieżący stan wymowy <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiektu.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aby uzyskać nowy stan <xref:System.Speech.Synthesis.SpeechSynthesizer> po jego zmian, użyj <xref:System.Speech.Synthesis.StateChangedEventArgs.State%2A> właściwość <xref:System.Speech.Synthesis.StateChangedEventArgs> klasy.  
  
   
  
## Examples  
 Poniższy przykład przedstawia stan <xref:System.Speech.Synthesis.SpeechSynthesizer> przed, podczas i po mówiąc monit.  
  
```csharp  
using System;  
using System.Threading;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer() ;  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Subscribe to the SpeakProgress event.         
      synth.SpeakProgress += new EventHandler<SpeakProgressEventArgs>(synth_SpeakProgress);  
  
      // Write the state of the SpeechSynthesizer to the console.  
      Console.WriteLine("Current Synthesizer state: " + synth.State + "\n");  
  
      // Speak a string asynchronously.  
      synth.SpeakAsync("What is your favorite color?");  
  
      // Write the state of the SpeechSynthesizer to the console while it is speaking.  
      Thread.Sleep(1000);  
      Console.WriteLine("\n - Current Synthesizer state: " + synth.State + " - \n");  
  
      // Write the state of the SpeechSynthesizer to the console after it is done speaking.  
      Thread.Sleep(2000);  
      Console.WriteLine("\nCurrent Synthesizer state: " + synth.State);  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    static void synth_SpeakProgress(object sender, SpeakProgressEventArgs e)  
    {  
      Console.WriteLine(e.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StateChanged">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.StateChangedEventArgs&gt; StateChanged;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.StateChangedEventArgs&gt; StateChanged" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.StateChanged" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event StateChanged As EventHandler(Of StateChangedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::StateChangedEventArgs ^&gt; ^ StateChanged;" />
      <MemberSignature Language="F#" Value="member this.StateChanged : EventHandler&lt;System.Speech.Synthesis.StateChangedEventArgs&gt; " Usage="member this.StateChanged : System.EventHandler&lt;System.Speech.Synthesis.StateChangedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.StateChangedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Wywoływane, gdy stan <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> zmiany.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Synthesis.SpeechSynthesizer> Zgłasza to zdarzenie po jego mówiąc <xref:System.Speech.Synthesis.SpeechSynthesizer.State%2A> zmiany. Na przykład i więcej informacji na temat dane skojarzone ze zdarzeniem, zobacz <xref:System.Speech.Synthesis.StateChangedEventArgs>.  
  
 Aby wstrzymać lub wznowić syntezy mowy, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.Pause%2A> i <xref:System.Speech.Synthesis.SpeechSynthesizer.Resume%2A> metody.  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="VisemeReached">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.VisemeReachedEventArgs&gt; VisemeReached;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.VisemeReachedEventArgs&gt; VisemeReached" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event VisemeReached As EventHandler(Of VisemeReachedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::VisemeReachedEventArgs ^&gt; ^ VisemeReached;" />
      <MemberSignature Language="F#" Value="member this.VisemeReached : EventHandler&lt;System.Speech.Synthesis.VisemeReachedEventArgs&gt; " Usage="member this.VisemeReached : System.EventHandler&lt;System.Speech.Synthesis.VisemeReachedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.VisemeReachedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Wywoływane, gdy zostanie osiągnięty viseme.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Viseme to podstawowe pozycja ujścia i twarzy przy wymawianiu phoneme. Visemes to wizualne reprezentacje fonemów.  
  
 System.Speech obsługuje 21 visemes US English, z których każdy odpowiada fonemów jeden lub więcej.  <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached> zdarzenia są wywoływane, gdy nowy phoneme, osiągnięto ma inną viseme odpowiedniego niż poprzednie phoneme, osiągnięto. Ponieważ niektóre visemes stanowią więcej niż jeden phoneme <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached> zdarzeń nie jest generowany, jeśli dalej phoneme, osiągnięto odnosi się do tej samej viseme jako phoneme poprzedniej. Na przykład w przypadku rozmowy wyrazy "tej strefy" <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached> zdarzenia "s" w "to" i "z" w "w strefie". Jednak <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached> zdarzenie nie jest wywoływane dla "z" w "strefy", ponieważ odnosi się do tej samej viseme jako "s" w "this".  
  
 Poniżej znajduje się lista 21 fonemów SAPI i phoneme grup, które odpowiadają viseme w US English.  
  
|Viseme|Phoneme(s)|  
|------------|------------------|  
|0|cisza|  
|1|AE, ax, ah|  
|2|aa|  
|3|ao|  
|4|EY, eh, Niestety|  
|5|Era|  
|6|y, iy, umożliwiają, popraw|  
|7|w, uw|  
|8|ow|  
|9|aw|  
|10|Oy|  
|11|dni|  
|12|h|  
|13|r|  
|14|l|  
|15|s, z|  
|16|sh, ch, jh, zh|  
|17|TH, dh|  
|18|f, v|  
|19|d, t, n|  
|20|k, g, ng|  
|21|p, b, m|  
  
 Informacje o danych skojarzonych z `VisemeReached` zdarzeń, zobacz <xref:System.Speech.Synthesis.VisemeReachedEventArgs>.  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="Voice">
      <MemberSignature Language="C#" Value="public System.Speech.Synthesis.VoiceInfo Voice { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Synthesis.VoiceInfo Voice" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.SpeechSynthesizer.Voice" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Voice As VoiceInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Synthesis::VoiceInfo ^ Voice { System::Speech::Synthesis::VoiceInfo ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Voice : System.Speech.Synthesis.VoiceInfo" Usage="System.Speech.Synthesis.SpeechSynthesizer.Voice" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Synthesis.VoiceInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera informacje o bieżącym głos <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiektu.</summary>
        <value>Zwraca informacje o bieżącym głos <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiektu.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Podczas inicjowania nowy <xref:System.Speech.Synthesis.SpeechSynthesizer>, używa głos systemu domyślny. Aby skonfigurować <xref:System.Speech.Synthesis.SpeechSynthesizer> obiektów, użyj jednej z głosy syntezie mowy zainstalowany, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> metody. Aby uzyskać informacje o tym, które głosy są zainstalowane, należy użyć <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> — metoda i <xref:System.Speech.Synthesis.VoiceInfo> klasy.  
  
   
  
## Examples  
 W poniższym przykładzie inicjowane wystąpienia <xref:System.Speech.Synthesis.SpeechSynthesizer> i pobiera informacje o bieżącym głosu.  
  
```csharp  
using System;  
using System.IO;  
using System.Speech.Synthesis;  
using System.Speech.AudioFormat;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Get information about supported audio formats.  
        string AudioFormats = "";  
        foreach (SpeechAudioFormatInfo fmt in synth.Voice.SupportedAudioFormats)  
        {  
          AudioFormats += String.Format("{0}\n",  
          fmt.EncodingFormat.ToString());  
        }  
  
        // Write information about the voice to the console.  
        Console.WriteLine(" Name:          " + synth.Voice.Name);  
        Console.WriteLine(" Culture:       " + synth.Voice.Culture);  
        Console.WriteLine(" Age:           " + synth.Voice.Age);  
        Console.WriteLine(" Gender:        " + synth.Voice.Gender);  
        Console.WriteLine(" Description:   " + synth.Voice.Description);  
        Console.WriteLine(" ID:            " + synth.Voice.Id);  
        if (synth.Voice.SupportedAudioFormats.Count != 0)  
        {  
          Console.WriteLine(" Audio formats: " + AudioFormats);  
        }  
        else  
        {  
          Console.WriteLine(" No supported audio formats found");  
        }  
  
        // Get additional information about the voice.  
        string AdditionalInfo = "";  
        foreach (string key in synth.Voice.AdditionalInfo.Keys)  
        {  
          AdditionalInfo += String.Format("  {0}: {1}\n",  
            key, synth.Voice.AdditionalInfo[key]);  
        }  
  
        Console.WriteLine(" Additional Info - " + AdditionalInfo);  
        Console.WriteLine();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints(System.Speech.Synthesis.VoiceGender)" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange" />
      </Docs>
    </Member>
    <Member MemberName="VoiceChange">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.VoiceChangeEventArgs&gt; VoiceChange;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.VoiceChangeEventArgs&gt; VoiceChange" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event VoiceChange As EventHandler(Of VoiceChangeEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::VoiceChangeEventArgs ^&gt; ^ VoiceChange;" />
      <MemberSignature Language="F#" Value="member this.VoiceChange : EventHandler&lt;System.Speech.Synthesis.VoiceChangeEventArgs&gt; " Usage="member this.VoiceChange : System.EventHandler&lt;System.Speech.Synthesis.VoiceChangeEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.VoiceChangeEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Wywoływane, gdy głos <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> zmiany.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Na przykład i informacje o danych skojarzone ze zdarzeniem, zobacz <xref:System.Speech.Synthesis.VoiceChangeEventArgs>.  
  
 Można zmienić głos który <xref:System.Speech.Synthesis.SpeechSynthesizer> korzysta ze wszystkimi <xref:System.Speech.Synthesis.PromptBuilder>w <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> metody lub <xref:System.Speech.Synthesis.SpeechSynthesizer>w <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> lub <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> metody.  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="Volume">
      <MemberSignature Language="C#" Value="public int Volume { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 Volume" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.SpeechSynthesizer.Volume" />
      <MemberSignature Language="VB.NET" Value="Public Property Volume As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int Volume { int get(); void set(int value); };" />
      <MemberSignature Language="F#" Value="member this.Volume : int with get, set" Usage="System.Speech.Synthesis.SpeechSynthesizer.Volume" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera lub ustawia wielkość danych wyjściowych <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> obiektu.</summary>
        <value>Zwraca ilość <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />, od 0 do 100.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Poniższy przykład przedstawia ilość <xref:System.Speech.Synthesis.SpeechSynthesizer>audio wyjściowy plików WAV i syntezatora mowy.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Set the volume of the SpeechSynthesizer's ouput.  
        synth.Volume = 60;  
  
        // Build a prompt containing recorded audio and synthesized speech.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendAudio("C:\\Test\\WelcomeToContosoRadio.wav");  
        builder.AppendText(  
          "The weather forecast for today is partly cloudy with some sun breaks.");  
  
        // Speak the prompt.  
        synth.Speak(builder);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>