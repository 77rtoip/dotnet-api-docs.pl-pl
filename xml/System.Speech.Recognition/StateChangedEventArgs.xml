<Type Name="StateChangedEventArgs" FullName="System.Speech.Recognition.StateChangedEventArgs">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="d74bd2ebaba4fb23f1dfb7ec3d953fff736dbe01" />
    <Meta Name="ms.sourcegitcommit" Value="d877ae76e9e11799bf919379507239e2c4072742" />
    <Meta Name="ms.translationtype" Value="MT" />
    <Meta Name="ms.contentlocale" Value="pl-PL" />
    <Meta Name="ms.lasthandoff" Value="08/09/2018" />
    <Meta Name="ms.locfileid" Value="39988611" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class StateChangedEventArgs : EventArgs" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit StateChangedEventArgs extends System.EventArgs" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.StateChangedEventArgs" />
  <TypeSignature Language="VB.NET" Value="Public Class StateChangedEventArgs&#xA;Inherits EventArgs" />
  <TypeSignature Language="C++ CLI" Value="public ref class StateChangedEventArgs : EventArgs" />
  <TypeSignature Language="F#" Value="type StateChangedEventArgs = class&#xA;    inherit EventArgs" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.EventArgs</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>
      <span data-ttu-id="23cb1-101">Zwraca dane z <see cref="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" /> zdarzeń.</span>
      <span class="sxs-lookup">
        <span data-stu-id="23cb1-101">Returns data from the <see cref="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" /> event.</span>
      </span>
    </summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="23cb1-102"><xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> Wydarzenie jest podniesione przez <xref:System.Speech.Recognition.SpeechRecognizer> klasy.</span><span class="sxs-lookup"><span data-stu-id="23cb1-102">The <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> event is raised by the <xref:System.Speech.Recognition.SpeechRecognizer> class.</span></span> <span data-ttu-id="23cb1-103"><xref:System.Speech.Recognition.StateChangedEventArgs> pochodzi od klasy <xref:System.EventArgs> i jest przekazywany do obsługi <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> zdarzenia.</span><span class="sxs-lookup"><span data-stu-id="23cb1-103"><xref:System.Speech.Recognition.StateChangedEventArgs> derives from <xref:System.EventArgs> and is passed to handlers for <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> events.</span></span>  
  
 <span data-ttu-id="23cb1-104"><xref:System.Speech.Recognition.SpeechRecognizer.State%2A> jest to właściwość tylko do odczytu.</span><span class="sxs-lookup"><span data-stu-id="23cb1-104"><xref:System.Speech.Recognition.SpeechRecognizer.State%2A> is a read-only property.</span></span> <span data-ttu-id="23cb1-105">Stan aparatu rozpoznawania mowy udostępnionego nie można zmienić programowo.</span><span class="sxs-lookup"><span data-stu-id="23cb1-105">A shared speech recognizer's state cannot be changed programmatically.</span></span> <span data-ttu-id="23cb1-106">Użytkownicy mogą zmieniać stan aparatu rozpoznawania mowy udostępnione za pomocą funkcji rozpoznawania mowy interfejsu użytkownika (UI) lub za pomocą **rozpoznawania mowy** członkiem Windows **Panelu sterowania**.</span><span class="sxs-lookup"><span data-stu-id="23cb1-106">Users can change a shared speech recognizer's state using the Speech Recognition user interface (UI) or through the **Speech Recognition** member of the Windows **Control Panel**.</span></span>  
  
 <span data-ttu-id="23cb1-107">Zarówno **na** i **uśpienia** ustawienia w Interfejsie użytkownika rozpoznawania mowy odpowiadają `Listening` stanu.</span><span class="sxs-lookup"><span data-stu-id="23cb1-107">Both the **On** and **Sleep** settings in the Speech Recognition UI correspond to the `Listening` state.</span></span> <span data-ttu-id="23cb1-108">**Poza** ustawienie w Interfejsie użytkownika rozpoznawania mowy odpowiada <xref:System.Speech.Recognition.RecognizerState.Stopped>.</span><span class="sxs-lookup"><span data-stu-id="23cb1-108">The **Off** setting in the Speech Recognition UI corresponds to <xref:System.Speech.Recognition.RecognizerState.Stopped>.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="23cb1-109">Poniższy przykład tworzy rozpoznawania mowy udostępnionego, a następnie tworzy dwa typy gramatyki rozpoznawania konkretnych słów i akceptowania dyktowanie bezpłatne.</span><span class="sxs-lookup"><span data-stu-id="23cb1-109">The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</span></span> <span data-ttu-id="23cb1-110">Przykład ładuje asynchronicznie wszystkich gramatykach utworzonego dla aparatu rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="23cb1-110">The example asynchronously loads all the created grammars to the recognizer.</span></span>  <span data-ttu-id="23cb1-111">Program obsługi <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> zdarzeń używa <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> metodę, aby umieścić rozpoznawania Windows w trybie "nasłuchiwania".</span><span class="sxs-lookup"><span data-stu-id="23cb1-111">A handler for the <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> event uses the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> method to put Windows Recognition in "listening" mode.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted += new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the SpeechRecognized event.  
      recognizer.SpeechRecognized += new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
      // Add a handler for the StateChanged event.  
      recognizer.StateChanged += new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
      // Create "yesno" grammar.  
      Choices yesChoices = new Choices(new string[] { "yes", "yup", "yah}" });  
      SemanticResultValue yesValue =  
          new SemanticResultValue(yesChoices, (bool)true);  
      Choices noChoices = new Choices(new string[] { "no", "nope", "nah" });  
      SemanticResultValue noValue = new SemanticResultValue(noChoices, (bool)false);  
      SemanticResultKey yesNoKey =  
          new SemanticResultKey("yesno", new Choices(new GrammarBuilder[] { yesValue, noValue }));  
      Grammar yesnoGrammar = new Grammar(yesNoKey);  
      yesnoGrammar.Name = "yesNo";  
  
      // Create "done" grammar.  
      Grammar doneGrammar =  
        new Grammar(new Choices(new string[] { "done", "exit", "quit", "stop" }));  
      doneGrammar.Name = "Done";  
  
      // Create dictation grammar.  
      Grammar dictation = new DictationGrammar();  
      dictation.Name = "Dictation";  
  
      // Load grammars to the recognizer.  
      recognizer.LoadGrammarAsync(yesnoGrammar);  
      recognizer.LoadGrammarAsync(doneGrammar);  
      recognizer.LoadGrammarAsync(dictation);  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void  recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
     if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  
    // Write the grammar name and the text of the recognized phrase to the console.  
    static void  recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
     Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void  recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
     string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
      }  
  
      // Add exception handling code here.  
      Console.WriteLine("Grammar {0} {1} loaded.",  
      grammarName, (grammarLoaded) ? "is" : "is not");  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
    <altmember cref="T:System.Speech.Recognition.RecognizerState" />
  </Docs>
  <Members>
    <Member MemberName="RecognizerState">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizerState RecognizerState { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.RecognizerState RecognizerState" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.StateChangedEventArgs.RecognizerState" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerState As RecognizerState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizerState RecognizerState { System::Speech::Recognition::RecognizerState get(); };" />
      <MemberSignature Language="F#" Value="member this.RecognizerState : System.Speech.Recognition.RecognizerState" Usage="System.Speech.Recognition.StateChangedEventArgs.RecognizerState" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="23cb1-112">Pobiera bieżący stan aparatu rozpoznawania mowy udostępnionych w Windows.</span>
          <span class="sxs-lookup">
            <span data-stu-id="23cb1-112">Gets the current state of the shared speech recognition engine in Windows.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="23cb1-113">A <see cref="T:System.Speech.Recognition.RecognizerState" /> wystąpienie, które wskazuje, czy stan aparatu rozpoznawania mowy udostępnionego <see langword="Listening" /> lub <see langword="Stopped" />.</span>
          <span class="sxs-lookup">
            <span data-stu-id="23cb1-113">A <see cref="T:System.Speech.Recognition.RecognizerState" /> instance that indicates whether the state of a shared speech recognition engine is <see langword="Listening" /> or <see langword="Stopped" />.</span>
          </span>
        </value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 <span data-ttu-id="23cb1-114">Poniższy przykład aktualizuje wyświetlania, w oparciu o informacje o stanie, dostarczone przez <xref:System.Speech.Recognition.RecognizerState> wystąpienie, które są uzyskiwane z <xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A> właściwość <xref:System.Speech.Recognition.StateChangedEventArgs> wystąpienia przekazany do procedury obsługi dla <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> zdarzeń.</span><span class="sxs-lookup"><span data-stu-id="23cb1-114">The following example updates a display based on the state information provided by a <xref:System.Speech.Recognition.RecognizerState> instance that is obtained from the <xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A> property of a <xref:System.Speech.Recognition.StateChangedEventArgs> instance passed to a handler for a <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> event.</span></span>  
  
```  
  
// Make sure that _recognizer and recognition start buttons are disabled if state is stopped.  
// Re-enable the start button to allow manual re-enable if the speech recognizer is listening.  
_recognizer.StateChanged +=  
  delegate(object sender, StateChangedEventArgs eventArgs)   
{  
  _recognizerStateLabel.Text = "Speech Recognizer State: " + eventArgs.RecognizerState.ToString();  
};  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>