<Type Name="DictationGrammar" FullName="System.Speech.Recognition.DictationGrammar">
  <Metadata><Meta Name="ms.openlocfilehash" Value="18a457ab8c4b088fb91ffc48e4b48c4dc26c4a89" /><Meta Name="ms.sourcegitcommit" Value="055a4a82a0b08bfbdc21bd1347fb71f7fe2c099e" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="pl-PL" /><Meta Name="ms.lasthandoff" Value="08/15/2019" /><Meta Name="ms.locfileid" Value="69231367" /></Metadata><TypeSignature Language="C#" Value="public class DictationGrammar : System.Speech.Recognition.Grammar" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit DictationGrammar extends System.Speech.Recognition.Grammar" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.DictationGrammar" />
  <TypeSignature Language="VB.NET" Value="Public Class DictationGrammar&#xA;Inherits Grammar" />
  <TypeSignature Language="C++ CLI" Value="public ref class DictationGrammar : System::Speech::Recognition::Grammar" />
  <TypeSignature Language="F#" Value="type DictationGrammar = class&#xA;    inherit Grammar" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Speech.Recognition.Grammar</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>Reprezentuje gramatykę rozpoznawania mowy używaną do dyktowania tekstu.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ta klasa udostępnia aplikacje ze wstępnie zdefiniowanym modelem języka, który może przetwarzać dane wprowadzane przez użytkownika jako tekst. Ta klasa obsługuje zarówno obiekty domyślne, <xref:System.Speech.Recognition.DictationGrammar> jak i niestandardowe. Aby uzyskać informacje na temat wybierania gramatyki dyktowania, <xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29> Zobacz Konstruktor.  
  
 Domyślnie model języka jest <xref:System.Speech.Recognition.DictationGrammar> bezpłatny dla kontekstu. Nie używa określonych wyrazów ani kolejności słów, aby identyfikować i interpretować dane wejściowe audio. Aby dodać kontekst do gramatyki dyktowania, użyj <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> metody.  
  
> [!NOTE]
>  <xref:System.Speech.Recognition.DictationGrammar>obiekty nie obsługują <xref:System.Speech.Recognition.Grammar.Priority%2A> właściwości. <xref:System.Speech.Recognition.DictationGrammar>Zwraca wartość <xref:System.NotSupportedException> , <xref:System.Speech.Recognition.Grammar.Priority%2A> jeśli jest ustawiona.  
  
   
  
## Examples  
 Poniższy przykład tworzy trzy gramatyki dyktowania, dodaje je do nowego <xref:System.Speech.Recognition.SpeechRecognitionEngine> obiektu i zwraca nowy obiekt. Pierwsza Gramatyka jest domyślną gramatyką dyktowania. Druga Gramatyka to Gramatyka dyktowania pisowni. Trzecia Gramatyka jest domyślną gramatyką dyktowania, która zawiera frazę kontekstową. Metoda jest używana do kojarzenia frazy kontekstu z gramatyką dyktowania po załadowaniu jej <xref:System.Speech.Recognition.SpeechRecognitionEngine> do obiektu. <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A>  
  
```csharp  
  
private SpeechRecognitionEngine LoadDictationGrammars()  
{  
  
  // Create a default dictation grammar.  
  DictationGrammar defaultDictationGrammar = new DictationGrammar();  
  defaultDictationGrammar.Name = "default dictation";  
  defaultDictationGrammar.Enabled = true;  
  
  // Create the spelling dictation grammar.  
  DictationGrammar spellingDictationGrammar =  
    new DictationGrammar("grammar:dictation#spelling");  
  spellingDictationGrammar.Name = "spelling dictation";  
  spellingDictationGrammar.Enabled = true;  
  
  // Create the question dictation grammar.  
  DictationGrammar customDictationGrammar =  
    new DictationGrammar("grammar:dictation");  
  customDictationGrammar.Name = "question dictation";  
  customDictationGrammar.Enabled = true;  
  
  // Create a SpeechRecognitionEngine object and add the grammars to it.  
  SpeechRecognitionEngine recoEngine = new SpeechRecognitionEngine();  
  recoEngine.LoadGrammar(defaultDictationGrammar);  
  recoEngine.LoadGrammar(spellingDictationGrammar);  
  recoEngine.LoadGrammar(customDictationGrammar);  
  
  // Add a context to customDictationGrammar.  
  customDictationGrammar.SetDictationContext("How do you", null);  
  
  return recoEngine;  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.Grammar" />
  </Docs>
  <Members>
    <MemberGroup MemberName=".ctor">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Inicjuje nowe wystąpienie klasy <see cref="T:System.Speech.Recognition.DictationGrammar" /> klasy.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public DictationGrammar ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; DictationGrammar();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>Inicjuje nowe wystąpienie <see cref="T:System.Speech.Recognition.DictationGrammar" /> klasy dla domyślnej gramatyki dyktowania zapewnianej przez technologię mowy dla systemu Windows Desktop.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Domyślna Gramatyka dyktowania emuluje standardowe praktyki dyktowania, w tym znaki interpunkcyjne. Nie obsługuje pisowni wyrazu.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public DictationGrammar (string topic);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string topic) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.#ctor(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (topic As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; DictationGrammar(System::String ^ topic);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.DictationGrammar : string -&gt; System.Speech.Recognition.DictationGrammar" Usage="new System.Speech.Recognition.DictationGrammar topic" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="topic" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="topic">Identyfikator URI zgodny ze standardem XML, który określa gramatykę dyktowania, <c>gramatykę: dyktowanie</c> lub gramatykę <c>: dyktowanie # pisownia</c>.</param>
        <summary>Inicjuje nowe wystąpienie <see cref="T:System.Speech.Recognition.DictationGrammar" /> klasy z określoną gramatyką dyktowania.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Platforma mowy używa wyspecjalizowanej składni identyfikatora URI do definiowania niestandardowej gramatyki dyktowania. Wartość `grammar:dictation` wskazuje domyślną gramatykę dyktowania. Wartość `grammar:dictation#spelling` wskazuje gramatykę dyktowania.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="SetDictationContext">
      <MemberSignature Language="C#" Value="public void SetDictationContext (string precedingText, string subsequentText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetDictationContext(string precedingText, string subsequentText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetDictationContext (precedingText As String, subsequentText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetDictationContext(System::String ^ precedingText, System::String ^ subsequentText);" />
      <MemberSignature Language="F#" Value="member this.SetDictationContext : string * string -&gt; unit" Usage="dictationGrammar.SetDictationContext (precedingText, subsequentText)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="precedingText" Type="System.String" />
        <Parameter Name="subsequentText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="precedingText">Tekst wskazujący początek kontekstu dyktowania.</param>
        <param name="subsequentText">Tekst wskazujący koniec kontekstu dyktowania.</param>
        <summary>Dodaje kontekst do gramatyki dyktowania, która została załadowana przez <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> obiekt lub.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Domyślnie gramatyki dyktowania nie używa określonych wyrazów ani kolejności słów, aby identyfikować i interpretować dane wejściowe audio. Po dodaniu kontekstu do gramatyki dyktowania aparat rozpoznawania używa `precedingText` i `subsequentText` do identyfikowania, kiedy należy interpretować mowę jako dyktowanie.  
  
> [!NOTE]
>  Gramatyka dyktowania musi być załadowana przez <xref:System.Speech.Recognition.SpeechRecognizer> obiekt <xref:System.Speech.Recognition.SpeechRecognitionEngine> lub, aby można było <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> użyć programu w celu dodania kontekstu.  
  
 W poniższej tabeli opisano, jak aparat rozpoznawania używa dwóch parametrów, aby określić, kiedy należy użyć gramatyki dyktowania.  
  
|`precedingText`|`subsequentText`|Opis|  
|---------------------|----------------------|-----------------|  
|niemożliwe`null`|niemożliwe`null`|Aparat rozpoznawania używa warunków, aby przenawiasować możliwe zwroty kandydatów.|  
|`null`|niemożliwe`null`|Aparat rozpoznawania używa `subsequentText` do zakończenia dyktowania.|  
|niemożliwe`null`|`null`|Aparat rozpoznawania używa `precedingText` do uruchamiania dyktowania.|  
|`null`|`null`|Aparat rozpoznawania nie używa kontekstu przy użyciu gramatyki dyktowania.|  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
      </Docs>
    </Member>
  </Members>
</Type>
