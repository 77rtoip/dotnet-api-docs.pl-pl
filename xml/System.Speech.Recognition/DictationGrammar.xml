<Type Name="DictationGrammar" FullName="System.Speech.Recognition.DictationGrammar">
  <Metadata><Meta Name="ms.openlocfilehash" Value="8a9e1eaa194231c8436fba54e4f887133b57bdd0" /><Meta Name="ms.sourcegitcommit" Value="f1d16425528e237257ca3b58eb49217a514849ea" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="pl-PL" /><Meta Name="ms.lasthandoff" Value="04/24/2019" /><Meta Name="ms.locfileid" Value="64097745" /></Metadata><TypeSignature Language="C#" Value="public class DictationGrammar : System.Speech.Recognition.Grammar" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit DictationGrammar extends System.Speech.Recognition.Grammar" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.DictationGrammar" />
  <TypeSignature Language="VB.NET" Value="Public Class DictationGrammar&#xA;Inherits Grammar" />
  <TypeSignature Language="C++ CLI" Value="public ref class DictationGrammar : System::Speech::Recognition::Grammar" />
  <TypeSignature Language="F#" Value="type DictationGrammar = class&#xA;    inherit Grammar" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Speech.Recognition.Grammar</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>Reprezentuje gramatyki rozpoznawania mowy, umożliwiający dyktowanie dowolny tekst.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ta klasa udostępnia aplikacje przy użyciu modelu języka wstępnie zdefiniowanych, która może przetwarzać dane wejściowe użytkownika mówiony na tekst. Ta klasa obsługuje domyślnych i niestandardowych <xref:System.Speech.Recognition.DictationGrammar> obiektów. Aby uzyskać informacji o wybieraniu gramatyki dyktowania, zobacz <xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29> konstruktora.  
  
 Domyślnie <xref:System.Speech.Recognition.DictationGrammar> model języka to bezpłatna na kontekst. Należy używać konkretnych słów lub word kolejności, aby zidentyfikować i interpretować dane wejściowe audio. Aby dodać kontekstowego gramatyki dyktowania, należy użyć <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> metody.  
  
> [!NOTE]
>  <xref:System.Speech.Recognition.DictationGrammar> obiekty nie obsługują <xref:System.Speech.Recognition.Grammar.Priority%2A> właściwości. <xref:System.Speech.Recognition.DictationGrammar> zgłasza <xref:System.NotSupportedException> Jeśli <xref:System.Speech.Recognition.Grammar.Priority%2A> jest ustawiona.  
  
   
  
## Examples  
 Poniższy przykład tworzy trzy gramatyki dyktowania, dodaje je do nowego <xref:System.Speech.Recognition.SpeechRecognitionEngine> obiektu i zwraca nowy obiekt. Pierwszy gramatyki jest gramatyki dyktowanie domyślne. Drugi gramatyki jest gramatyki dyktowanie pisowni. Trzeci gramatyki jest gramatyki dyktowanie domyślny, zawierający frazę kontekstu. <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> Metoda jest używana do skojarzenia z gramatyki dyktowanie frazy kontekstu, po załadowaniu danych do <xref:System.Speech.Recognition.SpeechRecognitionEngine> obiektu.  
  
```csharp  
  
private SpeechRecognitionEngine LoadDictationGrammars()  
{  
  
  // Create a default dictation grammar.  
  DictationGrammar defaultDictationGrammar = new DictationGrammar();  
  defaultDictationGrammar.Name = "default dictation";  
  defaultDictationGrammar.Enabled = true;  
  
  // Create the spelling dictation grammar.  
  DictationGrammar spellingDictationGrammar =  
    new DictationGrammar("grammar:dictation#spelling");  
  spellingDictationGrammar.Name = "spelling dictation";  
  spellingDictationGrammar.Enabled = true;  
  
  // Create the question dictation grammar.  
  DictationGrammar customDictationGrammar =  
    new DictationGrammar("grammar:dictation");  
  customDictationGrammar.Name = "question dictation";  
  customDictationGrammar.Enabled = true;  
  
  // Create a SpeechRecognitionEngine object and add the grammars to it.  
  SpeechRecognitionEngine recoEngine = new SpeechRecognitionEngine();  
  recoEngine.LoadGrammar(defaultDictationGrammar);  
  recoEngine.LoadGrammar(spellingDictationGrammar);  
  recoEngine.LoadGrammar(customDictationGrammar);  
  
  // Add a context to customDictationGrammar.  
  customDictationGrammar.SetDictationContext("How do you", null);  
  
  return recoEngine;  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.Grammar" />
  </Docs>
  <Members>
    <MemberGroup MemberName=".ctor">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Inicjuje nowe wystąpienie klasy <see cref="T:System.Speech.Recognition.DictationGrammar" /> klasy.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public DictationGrammar ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; DictationGrammar();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>Inicjuje nowe wystąpienie klasy <see cref="T:System.Speech.Recognition.DictationGrammar" /> klasy dla gramatyki dyktowanie domyślne, dostarczone przez technologii mowy pulpitu Windows.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Gramatyka dyktowanie domyślne emuluje praktyki dyktowanie standardowego, w tym znaki interpunkcyjne. Nie obsługuje pisownię wyrazu.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public DictationGrammar (string topic);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string topic) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.#ctor(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (topic As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; DictationGrammar(System::String ^ topic);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.DictationGrammar : string -&gt; System.Speech.Recognition.DictationGrammar" Usage="new System.Speech.Recognition.DictationGrammar topic" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="topic" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="topic">XML zgodne Universal identyfikator (URI) określający gramatykę dyktowania, albo <c>gramatyki: dyktowanie</c> lub <c>gramatyki: dyktowanie #spelling</c>.</param>
        <summary>Inicjuje nowe wystąpienie klasy <see cref="T:System.Speech.Recognition.DictationGrammar" /> klasy przy użyciu gramatyka dyktowanie określone.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Platforma mowy używa specjalne składni identyfikatora URI do definiowania gramatyki dyktowanie niestandardowych. Wartość `grammar:dictation` wskazuje gramatyki dyktowanie domyślne. Wartość `grammar:dictation#spelling` wskazuje gramatyki dyktowanie pisowni.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="SetDictationContext">
      <MemberSignature Language="C#" Value="public void SetDictationContext (string precedingText, string subsequentText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetDictationContext(string precedingText, string subsequentText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetDictationContext (precedingText As String, subsequentText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetDictationContext(System::String ^ precedingText, System::String ^ subsequentText);" />
      <MemberSignature Language="F#" Value="member this.SetDictationContext : string * string -&gt; unit" Usage="dictationGrammar.SetDictationContext (precedingText, subsequentText)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="precedingText" Type="System.String" />
        <Parameter Name="subsequentText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="precedingText">Tekst, który wskazuje początek kontekstu dyktowanie.</param>
        <param name="subsequentText">Tekst, który wskazuje koniec kontekstu dyktowanie.</param>
        <summary>Dodaje kontekst do gramatyki dyktowania, który został załadowany przez <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> lub <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> obiektu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Domyślnie gramatyka Dyktowanie nie powoduje wykorzystanie konkretnych słów lub word kolejności, aby zidentyfikować i interpretować dane wejściowe audio. Po dodaniu kontekst gramatyki dyktowanie korzysta z aparatu rozpoznawania `precedingText` i `subsequentText` do identyfikowania, kiedy należy interpretować mowy jako dyktowanie.  
  
> [!NOTE]
>  Gramatyka dyktowanie muszą być ładowane przez <xref:System.Speech.Recognition.SpeechRecognizer> lub <xref:System.Speech.Recognition.SpeechRecognitionEngine> obiektu, zanim będzie można użyć <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> dodać kontekstowego.  
  
 W poniższej tabeli opisano, jak aparat rozpoznawania używa dwóch parametrów do określenia, kiedy używać gramatyki dyktowanie.  
  
|`precedingText`|`subsequentText`|Opis|  
|---------------------|----------------------|-----------------|  
|nie `null`|nie `null`|Aparat rozpoznawania dopasowywanie fraz kandydujących możliwe na podstawie warunków.|  
|`null`|nie `null`|Korzysta z aparatu rozpoznawania `subsequentText` zakończenie dyktowanie.|  
|nie `null`|`null`|Korzysta z aparatu rozpoznawania `precedingText` można uruchomić dyktowanie.|  
|`null`|`null`|Aparat rozpoznawania nie używać kontekstu przy użyciu gramatyka dyktowanie.|  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
      </Docs>
    </Member>
  </Members>
</Type>