<Type Name="SpeechRecognizedEventArgs" FullName="System.Speech.Recognition.SpeechRecognizedEventArgs">
  <Metadata><Meta Name="ms.openlocfilehash" Value="30d793d84b2d2d88503bb510061ce8318d089995" /><Meta Name="ms.sourcegitcommit" Value="756d085f27705e86604f1bba5f2086ee23761acf" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="pl-PL" /><Meta Name="ms.lasthandoff" Value="01/30/2019" /><Meta Name="ms.locfileid" Value="55312091" /></Metadata><TypeSignature Language="C#" Value="public class SpeechRecognizedEventArgs : System.Speech.Recognition.RecognitionEventArgs" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit SpeechRecognizedEventArgs extends System.Speech.Recognition.RecognitionEventArgs" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.SpeechRecognizedEventArgs" />
  <TypeSignature Language="VB.NET" Value="Public Class SpeechRecognizedEventArgs&#xA;Inherits RecognitionEventArgs" />
  <TypeSignature Language="C++ CLI" Value="public ref class SpeechRecognizedEventArgs : System::Speech::Recognition::RecognitionEventArgs" />
  <TypeSignature Language="F#" Value="type SpeechRecognizedEventArgs = class&#xA;    inherit RecognitionEventArgs" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Speech.Recognition.RecognitionEventArgs</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute>
      <AttributeName>System.Serializable</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Informacje dotyczące <see cref="E:System.Speech.Recognition.Grammar.SpeechRecognized" />, <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />, i <see cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" /> zdarzenia.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 A `SpeechRecognized` wydarzenie jest podniesione przez <xref:System.Speech.Recognition.Grammar>, <xref:System.Speech.Recognition.SpeechRecognizer> i <xref:System.Speech.Recognition.SpeechRecognitionEngine> klasy.  
  
 `SpeechRecognized` zdarzenia są generowane, gdy co najmniej jeden alternatyw z operacją rozpoznawania współczynnik ufności wystarczająco wysoka, należy zaakceptować. Aby uzyskać szczegółowe informacje na temat rozpoznawanym frazy, dostęp do <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> właściwości programu obsługi zdarzenia.  
  
 `SpeechRecognizedEventArgs` pochodzi od klasy <xref:System.Speech.Recognition.RecognitionEventArgs> klasy.  
  
   
  
## Examples  
 Poniższy przykład jest częścią aplikację konsolową która ładuje gramatyki rozpoznawania mowy i pokazuje dane wejściowe mowy udostępniony aparat rozpoznawania, wyniki rozpoznawania skojarzone i powiązanych zdarzeń wywołanych przez aparat rozpoznawania mowy. Jeśli usługa rozpoznawania mowy Windows nie jest uruchomiona, następnie uruchamianie tej aplikacji będzie również uruchomić rozpoznawanie mowy Windows.  
  
 Wypowiadane dane wejściowe, takie jak "Chcę się z Chicago do Warszawa" spowoduje wyzwolenie <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> zdarzeń. Nie wywoła wypowiedzi frazę "Podnoszenia me z Houston do Chicago" <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> zdarzeń.  
  
 W przykładzie użyto procedury obsługi dla <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> zdarzenie, aby wyświetlić pomyślnie rozpoznane fraz i semantyka zawierają one w konsoli.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create SemanticResultValue objects that contain cities and airport codes.  
        SemanticResultValue chicago = new SemanticResultValue("Chicago", "ORD");  
        SemanticResultValue boston = new SemanticResultValue("Boston", "BOS");  
        SemanticResultValue miami = new SemanticResultValue("Miami", "MIA");  
        SemanticResultValue dallas = new SemanticResultValue("Dallas", "DFW");  
  
        // Create a Choices object and add the SemanticResultValue objects, using  
        // implicit conversion from SemanticResultValue to GrammarBuilder  
        Choices cities = new Choices();  
        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  
  
        // Build the phrase and add SemanticResultKeys.  
        GrammarBuilder chooseCities = new GrammarBuilder();  
        chooseCities.Append("I want to fly from");  
        chooseCities.Append(new SemanticResultKey("origin", cities));  
        chooseCities.Append("to");  
        chooseCities.Append(new SemanticResultKey("destination", cities));  
  
        // Build a Grammar object from the GrammarBuilder.  
        Grammar bookFlight = new Grammar(chooseCities);  
        bookFlight.Name = "Book Flight";  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(bookFlight);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
      Console.WriteLine();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized:  " + e.Result.Text);  
      Console.WriteLine();  
      Console.WriteLine("Semantic results:");  
      Console.WriteLine("  The flight origin is " + e.Result.Semantics["origin"].Value);  
      Console.WriteLine("  The flight destination is " + e.Result.Semantics["destination"].Value);  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.SpeechRecognizedEventArgs" />
    <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.Grammar.SpeechRecognized" />
    <altmember cref="T:System.Speech.Recognition.SpeechHypothesizedEventArgs" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
    <altmember cref="T:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs" />
  </Docs>
  <Members />
</Type>