<Type Name="RecognitionResult" FullName="System.Speech.Recognition.RecognitionResult">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="670365ff9128cf5f671514db2428d8bcaa6b1b8d" />
    <Meta Name="ms.sourcegitcommit" Value="84c54c0c7d64827a5637d1f05e74e1f0598606a1" />
    <Meta Name="ms.translationtype" Value="MT" />
    <Meta Name="ms.contentlocale" Value="pl-PL" />
    <Meta Name="ms.lasthandoff" Value="08/27/2018" />
    <Meta Name="ms.locfileid" Value="42974445" />
  </Metadata>
  <TypeSignature Language="C#" Value="public sealed class RecognitionResult : System.Speech.Recognition.RecognizedPhrase, System.Runtime.Serialization.ISerializable" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable sealed beforefieldinit RecognitionResult extends System.Speech.Recognition.RecognizedPhrase implements class System.Runtime.Serialization.ISerializable" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognitionResult" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class RecognitionResult&#xA;Inherits RecognizedPhrase&#xA;Implements ISerializable" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognitionResult sealed : System::Speech::Recognition::RecognizedPhrase, System::Runtime::Serialization::ISerializable" />
  <TypeSignature Language="F#" Value="type RecognitionResult = class&#xA;    inherit RecognizedPhrase&#xA;    interface ISerializable" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Speech.Recognition.RecognizedPhrase</BaseTypeName>
  </Base>
  <Interfaces>
    <Interface>
      <InterfaceName>System.Runtime.Serialization.ISerializable</InterfaceName>
    </Interface>
  </Interfaces>
  <Attributes>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2">
      <AttributeName>System.Diagnostics.DebuggerDisplay("{DebuggerDisplayString ()}")</AttributeName>
    </Attribute>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2">
      <AttributeName>Serializable</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Zawiera szczegółowe informacje dotyczące danych wejściowych, który został rozpoznany przez wystąpienia <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> lub <see cref="T:System.Speech.Recognition.SpeechRecognizer" />.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ta klasa jest pochodną <xref:System.Speech.Recognition.RecognizedPhrase> i udostępnia szczegółowe informacje na temat rozpoznawanie mowy, w tym następujące:  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> Odwołania do właściwości <xref:System.Speech.Recognition.Grammar> , aparat rozpoznawania używany do identyfikowania mowy.  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> Właściwość zawiera tekst znormalizowane frazy. Aby uzyskać więcej informacji na temat normalizacji tekstu zobacz <xref:System.Speech.Recognition.ReplacementText>.  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> Semantycznego informacji zawartych w wyniku odwołuje się do właściwości. Informacje semantyczne jest słownik nazw kluczy i skojarzone dane semantycznego.  
  
-   <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> Właściwość zawiera zbiór <xref:System.Speech.Recognition.RecognizedPhrase> obiekty reprezentujące interpretacji inne Release candidate wejścia audio. Zobacz <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> Aby uzyskać dodatkowe informacje.  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Właściwość zawiera uporządkowany zbiór <xref:System.Speech.Recognition.RecognizedWordUnit> obiekty reprezentujące każdego rozpoznane słowa w danych wejściowych. Każdy <xref:System.Speech.Recognition.RecognizedWordUnit> zawiera format wyświetlania, format leksykalne i informacje Wymowa dla odpowiedniego programu word.  
  
 Niektórych członków <xref:System.Speech.Recognition.SpeechRecognitionEngine>, <xref:System.Speech.Recognition.SpeechRecognizer>, i <xref:System.Speech.Recognition.Grammar> można wygenerować klas <xref:System.Speech.Recognition.RecognitionResult>. Aby uzyskać więcej informacji zobacz następujące metody i zdarzenia.  
  
-   Metody i zdarzenia <xref:System.Speech.Recognition.SpeechRecognitionEngine> klasy:  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>  
  
-   Metody i zdarzenia <xref:System.Speech.Recognition.SpeechRecognizer> klasy:  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>  
  
-   <xref:System.Speech.Recognition.Grammar.SpeechRecognized> Zdarzenia <xref:System.Speech.Recognition.Grammar> klasy.  
  
 Aby uzyskać więcej informacji na temat rozpoznawania zdarzeń, zobacz [przy użyciu zdarzenia rozpoznawania mowy](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482).  
  
   
  
## Examples  
 W poniższym przykładzie pokazano program obsługi `SpeechRecognized` zdarzenia <xref:System.Speech.Recognition.SpeechRecognitionEngine> lub <xref:System.Speech.Recognition.SpeechRecognizer> obiektu, a niektóre informacje na temat skojarzonego <xref:System.Speech.Recognition.RecognitionResult>.  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Grammar({0}), {1}: {2}",  
    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  
  
  // Display the semantic values in the recognition result.  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine(" {0} key: {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  
    Console.WriteLine(" {0,-10} {1,-10} {2,-10} {3} ({4})",  
      word.Text, word.LexicalForm, word.Pronunciation,  
      audio.Duration, word.DisplayAttributes);  
  }  
  
  // Display the recognition alternates for the result.  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine(" alt({0}) {1}", phrase.Confidence, phrase.Text);  
  }  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
    <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
    <altmember cref="E:System.Speech.Recognition.Grammar.SpeechRecognized" />
  </Docs>
  <Members>
    <Member MemberName="Alternates">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt; Alternates { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizedPhrase&gt; Alternates" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognitionResult.Alternates" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Alternates As ReadOnlyCollection(Of RecognizedPhrase)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ Alternates { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Alternates : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;" Usage="System.Speech.Recognition.RecognitionResult.Alternates" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera kolekcję możliwych dopasowań dla danych wejściowych do rozpoznawania mowy.</summary>
        <value>Kolekcja tylko do odczytu alternatyw rozpoznawania.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Rozpoznawanie <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> są uporządkowane według wartości ich <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> właściwości. Wartość ufności danej frazy oznacza prawdopodobieństwo, że frazę odpowiada danych wejściowych. Wyrażenie o najwyższej wartości zaufania jest frazę, która najprawdopodobniej dopasowuje dane wejściowe.  
  
 Każdy <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> wartość powinna być oceniana indywidualnie i bez odwołania do wartości ufności innych <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>. Właściwości, <xref:System.Speech.Recognition.RecognitionResult> dziedziczy <xref:System.Speech.Recognition.RecognizedPhrase> zawierają szczegółowe informacje o zwrot z najwyższym wynikiem zaufania.  
  
 Jednym z zastosowań <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> kolekcja jest do korekcji błędów automatycznych. Na przykład podczas projektowania okna dialogowego katalogu, aplikacja może monitować użytkownika do sprawdzania, jeśli aplikacja ma poprawne informacje ze zdarzenia rozpoznawania, na przykład "wyjaśnić, co znaczy"Anna"?" Jeśli użytkownik jest wyświetlany komunikat "nie", a następnie aplikacja może wysłać zapytania do użytkownika o zastępców, które miały wystarczająco wysokiego <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> wynik.  
  
 Aby uzyskać więcej informacji na temat rozpoznawanie mowy i wykorzystania zastępców rozpoznawania zobacz [rozpoznawania mowy](http://msdn.microsoft.com/library/6a7dc524-07fc-4862-8d48-8c10dc64b919) i [przy użyciu zdarzenia rozpoznawania mowy](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482).  
  
   
  
## Examples  
 W poniższym przykładzie pokazano program obsługi `SpeechRecognized` zdarzeń, a niektóre informacje na temat skojarzonego <xref:System.Speech.Recognition.RecognitionResult>.  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Grammar({0}), {1}: {2}",  
    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  
  
  // Display the semantic values in the recognition result.  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine(" {0} key: {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  
    Console.WriteLine(" {0,-10} {1,-10} {2,-10} {3} ({4})",  
      word.Text, word.LexicalForm, word.Pronunciation,  
      audio.Duration, word.DisplayAttributes);  
  }  
  
  // Display the recognition alternates for the result.  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine(" alt({0}) {1}", phrase.Confidence, phrase.Text);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
        <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
      </Docs>
    </Member>
    <Member MemberName="Audio">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizedAudio Audio { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.RecognizedAudio Audio" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognitionResult.Audio" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Audio As RecognizedAudio" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizedAudio ^ Audio { System::Speech::Recognition::RecognizedAudio ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Audio : System.Speech.Recognition.RecognizedAudio" Usage="System.Speech.Recognition.RecognitionResult.Audio" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizedAudio</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera dźwięk skojarzonego z wynikiem rozpoznawania.</summary>
        <value>Dźwięk skojarzonego z wynikiem rozpoznawanie lub <see langword="null" /> Jeśli aparat rozpoznawania generowany wynik po wywołaniu <see langword="EmulateRecognize" /> lub <see langword="EmulateRecognizeAsync" /> metody <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> lub <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> wystąpienia.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aby uzyskać części dźwięk, który jest skojarzony z określonego zakresu słów w wyniku rozpoznawania, użyj <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A> metody.  
  
   
  
## Examples  
 W poniższym przykładzie pokazano program obsługi **SpeechRecognized** zdarzeń, a niektóre informacje na temat skojarzonego <xref:System.Speech.Recognition.RecognitionResult>.  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
      Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
      Console.WriteLine("Audio for result:");  
      Console.WriteLine("  Start time: "+ e.Result.Audio.StartTime);  
      Console.WriteLine("  Duration: " + e.Result.Audio.Duration);  
      Console.WriteLine("  Format: " + e.Result.Audio.Format.EncodingFormat);  
  
  // Display the semantic values in the recognition result.  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine(" {0} key: {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  
    Console.WriteLine(" {0,-10} {1,-10} {2,-10} {3} ({4})",  
      word.Text, word.LexicalForm, word.Pronunciation,  
      audio.Duration, word.DisplayAttributes);  
  }  
  
  // Display the recognition alternates for the result.  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine(" alt({0}) {1}", phrase.Confidence, phrase.Text);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
        <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
        <altmember cref="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)" />
      </Docs>
    </Member>
    <Member MemberName="GetAudioForWordRange">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizedAudio GetAudioForWordRange (System.Speech.Recognition.RecognizedWordUnit firstWord, System.Speech.Recognition.RecognizedWordUnit lastWord);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognizedAudio GetAudioForWordRange(class System.Speech.Recognition.RecognizedWordUnit firstWord, class System.Speech.Recognition.RecognizedWordUnit lastWord) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)" />
      <MemberSignature Language="VB.NET" Value="Public Function GetAudioForWordRange (firstWord As RecognizedWordUnit, lastWord As RecognizedWordUnit) As RecognizedAudio" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognizedAudio ^ GetAudioForWordRange(System::Speech::Recognition::RecognizedWordUnit ^ firstWord, System::Speech::Recognition::RecognizedWordUnit ^ lastWord);" />
      <MemberSignature Language="F#" Value="member this.GetAudioForWordRange : System.Speech.Recognition.RecognizedWordUnit * System.Speech.Recognition.RecognizedWordUnit -&gt; System.Speech.Recognition.RecognizedAudio" Usage="recognitionResult.GetAudioForWordRange (firstWord, lastWord)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizedAudio</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="firstWord" Type="System.Speech.Recognition.RecognizedWordUnit" />
        <Parameter Name="lastWord" Type="System.Speech.Recognition.RecognizedWordUnit" />
      </Parameters>
      <Docs>
        <param name="firstWord">Pierwszy wyraz w zakresie.</param>
        <param name="lastWord">Ostatni wyraz w zakresie.</param>
        <summary>Pobiera część dźwięk, który jest skojarzony z określonego zakresu słów w wyniku rozpoznawania.</summary>
        <returns>Część audio, związanych z zakresu programu word.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aby uzyskać pełną dźwięk skojarzonego z wynik rozpoznawania, użyj <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> właściwości.  
  
   
  
## Examples  
 Poniższy przykład tworzy gramatyki do przyjmowania danych wejściowych nazwy i dołącza do niej obsługi dla `SpeechRecognized` zdarzeń. Gramatyka używa symbolu wieloznacznego elementu name frazy. Obsługa zdarzeń używa audio z symbolu wieloznacznego do tworzenia i Odtwórz wiersza pozdrowienia.  
  
```csharp  
  
private Grammar CreateNameInputGrammar()  
{  
  GrammarBuilder wildcardBuilder = new GrammarBuilder();  
  wildcardBuilder.AppendWildcard();  
  SemanticResultKey nameKey =  
    new SemanticResultKey("Name", wildcardBuilder);  
  
  GrammarBuilder nameBuilder =  
    new GrammarBuilder("My name is");  
  nameBuilder.Append(nameKey);  
  
  Grammar nameGrammar = new Grammar(nameBuilder);  
  nameGrammar.Name = "Name input";  
  
  nameGrammar.SpeechRecognized +=  
    new EventHandler<SpeechRecognizedEventArgs>(  
      NameInputHandler);  
  
  return nameGrammar;  
}  
  
// Handle the SpeechRecognized event for the name grammar.  
private void NameInputHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  RecognitionResult result = e.Result;  
  SemanticValue semantics = e.Result.Semantics;  
  
  if (semantics.ContainsKey("Name"))  
  {  
    RecognizedAudio nameAudio =  
      result.GetAudioForWordRange(  
        result.Words[3], result.Words[result.Words.Count - 1]);  
  
    // Save the audio. Create a directory and file as necessary.  
    FileInfo fi = new FileInfo(@"C:\temp\temp.wav");  
    if (!fi.Directory.Exists)  
    {  
      fi.Directory.Create();  
    }  
    FileStream stream = new FileStream(fi.FullName, FileMode.Create);  
    nameAudio.WriteToWaveStream(stream);  
    stream.Close();  
  
    // Greet the person using the saved audio.  
    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  
    PromptBuilder builder = new PromptBuilder();  
    builder.AppendText("Hello");  
    builder.AppendAudio(fi.FullName);  
    synthesizer.Speak(builder);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.NullReferenceException">Aparat rozpoznawania generowany wynik po wywołaniu <see langword="EmulateRecognize" /> lub <see langword="EmulateRecognizeAsync" /> metody <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> lub <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> obiektów.</exception>
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
        <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
        <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Audio" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      </Docs>
    </Member>
    <Member MemberName="System.Runtime.Serialization.ISerializable.GetObjectData">
      <MemberSignature Language="C#" Value="void ISerializable.GetObjectData (System.Runtime.Serialization.SerializationInfo info, System.Runtime.Serialization.StreamingContext context);" />
      <MemberSignature Language="ILAsm" Value=".method hidebysig newslot virtual instance void System.Runtime.Serialization.ISerializable.GetObjectData(class System.Runtime.Serialization.SerializationInfo info, valuetype System.Runtime.Serialization.StreamingContext context) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)" />
      <MemberSignature Language="VB.NET" Value="Sub GetObjectData (info As SerializationInfo, context As StreamingContext) Implements ISerializable.GetObjectData" />
      <MemberSignature Language="C++ CLI" Value=" virtual void System.Runtime.Serialization.ISerializable.GetObjectData(System::Runtime::Serialization::SerializationInfo ^ info, System::Runtime::Serialization::StreamingContext context) = System::Runtime::Serialization::ISerializable::GetObjectData;" />
      <MemberType>Method</MemberType>
      <Implements>
        <InterfaceMember>M:System.Runtime.Serialization.ISerializable.GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)</InterfaceMember>
      </Implements>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="info" Type="System.Runtime.Serialization.SerializationInfo" />
        <Parameter Name="context" Type="System.Runtime.Serialization.StreamingContext" />
      </Parameters>
      <Docs>
        <param name="info">Obiekt używany do wypełniania danymi.</param>
        <param name="context">Miejsce docelowe dla serializacji.</param>
        <summary>Wypełnia <see cref="T:System.Runtime.Serialization.SerializationInfo" /> wystąpienia dane potrzebne do zserializowania obiektu docelowego.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ten element jest jawną implementacją członków. Mogą być używane tylko wtedy, gdy <xref:System.Speech.Recognition.RecognitionResult> wystąpienia jest rzutowany na <xref:System.Runtime.Serialization.ISerializable> interfejsu.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Runtime.Serialization.ISerializable" />
        <altmember cref="T:System.Runtime.Serialization.SerializationInfo" />
        <altmember cref="T:System.Runtime.Serialization.StreamingContext" />
      </Docs>
    </Member>
  </Members>
</Type>