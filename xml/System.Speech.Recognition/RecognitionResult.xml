<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="RecognitionResult.xml" source-language="en-US" target-language="pl-PL">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-15c36f0" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">02cd5861-7ce2-4a82-b358-31f8435a0ac558dc7fd01cd9580179bf403a5d3c0b372c8b28ee.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">58dc7fd01cd9580179bf403a5d3c0b372c8b28ee</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/03/2018</xliffext:ms.lasthandoff>
      <xliffext:moniker_ids xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">netframework-4.5.1,netframework-4.5.2,netframework-4.5,netframework-4.6.1,netframework-4.6.2,netframework-4.6,netframework-4.7.1,netframework-4.7</xliffext:moniker_ids>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>Contains detailed information about input that was recognized by instances of <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> or <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>.</source>
          <target state="translated">Zawiera szczegółowe informacje o danych wejściowych, który został rozpoznany przez wystąpienia <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> lub <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>This class derives from <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> and provides detailed information about speech recognition, including the following:</source>
          <target state="translated">Ta klasa pochodzi od <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> i zawiera szczegółowe informacje na temat rozpoznawania mowy, takie jak:</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A&gt;</ph> property references the <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> that the recognizer used to identify the speech.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A&gt;</ph> Odwołań do właściwości <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> czy aparat rozpoznawania używany do identyfikowania mowy.</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Text%2A&gt;</ph> property contains the normalized text for the phrase.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Text%2A&gt;</ph> Właściwość zawiera tekst znormalizowane wyrażenie.</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>For more information about text normalization, see <ph id="ph1">&lt;xref:System.Speech.Recognition.ReplacementText&gt;</ph>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat normalizacji tekstu, zobacz <ph id="ph1">&lt;xref:System.Speech.Recognition.ReplacementText&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A&gt;</ph> property references the semantic information contained in the result.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A&gt;</ph> Semantycznego informacje zawarte w wyniku odwołuje się do właściwości.</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>The semantic information is a dictionary of the key names and associated semantic data.</source>
          <target state="translated">Informacje semantyczne jest słownikiem nazwy kluczy i skojarzone dane semantycznego.</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> property contains a collection of <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> objects that represent other candidate interpretations of the audio input.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> Właściwość zawiera zbiór <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> obiektów, które reprezentują inne interpretacji candidate wejście audio.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>See <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> for additional information.</source>
          <target state="translated">Zobacz <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> Aby uzyskać dodatkowe informacje.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Words%2A&gt;</ph> property contains an ordered collection of <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedWordUnit&gt;</ph> objects that represent each recognized word in the input.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Words%2A&gt;</ph> Właściwość zawiera uporządkowaną kolekcję <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedWordUnit&gt;</ph> obiekty reprezentujące każdego rozpoznany programu word w danych wejściowych.</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedWordUnit&gt;</ph> contains display format, lexical format, and pronunciation information for the corresponding word.</source>
          <target state="translated">Każdy <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedWordUnit&gt;</ph> zawiera informacje wymowy dla odpowiedniego programu word, format leksykalne i format wyświetlania.</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>Certain members of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, and <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> classes can generate a <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</source>
          <target state="translated">Niektóre elementy członkowskie z <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, i <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> klasy może powodować generowanie <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>For more information, see the following methods and events.</source>
          <target state="translated">Aby uzyskać więcej informacji zobacz następujące metod i zdarzeń.</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>Methods and events of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> class:</source>
          <target state="translated">Metody i zdarzenia <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> klasy:</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>Methods and events of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class:</source>
          <target state="translated">Metody i zdarzenia <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> klasy:</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event of the <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> class.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> Zdarzenie <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> klasy.</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>For more information about recognition events, see <bpt id="p1">[</bpt>Using Speech Recognition Events<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji o zdarzeniach rozpoznawania, zobacz <bpt id="p1">[</bpt>przy użyciu zdarzenia rozpoznawania mowy<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept>.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognitionResult">
          <source>The following example shows a handler for the <ph id="ph1">`SpeechRecognized`</ph> event of a <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> or <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object, and some of the information about the associated <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</source>
          <target state="translated">W poniższym przykładzie przedstawiono obsługi dla <ph id="ph1">`SpeechRecognized`</ph> zdarzenie <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> lub <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> obiektu, a niektóre informacje o skojarzonych <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.RecognitionResult.Alternates">
          <source>Gets the collection of possible matches for input to the speech recognizer.</source>
          <target state="translated">Pobiera kolekcję możliwych dopasowań dla danych wejściowych do rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognitionResult.Alternates">
          <source>A read-only collection of the recognition alternates.</source>
          <target state="translated">Kolekcja tylko do odczytu alternatyw rozpoznawania.</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognitionResult.Alternates">
          <source>Recognition <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> are ordered by the values of their <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> properties.</source>
          <target state="translated">Rozpoznawanie <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> są uporządkowane według wartości ich <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognitionResult.Alternates">
          <source>The confidence value of a given phrase indicates the probability that the phrase matches the input.</source>
          <target state="translated">Wartość zaufania danego frazy wskazuje prawdopodobieństwo frazę zgodność danych wejściowych.</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognitionResult.Alternates">
          <source>The phrase with the highest confidence value is the phrase that most likely matches the input.</source>
          <target state="translated">Wyrażenie o najwyższej wartości zaufania jest frazę, które najprawdopodobniej odpowiada danych wejściowych.</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognitionResult.Alternates">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> value should be evaluated individually and without reference to the confidence values of other <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph>.</source>
          <target state="translated">Każdy <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> wartości powinny być oceniane oddzielnie i bez odwołania do wartości zaufania innych <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognitionResult.Alternates">
          <source>The properties that the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> inherits from <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> provide detailed information about the phrase with the highest confidence score.</source>
          <target state="translated">Właściwości który <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> dziedziczy <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> zawierają szczegółowe informacje o zwrot z najwyższym wynik zaufania.</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognitionResult.Alternates">
          <source>One use for the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> collection is for automated error correction.</source>
          <target state="translated">Użycie jednego <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> kolekcji dotyczy korekcja błędów automatycznych.</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognitionResult.Alternates">
          <source>For example, when designing a directory dialog, an application could prompt the user to check if the application has the correct information from a recognition event, as in, "Did you say 'Anna'?" If the user says "no", then the application could query the user about any alternates that had a high enough <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> score.</source>
          <target state="translated">Na przykład podczas projektowania katalogu okna dialogowego, aplikacja może Monituj użytkownika o Sprawdź, czy aplikacja ma poprawne informacje ze zdarzenia rozpoznawania, podobnie jak w "wyjaśnić, co znaczy"Anna"?" Jeśli użytkownik odpowie "nie", a następnie aplikacja może wykonać kwerendy dla użytkownika o zastępców, które miały wystarczająco duży <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> wynik.</target>       </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognitionResult.Alternates">
          <source>For more information about speech recognition and the use of recognition alternates, see <bpt id="p1">[</bpt>Speech Recognition<ept id="p1">](http://msdn.microsoft.com/library/6a7dc524-07fc-4862-8d48-8c10dc64b919)</ept> and <bpt id="p2">[</bpt>Using Speech Recognition Events<ept id="p2">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat rozpoznawania mowy i użyj alternatyw rozpoznawania, zobacz <bpt id="p1">[</bpt>rozpoznawania mowy<ept id="p1">](http://msdn.microsoft.com/library/6a7dc524-07fc-4862-8d48-8c10dc64b919)</ept> i <bpt id="p2">[</bpt>przy użyciu zdarzenia rozpoznawania mowy<ept id="p2">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept>.</target>       </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognitionResult.Alternates">
          <source>The following example shows a handler for the <ph id="ph1">`SpeechRecognized`</ph> event and some of the information about the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</source>
          <target state="translated">W poniższym przykładzie przedstawiono obsługi dla <ph id="ph1">`SpeechRecognized`</ph> zdarzeń, a niektóre informacje na temat skojarzony <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.RecognitionResult.Audio">
          <source>Gets the audio associated with the recognition result.</source>
          <target state="translated">Pobiera audio skojarzony z wynikiem rozpoznawania.</target>       </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognitionResult.Audio">
          <source>The audio associated with the recognition result or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the recognizer generated the result from a call to the <ph id="ph2">&lt;see langword="EmulateRecognize" /&gt;</ph> or <ph id="ph3">&lt;see langword="EmulateRecognizeAsync" /&gt;</ph> methods of a <ph id="ph4">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> or <ph id="ph5">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> instance.</source>
          <target state="translated">Dźwięk skojarzony z wynikiem rozpoznawania lub <ph id="ph1">&lt;see langword="null" /&gt;</ph> Jeśli aparat rozpoznawania wygenerowanych wynik po wywołaniu <ph id="ph2">&lt;see langword="EmulateRecognize" /&gt;</ph> lub <ph id="ph3">&lt;see langword="EmulateRecognizeAsync" /&gt;</ph> metody <ph id="ph4">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> lub <ph id="ph5">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> wystąpienia.</target>       </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognitionResult.Audio">
          <source>To get a section of the audio that is associated with a specific range of words in the recognition result, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A&gt;</ph> method.</source>
          <target state="translated">Aby uzyskać części audio, który jest skojarzony z określonego zakresu słów w wyniku rozpoznawania, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognitionResult.Audio">
          <source>The following example shows a handler for the <bpt id="p1">**</bpt>SpeechRecognized<ept id="p1">**</ept> event and some of the information about the associated <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</source>
          <target state="translated">W poniższym przykładzie przedstawiono obsługi dla <bpt id="p1">**</bpt>SpeechRecognized<ept id="p1">**</ept> zdarzeń, a niektóre informacje na temat skojarzony <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)">
          <source>The first word in the range.</source>
          <target state="translated">Pierwsze słowo w zakresie.</target>       </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)">
          <source>The last word in the range.</source>
          <target state="translated">Wyraz ostatniej w zakresie.</target>       </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)">
          <source>Gets a section of the audio that is associated with a specific range of words in the recognition result.</source>
          <target state="translated">Pobiera część audio, który jest skojarzony z określonego zakresu słów w wyniku rozpoznawania.</target>       </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)">
          <source>The section of audio associated with the word range.</source>
          <target state="translated">Sekcja nagrań audio, związanych z zakresem programu word.</target>       </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)">
          <source>To get the complete audio associated with the recognition result, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.</source>
          <target state="translated">Aby uzyskać pełną nagrań audio, związanych z wynikiem rozpoznawania, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)">
          <source>The following example creates a grammar to accept name input and attaches to it a handler for the <ph id="ph1">`SpeechRecognized`</ph> event.</source>
          <target state="translated">Poniższy przykład tworzy gramatyki do przyjmowania danych wejściowych nazwy i dołącza do jej obsługi dla <ph id="ph1">`SpeechRecognized`</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)">
          <source>The grammar uses a wildcard for the name element of the phrase.</source>
          <target state="translated">Gramatyka używa symbolu wieloznacznego elementu name frazy.</target>       </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)">
          <source>The event handler uses the audio from the wildcard to create and play a greeting prompt.</source>
          <target state="translated">Program obsługi zdarzeń używa dźwięku symbol wieloznaczny do tworzenia i odtwarzać wiersza pozdrowienia.</target>       </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)">
          <source>The recognizer generated the result from a call to <ph id="ph1">&lt;see langword="EmulateRecognize" /&gt;</ph> or <ph id="ph2">&lt;see langword="EmulateRecognizeAsync" /&gt;</ph> methods of the <ph id="ph3">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> or <ph id="ph4">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> objects.</source>
          <target state="translated">Aparat rozpoznawania wygenerowanych wynik po wywołaniu <ph id="ph1">&lt;see langword="EmulateRecognize" /&gt;</ph> lub <ph id="ph2">&lt;see langword="EmulateRecognizeAsync" /&gt;</ph> metody <ph id="ph3">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> lub <ph id="ph4">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)">
          <source>The object to populate with data.</source>
          <target state="translated">Obiekt używany do wypełniania danymi.</target>       </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)">
          <source>The destination for the serialization.</source>
          <target state="translated">Lokalizacja docelowa dla serializacji.</target>       </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)">
          <source>Populates a <ph id="ph1">&lt;see cref="T:System.Runtime.Serialization.SerializationInfo" /&gt;</ph> instance with the data needed to serialize the target object.</source>
          <target state="translated">Wypełnia <ph id="ph1">&lt;see cref="T:System.Runtime.Serialization.SerializationInfo" /&gt;</ph> wystąpienia o dane potrzebne do zserializowania obiektu docelowego.</target>       </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)">
          <source>This member is an explicit interface member implementation.</source>
          <target state="translated">Ten element jest jawną implementacją członków.</target>       </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)">
          <source>It can be used only when the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> instance is cast to an <ph id="ph2">&lt;xref:System.Runtime.Serialization.ISerializable&gt;</ph> interface.</source>
          <target state="translated">Można go używać tylko wtedy, gdy <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> wystąpienia jest rzutowane na <ph id="ph2">&lt;xref:System.Runtime.Serialization.ISerializable&gt;</ph> interfejsu.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>