<Type Name="AudioStateChangedEventArgs" FullName="System.Speech.Recognition.AudioStateChangedEventArgs">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="da3ae36f24bf9b80dfa482fd66b88e786e5cccce" />
    <Meta Name="ms.sourcegitcommit" Value="d877ae76e9e11799bf919379507239e2c4072742" />
    <Meta Name="ms.translationtype" Value="MT" />
    <Meta Name="ms.contentlocale" Value="pl-PL" />
    <Meta Name="ms.lasthandoff" Value="08/09/2018" />
    <Meta Name="ms.locfileid" Value="39855451" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class AudioStateChangedEventArgs : EventArgs" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit AudioStateChangedEventArgs extends System.EventArgs" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.AudioStateChangedEventArgs" />
  <TypeSignature Language="VB.NET" Value="Public Class AudioStateChangedEventArgs&#xA;Inherits EventArgs" />
  <TypeSignature Language="C++ CLI" Value="public ref class AudioStateChangedEventArgs : EventArgs" />
  <TypeSignature Language="F#" Value="type AudioStateChangedEventArgs = class&#xA;    inherit EventArgs" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.EventArgs</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>Udostępnia dane dla <see langword="AudioStateChanged" /> zdarzenia <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> lub <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> klasy.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> Właściwości pobiera nowe wystąpienie klasy <xref:System.Speech.Recognition.AudioState> wyliczenie podczas <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged?displayProperty=nameWithType> lub <xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged?displayProperty=nameWithType> zdarzenie jest wywoływane.  
  
 Można uzyskać bieżący stan audio danych wejściowych przy użyciu `AudioState` właściwość <xref:System.Speech.Recognition.SpeechRecognizer> lub <xref:System.Speech.Recognition.SpeechRecognitionEngine> klasy.  
  
   
  
## Examples  
 W poniższym przykładzie pokazano program obsługi zdarzeń do obsługi zmiany stanu audio aparatu rozpoznawania mowy.  
  
```csharp  
  
private SpeechRecognitionEngine sre;  
  
// Initialize the SpeechRecognitionEngine object.   
private void Initialize()  
{  
  sre = new SpeechRecognitionEngine();  
  
  // Add a handler for the AudioStateChanged event.  
  sre.AudioStateChanged += new EventHandler<AudioStateChangedEventArgs>(sre_AudioStateChanged);  
  
  // Add other initialization code here.  
}  
  
// Handle the AudioStateChanged event.   
void sre_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  
{  
  AudioState newState = e.AudioState;  
  
  // Handle event here.  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.AudioState" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged" />
    <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioState" />
    <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioState" />
  </Docs>
  <Members>
    <Member MemberName="AudioState">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.AudioState AudioState { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.AudioState AudioState" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioState As AudioState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::AudioState AudioState { System::Speech::Recognition::AudioState get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioState : System.Speech.Recognition.AudioState" Usage="System.Speech.Recognition.AudioStateChangedEventArgs.AudioState" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.AudioState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera nowy stan wejścia audio dla aparatu rozpoznawania.</summary>
        <value>Stan wejścia audio po <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged" /> lub <see cref="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged" /> zdarzenie jest wywoływane.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> Właściwość zawiera jedną z trzech wartości z <xref:System.Speech.Recognition.AudioState> wyliczenia.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioState" />
      </Docs>
    </Member>
  </Members>
</Type>