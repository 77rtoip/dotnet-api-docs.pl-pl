<Type Name="RecognizerState" FullName="System.Speech.Recognition.RecognizerState">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="d33bdbe741762a07aaa678a9729992805e7da646" />
    <Meta Name="ms.sourcegitcommit" Value="d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b" />
    <Meta Name="ms.translationtype" Value="MT" />
    <Meta Name="ms.contentlocale" Value="pl-PL" />
    <Meta Name="ms.lasthandoff" Value="04/03/2018" />
    <Meta Name="ms.locfileid" Value="30578305" />
  </Metadata>
  <TypeSignature Language="C#" Value="public enum RecognizerState" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed RecognizerState extends System.Enum" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizerState" />
  <TypeSignature Language="VB.NET" Value="Public Enum RecognizerState" />
  <TypeSignature Language="C++ CLI" Value="public enum class RecognizerState" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Enum</BaseTypeName>
  </Base>
  <Docs>
    <summary>Wylicza wartości stanu aparat rozpoznawania.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Recognition.RecognizerState> hermetyzuje stan działania domyślny aparat rozpoznawania mowy dla klientów korzystających z <xref:System.Speech.Recognition.SpeechRecognizer> do uzyskania dostępu do usługi technologii rozpoznawania mowy pulpitu systemu Windows.  
  
 Aplikacje mogą uzyskać bieżący stan aparatu rozpoznawania pulpitu jako <xref:System.Speech.Recognition.RecognizerState> obiektu badając <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> właściwość <xref:System.Speech.Recognition.SpeechRecognizer> wystąpienia.  Aby uzyskać stan aparatu rozpoznawania pulpitu, po jego zmian, aplikacje można zbadać <xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A> właściwość <xref:System.Speech.Recognition.StateChangedEventArgs> obiekt przekazany do obsługi dla <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> zdarzenia.  
  
> [!NOTE]
>  <xref:System.Speech.Recognition.SpeechRecognitionEngine> w trakcie uruchamiania wystąpień i ich stan jest pod kontrolą aplikacji. W związku z tym <xref:System.Speech.Recognition.SpeechRecognitionEngine> nie zawiera właściwości do zwrócenia <xref:System.Speech.Recognition.RecognizerState> obiektu.  
  
 Stan serwera rozpoznawania mowy pulpitu jest właściwością tylko do odczytu i nie mogą być kontrolowane programowo. Użytkownicy mogą zmieniać stan aparatu rozpoznawania mowy udostępnionych za pomocą interfejsu użytkownika (UI) rozpoznawanie mowy lub za pomocą **rozpoznawania mowy** członkiem systemu Windows **Panelu sterowania**.  
  
 Zarówno **na** i **uśpienia** ustawienia w interfejsie użytkownika rozpoznawania mowy odpowiadają `Listening` stanu. **Poza** ustawienie w interfejsie użytkownika rozpoznawania mowy odpowiada na zatrzymane.  
  
 <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> jest właściwość, która wpływa na gotowość aparat rozpoznawania mowy udostępnionych w celu odbierania i przetwarzania danych wejściowych mowy. Można użyć <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> do kontrolowania, czy aparat rozpoznawania mowy udostępnionego gramatyki są aktywne dla rozpoznawania. Jednak zmiana <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> właściwość nie ma wpływu <xref:System.Speech.Recognition.RecognizerState> właściwości.  
  
 Informacje, takie jak opis obsługiwaną kulturą i formatów audio i nazwa aparatu rozpoznawania jest hermetyzowany w <xref:System.Speech.Recognition.RecognizerInfo> typu.  
  
   
  
## Examples  
 W poniższym przykładzie aplikacja wyświetla stan aparatu rozpoznawania w swojej implementacji obsługi dla <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> zdarzeń.  
  
```  
  
_recognizer.StateChanged +=  
    delegate(object sender, StateChangedEventArgs eventArgs) {  
        _recognizerStateLabel.Text = "Speech Recognizer State: " + eventArgs.RecognizerState.ToString();  
    };  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="P:System.Speech.Recognition.StateChangedEventArgs.RecognizerState" />
    <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
    <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
    <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
    <altmember cref="T:System.Speech.Recognition.StateChangedEventArgs" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
  </Docs>
  <Members>
    <Member MemberName="Listening">
      <MemberSignature Language="C#" Value="Listening" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype System.Speech.Recognition.RecognizerState Listening = int32(1)" />
      <MemberSignature Language="DocId" Value="F:System.Speech.Recognition.RecognizerState.Listening" />
      <MemberSignature Language="VB.NET" Value="Listening" />
      <MemberSignature Language="C++ CLI" Value="Listening" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <MemberValue>1</MemberValue>
      <Docs>
        <summary>Aparat rozpoznawania jest dostępna do pobierania i analizowania wejście audio.</summary>
      </Docs>
    </Member>
    <Member MemberName="Stopped">
      <MemberSignature Language="C#" Value="Stopped" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype System.Speech.Recognition.RecognizerState Stopped = int32(0)" />
      <MemberSignature Language="DocId" Value="F:System.Speech.Recognition.RecognizerState.Stopped" />
      <MemberSignature Language="VB.NET" Value="Stopped" />
      <MemberSignature Language="C++ CLI" Value="Stopped" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <MemberValue>0</MemberValue>
      <Docs>
        <summary>Aparat rozpoznawania nie jest odbieranie lub analizowanie danych wejściowych danych audio.</summary>
      </Docs>
    </Member>
  </Members>
</Type>