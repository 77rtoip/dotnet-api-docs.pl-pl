<Type Name="RecognizedWordUnit" FullName="System.Speech.Recognition.RecognizedWordUnit">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="95cbc484ad2f61d90e672b839c60865c972a6fea" />
    <Meta Name="ms.sourcegitcommit" Value="d877ae76e9e11799bf919379507239e2c4072742" />
    <Meta Name="ms.translationtype" Value="MT" />
    <Meta Name="ms.contentlocale" Value="pl-PL" />
    <Meta Name="ms.lasthandoff" Value="08/09/2018" />
    <Meta Name="ms.locfileid" Value="39988897" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class RecognizedWordUnit" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit RecognizedWordUnit extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizedWordUnit" />
  <TypeSignature Language="VB.NET" Value="Public Class RecognizedWordUnit" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognizedWordUnit" />
  <TypeSignature Language="F#" Value="type RecognizedWordUnit = class" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2">
      <AttributeName>System.Diagnostics.DebuggerDisplay("Text: {Text}")</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Udostępnia niepodzielnego rozpoznawanym mowy.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Wszystkie wyniki zwrócone przez aparat rozpoznawania są zbudowane z <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów.  
  
 Tablica <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów jest dostępny dla każdej operacji uznanie za pośrednictwem <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
 Oprócz zapewniania miary pewności rozpoznawania (<xref:System.Speech.Recognition.RecognizedWordUnit.Confidence%2A>) <xref:System.Speech.Recognition.RecognizedWordUnit> wystąpienie zapewnia:  
  
-   Znormalizowana i dokładne (lub leksykalne) tekstowa reprezentacja rozpoznawanym wyrazu. Aby uzyskać więcej informacji, zobacz <xref:System.Speech.Recognition.ReplacementText>, <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>, i <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>.  
  
-   Informacje o Wymowa przy użyciu znaków z obsługiwanych alfabet fonetyczny, takich jak międzynarodowy alfabet fonetyczny (IPA) lub uniwersalnych telefonu Ustaw (UPS). Aby uzyskać więcej informacji, zobacz <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>.  
  
-   Formatowanie drukowania. Aby uzyskać więcej informacji, zobacz <xref:System.Speech.Recognition.DisplayAttributes> klasy i jego <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> właściwości.  
  
   
  
## Examples  
 W poniższym przykładzie przedstawiono procedury narzędzie (`stringFromWordArray`) generujący ciągów. Ciągi zawierają dane wyjściowe leksykalne (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), znormalizowane tekstu (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), lub fonetycznych znaków z międzynarodowy alfabet fonetyczny (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Ciągi są formatowane przy użyciu <xref:System.Speech.Recognition.DisplayAttributes> obiektów uzyskany z <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> właściwość <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> z <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów. <xref:System.Speech.Recognition.RecognizedWordUnit> Obiekty są uzyskiwane z <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(ReadOnlyCollection<RecognizedWordUnit> words, WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(String.Format("[0}: is not a valid input", type));  
    }  
    // Use display attribute  
  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)  
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)  
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public RecognizedWordUnit (string text, float confidence, string pronunciation, string lexicalForm, System.Speech.Recognition.DisplayAttributes displayAttributes, TimeSpan audioPosition, TimeSpan audioDuration);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string text, float32 confidence, string pronunciation, string lexicalForm, valuetype System.Speech.Recognition.DisplayAttributes displayAttributes, valuetype System.TimeSpan audioPosition, valuetype System.TimeSpan audioDuration) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognizedWordUnit.#ctor(System.String,System.Single,System.String,System.String,System.Speech.Recognition.DisplayAttributes,System.TimeSpan,System.TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; RecognizedWordUnit(System::String ^ text, float confidence, System::String ^ pronunciation, System::String ^ lexicalForm, System::Speech::Recognition::DisplayAttributes displayAttributes, TimeSpan audioPosition, TimeSpan audioDuration);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.RecognizedWordUnit : string * single * string * string * System.Speech.Recognition.DisplayAttributes * TimeSpan * TimeSpan -&gt; System.Speech.Recognition.RecognizedWordUnit" Usage="new System.Speech.Recognition.RecognizedWordUnit (text, confidence, pronunciation, lexicalForm, displayAttributes, audioPosition, audioDuration)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="text" Type="System.String" />
        <Parameter Name="confidence" Type="System.Single" />
        <Parameter Name="pronunciation" Type="System.String" />
        <Parameter Name="lexicalForm" Type="System.String" />
        <Parameter Name="displayAttributes" Type="System.Speech.Recognition.DisplayAttributes" />
        <Parameter Name="audioPosition" Type="System.TimeSpan" />
        <Parameter Name="audioDuration" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="text">Znormalizowana tekst rozpoznany wyraz.  Ta wartość może być <see langword="null" />, "", lub <see cref="F:System.String.Empty" />.</param>
        <param name="confidence">A <see langword="float" /> wartość od 0,0 do 1,0, wskazując pewności rozpoznawania wyrazów.</param>
        <param name="pronunciation">Wymowę rozpoznany wyraz.  Ta wartość może być <see langword="null" />, "", lub <see cref="F:System.String.Empty" />.</param>
        <param name="lexicalForm">Tekst unnormalized rozpoznany wyraz.  Ten argument jest wymagany i może nie być <see langword="null" />, "", lub <see cref="F:System.String.Empty" />.</param>
        <param name="displayAttributes">Definiuje użytkowania światło, aby wyświetlić rozpoznane słowa.</param>
        <param name="audioPosition">Lokalizacja rozpoznany wyraz w strumieniu wejściowym audio.  Ta wartość może być <see cref="F:System.TimeSpan.Zero" />.</param>
        <param name="audioDuration">Długość audio wejściowych odpowiadający rozpoznany wyraz.  Ta wartość może być <see cref="F:System.TimeSpan.Zero" />.</param>
        <summary>Inicjuje nowe wystąpienie klasy <see cref="T:System.Speech.Recognition.RecognizedWordUnit" /> klasy.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Jeśli `text` lub `pronunciation` są `null`, "", lub <xref:System.String.Empty> i <xref:System.Speech.Recognition.RecognizedWordUnit> jest używany w ramach operacji rozpoznawania aparat rozpoznawania wygeneruje odpowiednie wartości w żadnych danych wyjściowych <xref:System.Speech.Recognition.RecognizedWordUnit> wystąpienia.  
  
 Bezpośrednie konstrukcja <xref:System.Speech.Recognition.RecognizedWordUnit> wystąpień jest zwykle używana tylko wtedy, gdy emulowanie uznanie operacji za pomocą <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> lub <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> metody <xref:System.Speech.Recognition.SpeechRecognitionEngine> klasy i <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> lub <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> metody <xref:System.Speech.Recognition.SpeechRecognizer> klasy.  
  
 W przypadku aplikacji rzeczywistych nie bezpośrednio utworzyć <xref:System.Speech.Recognition.RecognizedWordUnit>, zamiast go za pośrednictwem uzyskać <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
   
  
## Examples  
 Poniższy przykład jest to nieco contrived test emulacji, gdzie nowych słów są generowane na podstawie danych wejściowych i przekazane do emulatora, a następnie weryfikowany.  
  
```csharp  
private void _emulateAndVerify_Click(object sender, EventArgs e)   
{  
  char[] delimiterChars = { ' ', ',', '.', ':', ';', '\t' };  
  string text = _emulateTextBox.Text;  
  string[] words = text.Split(delimiterChars);  
  
  RecognizedWordUnit[] InputWordUnits = new RecognizedWordUnit[words.Length];  
  for (int i = 0; i < words.Length; i++)   
  {  
    InputWordUnits[i] = new RecognizedWordUnit(  
        "",   
        0,   
        "",  
        words[i].ToLower(),   
        DisplayAttributes.OneTrailingSpace,   
        new TimeSpan(),   
        new TimeSpan());  
  }  
  
  RecognitionResult rec = _recognizer.EmulateRecognize(  
        InputWordUnits,   
        System.Globalization.CompareOptions.IgnoreCase);  
  if (rec == null)   
  {  
    MessageBox.Show(String.Format("Recognition emulation for {0} failed.\n", text));  
  }   
  else if (InputWordUnits.Length != rec.Words.Count)   
  {  
    MessageBox.Show(  
       String.Format("Length mismatch: Input was {0} words, Recognition has {1} words.\n}"));  
  }   
  else   
  {  
    for (int i = 0; i < InputWordUnits.Length; i++)   
    {  
  
      if (rec.Words[i].LexicalForm.ToLower() != InputWordUnits[i].LexicalForm.ToLower())   
      {  
        MessageBox.Show(  
          String.Format("Input word {0} \"{1}\" not found. Recognition output is {2}",  
          i, InputWordUnits[i].LexicalForm, rec.Words[i].LexicalForm));  
        continue;  
      }  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="Confidence">
      <MemberSignature Language="C#" Value="public float Confidence { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance float32 Confidence" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.Confidence" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Confidence As Single" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property float Confidence { float get(); };" />
      <MemberSignature Language="F#" Value="member this.Confidence : single" Usage="System.Speech.Recognition.RecognizedWordUnit.Confidence" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Single</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera wartość przypisaną przez aparat rozpoznawania, reprezentujący prawdopodobieństwo, że rozpoznany wyraz pasuje do podanego danych wejściowych.</summary>
        <value>Względna miara pewności poprawne rozpoznawanie wyrazu. Wartość jest od 0,0 do 1,0, niski wysokiego zaufania, aby uzyskać odpowiednio.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Oceny zaufania nie wskazują na bezwzględny prawdopodobieństwo, że wyrazu została rozpoznana poprawnie. Zamiast tego oceny zaufania mechanizm umożliwiający porównanie względną dokładność wiele alternatyw rozpoznawania dla danego danych wejściowych. To ułatwia, zwracając najdokładniejszych wynik rozpoznawania. Na przykład jeśli rozpoznany wyraz ma współczynnik ufności 0,8, to oznacza, że wyraz ma szansę 80% są poprawne dopasowania dla danych wejściowych.  Oznacza to, że wyraz jest bardziej prawdopodobne, jako prawidłowego dopasowania dla danych wejściowych niż inne wyniki, które mają zaufanie ocenia mniejsza niż 0,8.  
  
 Współczynnik ufności, samodzielnie nie ma sensu, chyba że masz alternatywnych wyników, aby porównać z tej samej operacji rozpoznawania albo z poprzednich rozpoznawań tych samych danych wejściowych.  
  
 Wartości zwracane przez <xref:System.Speech.Recognition.RecognizedWordUnit.Confidence%2A> dotyczą każdego aparat rozpoznawania względnych i unikatowy. Jest nie definicji porównanie wartości zaufania między dwoma aparatów rozpoznawania w różnych ani jak <xref:System.Speech.Recognition.RecognizedWordUnit.Confidence%2A> indywidualnego <xref:System.Speech.Recognition.RecognizedWordUnit> Zdefiniuj obiekty <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> z <xref:System.Speech.Recognition.RecognizedPhrase>.  
  
 Aparat rozpoznawania mowy może przydzielić współczynnik ufności niski prowadzone danych wejściowych z różnych powodów, takie jak zakłócenia w tle, inarticulate mowy lub nieprzewidziane słowa lub sekwencji. Jeśli aplikacja wykorzystuje <xref:System.Speech.Recognition.SpeechRecognitionEngine> wystąpienia, możesz zmodyfikować poziom ufności, w których mowy danych wejściowych jest zaakceptowane lub odrzucone z jednym z <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> metody. Progi zaufania dla udostępnionego urządzenia rozpoznającego zarządzane przez <xref:System.Speech.Recognition.SpeechRecognizer>, są skojarzone z profilem użytkownika i przechowywane w rejestrze systemu Windows. Aplikacje nie powinien zapisać zmiany w rejestrze dla właściwości udostępniony aparat rozpoznawania.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="DisplayAttributes">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.DisplayAttributes DisplayAttributes { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.DisplayAttributes DisplayAttributes" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property DisplayAttributes As DisplayAttributes" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::DisplayAttributes DisplayAttributes { System::Speech::Recognition::DisplayAttributes get(); };" />
      <MemberSignature Language="F#" Value="member this.DisplayAttributes : System.Speech.Recognition.DisplayAttributes" Usage="System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.DisplayAttributes</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera formatowanie informacje używane do tworzenia tekst wyjściowy z bieżącej <see cref="T:System.Speech.Recognition.RecognizedWordUnit" /> wystąpienia.</summary>
        <value>Określa użycie biały znak do wyświetlania zawartości <see cref="T:System.Speech.Recognition.RecognizedWordUnit" /> obiektu.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Recognition.DisplayAttributes> Obiektu zwróconego przez <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> właściwość określa spacje początkowe i końcowe, które ma być używany z danego wyrazu, jeśli istnieje.  
  
 Aby uzyskać więcej informacji o sposobie używania tych informacji formatowania, zobacz <xref:System.Speech.Recognition.DisplayAttributes> wyliczenia.  
  
   
  
## Examples  
 W poniższym przykładzie przedstawiono procedury narzędzie (`stringFromWordArray`) generujący ciąg, który jest sformatowany w jeden z trzech sposobów: leksykalnie (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), jest to znormalizowane (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), lub fonetycznie (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Tekst wyjściowy jest uzyskiwana z <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> właściwość <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> z <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów, które są uzyskiwane z <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
        ReadOnlyCollection<RecognizedWordUnit> words,   
        WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }  
    else if (type == WordType.Pronunciation)   
    {  
       wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
         String.Format("[0}: is not a valid input", type));  
    }  
  
    // Use display attribute  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)  
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)  
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="LexicalForm">
      <MemberSignature Language="C#" Value="public string LexicalForm { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string LexicalForm" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.LexicalForm" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property LexicalForm As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ LexicalForm { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.LexicalForm : string" Usage="System.Speech.Recognition.RecognizedWordUnit.LexicalForm" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera tekst unnormalized rozpoznane słowa.</summary>
        <value>Zwraca <see cref="T:System.String" /> zawierający tekst rozpoznany wyraz, bez żadnych normalizacji.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 W większości przypadków wartości zwracanych przez <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A> i <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A> są identyczne. Jednak aparatów rozpoznawania może używać normalizacji mowy do zwrócenia bardziej przyjazny dla użytkownika lub kolokwialne Reprezentacja tekstowa wejścia audio.  
  
 Normalizacja mowy polega na użyciu konstrukcje specjalne i symbole, aby express mowy na piśmie. Na przykład normalizacji można zastąpić wypowiadanych słów "dolar i centów szesnastu" "$1.16" w danych wyjściowych tekst.  
  
   
  
## Examples  
 W poniższym przykładzie przedstawiono procedury narzędzia, która generuje tekst w jednym z trzech formatów: leksykalne (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), jest to znormalizowane (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), a fonetyczne (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Tekst wyjściowy jest uzyskiwana z <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> z <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów, które są uzyskiwane z <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
         ReadOnlyCollection<RecognizedWordUnit> words,   
         WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
          String.Format("[0}: is not a valid input", type));  
    }  
  
    // Use display attribute  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)  
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)  
    {  
    wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="Pronunciation">
      <MemberSignature Language="C#" Value="public string Pronunciation { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Pronunciation" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.Pronunciation" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Pronunciation As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ Pronunciation { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Pronunciation : string" Usage="System.Speech.Recognition.RecognizedWordUnit.Pronunciation" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera wymowę rozpoznany wyraz.</summary>
        <value>Ciąg znaków z obsługiwanych alfabet fonetyczny, takich jak międzynarodowy alfabet fonetyczny (IPA) lub uniwersalnych telefonu Ustaw (UPS).</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Zawartość <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A> wskazać, które Wymowa aparatu rozpoznawania mowy, używany do dopasowywania wejście mowy do jednej z jej załadować <xref:System.Speech.Recognition.Grammar> obiektów. Wymowy może być zdefiniowana w wewnętrznych leksykonu aparatu rozpoznawania mowy w dokumencie leksykonu, który jest połączony z gramatyki rozpoznawania w załadowaną <xref:System.Speech.Recognition.Grammar> obiektu lub bezpośrednio w gramatyki rozpoznawania w załadowaną <xref:System.Speech.Recognition.Grammar> obiektu. Aparat rozpoznawania mowy może również utworzyć wymowy nietypowe słów, których wymowy nie są zdefiniowane w leksykonu lub gramatyki, do której aparatu rozpoznawania mowy obecnie ma dostęp.  
  
 Wiele czcionek Unicode z systemem Windows, takich jak nowe Courier obsługują wyświetlanie ciągów IPA. Aby uzyskać więcej informacji, zobacz [międzynarodowy alfabet fonetyczny](http://go.microsoft.com/fwlink/?LinkId=58363).  
  
   
  
## Examples  
 W poniższym przykładzie przedstawiono procedury narzędzia, która generuje ciąg z jednej z trzech możliwych formatów: leksykalne (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), jest to znormalizowane (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), a fonetyczne (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Tekst wyjściowy jest uzyskiwana z <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> z <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów, które są uzyskiwane z <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
          ReadOnlyCollection<RecognizedWordUnit> words,   
          WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
          String.Format("[0}: is not a valid input", type));  
    }  
    // Use display attribute  
  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)   
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)   
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="Text">
      <MemberSignature Language="C#" Value="public string Text { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Text" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.Text" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Text As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ Text { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Text : string" Usage="System.Speech.Recognition.RecognizedWordUnit.Text" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera tekst znormalizowane rozpoznany wyraz.</summary>
        <value>Ciąg, który zawiera dane wyjściowe znormalizowane tekstu dla danego wejściowego programu word.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 W większości przypadków wartości zwracanych przez <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A> i <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A> jest taka sama. Jednak aparatów rozpoznawania może używać normalizacji mowy do zwrócenia bardziej przyjazny dla użytkownika lub kolokwialne Reprezentacja tekstowa wejścia audio.  
  
 Normalizacja mowy polega na użyciu konstrukcje specjalne i symbole, aby express mowy na piśmie. Na przykład normalizacji można zastąpić wypowiadanych słów "dolar i centów szesnastu" "$1.16" w danych wyjściowych tekst.  
  
   
  
## Examples  
 W poniższym przykładzie przedstawiono procedury narzędzia, która generuje ciąg w jednym z trzech formatów: leksykalne (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), jest to znormalizowane (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), a fonetyczne (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Tekst wyjściowy jest uzyskiwana z <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> z <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów, które są uzyskiwane z <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
          ReadOnlyCollection<RecognizedWordUnit> words,   
          WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
           String.Format("[0}: is not a valid input", type));  
    }  
  
    // Use display attribute  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)   
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)   
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>