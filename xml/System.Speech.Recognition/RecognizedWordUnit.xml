<Type Name="RecognizedWordUnit" FullName="System.Speech.Recognition.RecognizedWordUnit">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="db8bbe70a61c7c005c717610d08e20178651bffc" />
    <Meta Name="ms.sourcegitcommit" Value="d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b" />
    <Meta Name="ms.translationtype" Value="MT" />
    <Meta Name="ms.contentlocale" Value="pl-PL" />
    <Meta Name="ms.lasthandoff" Value="04/03/2018" />
    <Meta Name="ms.locfileid" Value="30579484" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class RecognizedWordUnit" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit RecognizedWordUnit extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizedWordUnit" />
  <TypeSignature Language="VB.NET" Value="Public Class RecognizedWordUnit" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognizedWordUnit" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute>
      <AttributeName>System.Diagnostics.DebuggerDisplay("Text: {Text}")</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Udostępnia Atomowej jednostki rozpoznanej mowy.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Wszystkie wyniki zwrócone przez aparat rozpoznawania są konstruowane z <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów.  
  
 Tablica <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów jest dostępny do żadnej operacji rozpoznawania za pośrednictwem <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
 Oprócz zapewnienia miary pewności rozpoznawania (<xref:System.Speech.Recognition.RecognizedWordUnit.Confidence%2A>) <xref:System.Speech.Recognition.RecognizedWordUnit> udostępnia wystąpienie:  
  
-   Reprezentacja tekstowa znormalizowane i dokładne (lub leksykalne) rozpoznawaną wyrazu. Aby uzyskać więcej informacji, zobacz <xref:System.Speech.Recognition.ReplacementText>, <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>, i <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>.  
  
-   Informacje o wymowy przy użyciu znaków z obsługiwanych alfabet fonetyczny, takie jak międzynarodowy alfabet fonetyczny (IPA) lub uniwersalnych Phone Ustaw (UPS). Aby uzyskać więcej informacji, zobacz <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>.  
  
-   Formatowanie, aby je wydrukować. Aby uzyskać więcej informacji, zobacz <xref:System.Speech.Recognition.DisplayAttributes> klasy i jej <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> właściwości.  
  
   
  
## Examples  
 W poniższym przykładzie przedstawiono procedury narzędzia (`stringFromWordArray`) generujący ciągów. Leksykalne wyjściowego zawierać ciągi (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), znormalizowany tekst (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), lub fonetycznych znaków z międzynarodowy alfabet fonetyczny (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Ciągi sformatowane przy użyciu <xref:System.Speech.Recognition.DisplayAttributes> obiektów uzyskane z <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> właściwość z <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> z <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów. <xref:System.Speech.Recognition.RecognizedWordUnit> Obiekty są uzyskiwane z <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(ReadOnlyCollection<RecognizedWordUnit> words, WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(String.Format("[0}: is not a valid input", type));  
    }  
    // Use display attribute  
  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)  
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)  
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public RecognizedWordUnit (string text, float confidence, string pronunciation, string lexicalForm, System.Speech.Recognition.DisplayAttributes displayAttributes, TimeSpan audioPosition, TimeSpan audioDuration);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string text, float32 confidence, string pronunciation, string lexicalForm, valuetype System.Speech.Recognition.DisplayAttributes displayAttributes, valuetype System.TimeSpan audioPosition, valuetype System.TimeSpan audioDuration) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognizedWordUnit.#ctor(System.String,System.Single,System.String,System.String,System.Speech.Recognition.DisplayAttributes,System.TimeSpan,System.TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; RecognizedWordUnit(System::String ^ text, float confidence, System::String ^ pronunciation, System::String ^ lexicalForm, System::Speech::Recognition::DisplayAttributes displayAttributes, TimeSpan audioPosition, TimeSpan audioDuration);" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="text" Type="System.String" />
        <Parameter Name="confidence" Type="System.Single" />
        <Parameter Name="pronunciation" Type="System.String" />
        <Parameter Name="lexicalForm" Type="System.String" />
        <Parameter Name="displayAttributes" Type="System.Speech.Recognition.DisplayAttributes" />
        <Parameter Name="audioPosition" Type="System.TimeSpan" />
        <Parameter Name="audioDuration" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="text">Znormalizowany tekst rozpoznany wyraz.  
  
 Ta wartość może być <see langword="null" />, "", lub <see cref="F:System.String.Empty" />.</param>
        <param name="confidence">A <see langword="float" /> wartość z zakresu od 0,0 do 1,0 wskazujący pewności rozpoznawania wyrazów.</param>
        <param name="pronunciation">Wymowę rozpoznany wyraz.  
  
 Ta wartość może być <see langword="null" />, "", lub <see cref="F:System.String.Empty" />.</param>
        <param name="lexicalForm">Tekst unnormalized rozpoznany wyraz.  
  
 Tego argumentu jest wymagany i nie może być <see langword="null" />, "", lub <see cref="F:System.String.Empty" />.</param>
        <param name="displayAttributes">Określa użycie biały znak do wyświetlenia rozpoznanym słów.</param>
        <param name="audioPosition">Lokalizacja rozpoznany wyraz w strumienia wejściowego audio.  
  
 Ta wartość może być <see cref="F:System.TimeSpan.Zero" />.</param>
        <param name="audioDuration">Długość wejściowego audio odpowiadającego do rozpoznany wyraz.  
  
 Ta wartość może być <see cref="F:System.TimeSpan.Zero" />.</param>
        <summary>Inicjuje nowe wystąpienie klasy <see cref="T:System.Speech.Recognition.RecognizedWordUnit" /> klasy.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Jeśli `text` lub `pronunciation` są `null`, "", lub <xref:System.String.Empty> i <xref:System.Speech.Recognition.RecognizedWordUnit> jest używany w operacji rozpoznawania aparat rozpoznawania wygeneruje odpowiednie wartości w żadnych danych wyjściowych <xref:System.Speech.Recognition.RecognizedWordUnit> wystąpienia.  
  
 Bezpośrednie konstrukcja <xref:System.Speech.Recognition.RecognizedWordUnit> wystąpień jest zwykle używana tylko wtedy, gdy emulowanie operacji rozpoznawania za pomocą <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> lub <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> metody <xref:System.Speech.Recognition.SpeechRecognitionEngine> klasy i <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> lub <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> metody <xref:System.Speech.Recognition.SpeechRecognizer> klasy.  
  
 W przypadku aplikacji rzeczywistych nie bezpośrednio utworzyć <xref:System.Speech.Recognition.RecognizedWordUnit>, zamiast go za pomocą uzyskać <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
   
  
## Examples  
 Poniższy przykład jest nieco contrived test emulacji, gdzie nowych słów są generowane na podstawie danych wejściowych i przekazany do emulatora, a następnie zweryfikować.  
  
```csharp  
private void _emulateAndVerify_Click(object sender, EventArgs e)   
{  
  char[] delimiterChars = { ' ', ',', '.', ':', ';', '\t' };  
  string text = _emulateTextBox.Text;  
  string[] words = text.Split(delimiterChars);  
  
  RecognizedWordUnit[] InputWordUnits = new RecognizedWordUnit[words.Length];  
  for (int i = 0; i < words.Length; i++)   
  {  
    InputWordUnits[i] = new RecognizedWordUnit(  
        "",   
        0,   
        "",  
        words[i].ToLower(),   
        DisplayAttributes.OneTrailingSpace,   
        new TimeSpan(),   
        new TimeSpan());  
  }  
  
  RecognitionResult rec = _recognizer.EmulateRecognize(  
        InputWordUnits,   
        System.Globalization.CompareOptions.IgnoreCase);  
  if (rec == null)   
  {  
    MessageBox.Show(String.Format("Recognition emulation for {0} failed.\n", text));  
  }   
  else if (InputWordUnits.Length != rec.Words.Count)   
  {  
    MessageBox.Show(  
       String.Format("Length mismatch: Input was {0} words, Recognition has {1} words.\n}"));  
  }   
  else   
  {  
    for (int i = 0; i < InputWordUnits.Length; i++)   
    {  
  
      if (rec.Words[i].LexicalForm.ToLower() != InputWordUnits[i].LexicalForm.ToLower())   
      {  
        MessageBox.Show(  
          String.Format("Input word {0} \"{1}\" not found. Recognition output is {2}",  
          i, InputWordUnits[i].LexicalForm, rec.Words[i].LexicalForm));  
        continue;  
      }  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="Confidence">
      <MemberSignature Language="C#" Value="public float Confidence { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance float32 Confidence" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.Confidence" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Confidence As Single" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property float Confidence { float get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Single</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera wartość, przypisany przez aparat rozpoznawania, który reprezentuje prawdopodobieństwo, że rozpoznany wyraz odpowiada określonych danych wejściowych.</summary>
        <value>Miara względnych pewności poprawne rozpoznawanie wyrazu. Wartość jest od 0,0 do 1,0, niski wysokiego zaufania, aby uzyskać odpowiednio.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Wyniki zaufania nie wskazują bezwzględną prawdopodobieństwo wyraz rozpoznano poprawnie. Zamiast tego zaufania wyniki mechanizm umożliwiający porównanie względną dokładność wielu alternatyw rozpoznawania dla określonych danych wejściowych. Ułatwia to zwrócenia wyniku rozpoznawania najbardziej dokładna. Na przykład jeśli rozpoznany wyraz ma wynik zaufania 0,8, to oznacza, że wyraz ma prawidłowe dopasowania dla danych wejściowych jest ryzyko 80%.  Oznacza to, że wyraz jest bardziej prawdopodobne jest prawidłowe dopasowania dla danych wejściowych od innych wyników, które mają zaufanie wyników mniejsza niż 0,8.  
  
 Wynik zaufania na jego własnej nie ma sensu, chyba że masz alternatywnych wyniki do porównania z tej samej operacji rozpoznawania albo z poprzedniego uznania tego samego danych wejściowych.  
  
 Wartości zwracane przez <xref:System.Speech.Recognition.RecognizedWordUnit.Confidence%2A> mają każdego aparatu rozpoznawania względnych i unikatowe. Nie obowiązuje nie definicja porównanie wartości zaufania między dwa aparatów rozpoznawania różnych ani jak <xref:System.Speech.Recognition.RecognizedWordUnit.Confidence%2A> indywidualnego <xref:System.Speech.Recognition.RecognizedWordUnit> zdefiniować obiekty <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> z <xref:System.Speech.Recognition.RecognizedPhrase>.  
  
 Aparat rozpoznawania mowy może przydzielić wynik niski zaufania dane głosowe różnych powodów, takich jak zakłócenia w tle, inarticulate mowy lub nieprzewidziane słowa lub sekwencji programu word. Jeśli aplikacja korzysta <xref:System.Speech.Recognition.SpeechRecognitionEngine> wystąpienia, można zmodyfikować poziom ufności, w których mowy danych wejściowych jest zaakceptowane lub odrzucone z jednym z <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> metody. Progi zaufania udostępniony aparat rozpoznawania zarządza <xref:System.Speech.Recognition.SpeechRecognizer>, są skojarzone z profilem użytkownika i przechowywane w rejestrze systemu Windows. Aplikacje nie należy zapisać zmiany w rejestrze dla właściwości udostępniony aparat rozpoznawania.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="DisplayAttributes">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.DisplayAttributes DisplayAttributes { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.DisplayAttributes DisplayAttributes" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property DisplayAttributes As DisplayAttributes" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::DisplayAttributes DisplayAttributes { System::Speech::Recognition::DisplayAttributes get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.DisplayAttributes</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera formatowania informacje używane do tworzenia tekstowych danych wyjściowych z bieżącego <see cref="T:System.Speech.Recognition.RecognizedWordUnit" /> wystąpienia.</summary>
        <value>Określa użycie biały znak w celu wyświetlenia zawartości <see cref="T:System.Speech.Recognition.RecognizedWordUnit" /> obiektu.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Recognition.DisplayAttributes> Obiektu zwróconego przez <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> właściwość określa spacji wiodących i końcowych ma być używany z danym word, jeśli istnieje.  
  
 Aby uzyskać więcej informacji na temat używania tych informacji formatowania, zobacz <xref:System.Speech.Recognition.DisplayAttributes> wyliczenia.  
  
   
  
## Examples  
 W poniższym przykładzie przedstawiono procedury narzędzia (`stringFromWordArray`) generujący ciąg, który jest sformatowany w jeden z trzech sposobów: lexically (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), jest to znormalizowane (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), lub fonetycznie (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Tekst wyjściowy są uzyskiwane z <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> właściwości na <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> z <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów, które są uzyskiwane z <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
        ReadOnlyCollection<RecognizedWordUnit> words,   
        WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }  
    else if (type == WordType.Pronunciation)   
    {  
       wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
         String.Format("[0}: is not a valid input", type));  
    }  
  
    // Use display attribute  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)  
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)  
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="LexicalForm">
      <MemberSignature Language="C#" Value="public string LexicalForm { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string LexicalForm" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.LexicalForm" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property LexicalForm As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ LexicalForm { System::String ^ get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera tekst unnormalized rozpoznany wyraz.</summary>
        <value>Zwraca <see cref="T:System.String" /> zawierający tekst rozpoznany wyraz, bez żadnych normalizacji.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 W większości przypadków wartości zwracanych przez <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A> i <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A> są identyczne. Jednak aparatów rozpoznawania może używać normalizacji mowy do zwrócenia bardziej przyjazny dla użytkownika lub potocznej Reprezentacja tekstowa wejście audio.  
  
 Normalizacji mowy jest użycie konstrukcji specjalnych lub symbole Express mowy w przypadku pisma. Na przykład normalizacji można zastąpić rozmowy wyrazy "dolara ($) i szesnastu centów" "$1.16" w tekście danych wyjściowych.  
  
   
  
## Examples  
 W poniższym przykładzie przedstawiono procedury narzędzie generujący tekstu w jednym z trzech formatów: leksykalne (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), jest to znormalizowane (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), a fonetyczne (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Tekst wyjściowy są uzyskiwane z <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> z <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów, które są uzyskiwane z <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
         ReadOnlyCollection<RecognizedWordUnit> words,   
         WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
          String.Format("[0}: is not a valid input", type));  
    }  
  
    // Use display attribute  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)  
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)  
    {  
    wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="Pronunciation">
      <MemberSignature Language="C#" Value="public string Pronunciation { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Pronunciation" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.Pronunciation" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Pronunciation As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ Pronunciation { System::String ^ get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera wymowę rozpoznany wyraz.</summary>
        <value>Ciąg znaków z obsługiwanych alfabet fonetyczny, takie jak międzynarodowy alfabet fonetyczny (IPA) lub uniwersalnych Phone Ustaw (UPS).</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Zawartość <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A> wskazać, który wymowy aparat rozpoznawania mowy służy do dopasowania wejście mowy do jednej z jej załadować <xref:System.Speech.Recognition.Grammar> obiektów. Wymowy może być zdefiniowana w leksykonie wewnętrzny aparat rozpoznawania mowy, w leksykonie dokument, który jest połączony z gramatyki rozpoznawania w załadować <xref:System.Speech.Recognition.Grammar> obiektu lub wbudowany w gramatyce rozpoznawania w załadować <xref:System.Speech.Recognition.Grammar> obiektu. Aparat rozpoznawania mowy może także utworzyć wymowy nietypowe słowa, których wymowy nie są definiowane w leksykonie lub gramatyki, do której aparat rozpoznawania mowy aktualnie ma dostęp.  
  
 Wiele czcionek Unicode opartych na systemie Windows, takich jak Courier New obsługuje wyświetlania IPA ciągów. Aby uzyskać więcej informacji, zobacz [międzynarodowy alfabet fonetyczny](http://go.microsoft.com/fwlink/?LinkId=58363).  
  
   
  
## Examples  
 W poniższym przykładzie przedstawiono procedury narzędzie, które generuje ciąg z jednym z trzech formatów możliwych: leksykalne (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), jest to znormalizowane (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), a fonetyczne (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Tekst wyjściowy są uzyskiwane z <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> z <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów, które są uzyskiwane z <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
          ReadOnlyCollection<RecognizedWordUnit> words,   
          WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
          String.Format("[0}: is not a valid input", type));  
    }  
    // Use display attribute  
  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)   
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)   
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="Text">
      <MemberSignature Language="C#" Value="public string Text { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Text" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.Text" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Text As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ Text { System::String ^ get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera tekst znormalizowane rozpoznany wyraz.</summary>
        <value>Ciąg, który zawiera znormalizowane tekst wyjściowy dla danej wejściowej programu word.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 W większości przypadków wartości zwracanych przez <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A> i <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A> musi być taka sama. Jednak aparatów rozpoznawania może używać normalizacji mowy do zwrócenia bardziej przyjazny dla użytkownika lub potocznej Reprezentacja tekstowa wejście audio.  
  
 Normalizacji mowy jest użycie konstrukcji specjalnych lub symbole Express mowy w przypadku pisma. Na przykład normalizacji można zastąpić rozmowy wyrazy "dolara ($) i szesnastu centów" "$1.16" w tekście danych wyjściowych.  
  
   
  
## Examples  
 W poniższym przykładzie przedstawiono procedury narzędzie, które generuje ciąg w jednym z trzech formatów: leksykalne (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), jest to znormalizowane (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), a fonetyczne (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Tekst wyjściowy są uzyskiwane z <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> z <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów, które są uzyskiwane z <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
          ReadOnlyCollection<RecognizedWordUnit> words,   
          WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
           String.Format("[0}: is not a valid input", type));  
    }  
  
    // Use display attribute  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)   
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)   
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>