<Type Name="RecognizedWordUnit" FullName="System.Speech.Recognition.RecognizedWordUnit">
  <Metadata><Meta Name="ms.openlocfilehash" Value="f6e60e03331e99f03ff1e904e2a5581cf4a04c53" /><Meta Name="ms.sourcegitcommit" Value="055a4a82a0b08bfbdc21bd1347fb71f7fe2c099e" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="pl-PL" /><Meta Name="ms.lasthandoff" Value="08/15/2019" /><Meta Name="ms.locfileid" Value="69101027" /></Metadata><TypeSignature Language="C#" Value="public class RecognizedWordUnit" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit RecognizedWordUnit extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizedWordUnit" />
  <TypeSignature Language="VB.NET" Value="Public Class RecognizedWordUnit" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognizedWordUnit" />
  <TypeSignature Language="F#" Value="type RecognizedWordUnit = class" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute>
      <AttributeName>System.Diagnostics.DebuggerDisplay("Text: {Text}")</AttributeName>
    </Attribute>
    <Attribute>
      <AttributeName>System.Serializable</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Dostarcza niepodzielną jednostkę rozpoznanej mowy.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Wszystkie wyniki zwrócone przez aparat rozpoznawania są zbudowane z <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów.  
  
 Tablica <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów jest dostępna dla każdej operacji rozpoznawania <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> przez właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
 Oprócz zapewnienia dokładności rozpoznawania (<xref:System.Speech.Recognition.RecognizedWordUnit.Confidence%2A> <xref:System.Speech.Recognition.RecognizedWordUnit> ) wystąpienie zawiera następujące informacje:  
  
-   Znormalizowane i dokładne (lub leksykalne) reprezentacje tekstu dla rozpoznanego wyrazu. Aby uzyskać więcej informacji, <xref:System.Speech.Recognition.ReplacementText>zobacz <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>, i <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>.  
  
-   Informacje o wymowie używania znaków z obsługiwanego alfabetu fonetycznego, takiego jak Międzynarodowy alfabet fonetyczny (IPA) lub uniwersalny zestaw telefonu (UPS). Aby uzyskać więcej informacji <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>, zobacz.  
  
-   Formatowanie do drukowania. Aby uzyskać więcej informacji, <xref:System.Speech.Recognition.DisplayAttributes> zobacz Klasa i <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> jej właściwość.  
  
   
  
## Examples  
 Poniższy przykład pokazuje procedurę narzędziową (`stringFromWordArray`), która generuje ciągi. Ciągi zawierają leksykalne dane wyjściowe ( <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>przy użyciu), znormalizowany tekst ( <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>przy użyciu) lub znaki fonetyczne z międzynarodowego alfabetu fonetycznego (przy użyciu <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Ciągi są formatowane <xref:System.Speech.Recognition.DisplayAttributes> przy użyciu obiektów uzyskanych <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> z właściwości <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> z <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów. Obiekty są uzyskiwane <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> z właściwości <xref:System.Speech.Recognition.RecognizedPhrase> obiektu. <xref:System.Speech.Recognition.RecognizedWordUnit>  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(ReadOnlyCollection<RecognizedWordUnit> words, WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(String.Format("[0}: is not a valid input", type));  
    }  
    // Use display attribute  
  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)  
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)  
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public RecognizedWordUnit (string text, float confidence, string pronunciation, string lexicalForm, System.Speech.Recognition.DisplayAttributes displayAttributes, TimeSpan audioPosition, TimeSpan audioDuration);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string text, float32 confidence, string pronunciation, string lexicalForm, valuetype System.Speech.Recognition.DisplayAttributes displayAttributes, valuetype System.TimeSpan audioPosition, valuetype System.TimeSpan audioDuration) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognizedWordUnit.#ctor(System.String,System.Single,System.String,System.String,System.Speech.Recognition.DisplayAttributes,System.TimeSpan,System.TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; RecognizedWordUnit(System::String ^ text, float confidence, System::String ^ pronunciation, System::String ^ lexicalForm, System::Speech::Recognition::DisplayAttributes displayAttributes, TimeSpan audioPosition, TimeSpan audioDuration);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.RecognizedWordUnit : string * single * string * string * System.Speech.Recognition.DisplayAttributes * TimeSpan * TimeSpan -&gt; System.Speech.Recognition.RecognizedWordUnit" Usage="new System.Speech.Recognition.RecognizedWordUnit (text, confidence, pronunciation, lexicalForm, displayAttributes, audioPosition, audioDuration)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="text" Type="System.String" />
        <Parameter Name="confidence" Type="System.Single" />
        <Parameter Name="pronunciation" Type="System.String" />
        <Parameter Name="lexicalForm" Type="System.String" />
        <Parameter Name="displayAttributes" Type="System.Speech.Recognition.DisplayAttributes" />
        <Parameter Name="audioPosition" Type="System.TimeSpan" />
        <Parameter Name="audioDuration" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="text">Znormalizowany tekst dla rozpoznanego wyrazu.  
  
Ta wartość może być <see langword="null" />równa "" lub <see cref="F:System.String.Empty" />".</param>
        <param name="confidence"><see langword="float" /> Wartość od 0,0 do 1,0 wskazująca pewność rozpoznawania wyrazów.</param>
        <param name="pronunciation">Tekst fonetyczny rozpoznanego wyrazu.  
  
Ta wartość może być <see langword="null" />równa "" lub <see cref="F:System.String.Empty" />".</param>
        <param name="lexicalForm">Nieznormalizowany tekst dla rozpoznanego wyrazu.  
  
Ten argument jest wymagany i nie może być <see langword="null" />, "" lub. <see cref="F:System.String.Empty" /></param>
        <param name="displayAttributes">Definiuje użycie białych znaków do wyświetlania rozpoznawanych wyrazów.</param>
        <param name="audioPosition">Lokalizacja rozpoznanego wyrazu w strumieniu wejściowym audio.  
  
Ta wartość może być <see cref="F:System.TimeSpan.Zero" />równa.</param>
        <param name="audioDuration">Długość danych wejściowych audio odpowiadająca rozpoznawanym wyrazom.  
  
Ta wartość może być <see cref="F:System.TimeSpan.Zero" />równa.</param>
        <summary>Inicjuje nowe wystąpienie klasy <see cref="T:System.Speech.Recognition.RecognizedWordUnit" /> klasy.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Jeśli `text` lub <xref:System.String.Empty> <xref:System.Speech.Recognition.RecognizedWordUnit> jest, "", lub i jest używany w operacji rozpoznawania, aparat rozpoznawania będzie generować odpowiednie wartości w dowolnym wystąpieniu danych wyjściowych <xref:System.Speech.Recognition.RecognizedWordUnit>. `pronunciation` `null`  
  
 Bezpośrednie konstruowanie <xref:System.Speech.Recognition.RecognizedWordUnit> wystąpień jest zwykle używane tylko <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> w przypadku emulowania operacji rozpoznawania przy użyciu <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> metod <xref:System.Speech.Recognition.SpeechRecognitionEngine> lub klasy oraz <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> metod lub <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> <xref:System.Speech.Recognition.SpeechRecognizer> Klasa.  
  
 W przypadku rzeczywistych aplikacji nie należy bezpośrednio tworzyć <xref:System.Speech.Recognition.RecognizedWordUnit>, a nie uzyskiwać ich <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> przez właściwość <xref:System.Speech.Recognition.RecognizedPhrase> obiektu.  
  
   
  
## Examples  
 Poniższy przykład jest nieco contrivedm testem emulacji, w którym nowe wyrazy są generowane na podstawie danych wejściowych i przesyłane do emulatora, a następnie zweryfikowane.  
  
```csharp  
private void _emulateAndVerify_Click(object sender, EventArgs e)   
{  
  char[] delimiterChars = { ' ', ',', '.', ':', ';', '\t' };  
  string text = _emulateTextBox.Text;  
  string[] words = text.Split(delimiterChars);  
  
  RecognizedWordUnit[] InputWordUnits = new RecognizedWordUnit[words.Length];  
  for (int i = 0; i < words.Length; i++)   
  {  
    InputWordUnits[i] = new RecognizedWordUnit(  
        "",   
        0,   
        "",  
        words[i].ToLower(),   
        DisplayAttributes.OneTrailingSpace,   
        new TimeSpan(),   
        new TimeSpan());  
  }  
  
  RecognitionResult rec = _recognizer.EmulateRecognize(  
        InputWordUnits,   
        System.Globalization.CompareOptions.IgnoreCase);  
  if (rec == null)   
  {  
    MessageBox.Show(String.Format("Recognition emulation for {0} failed.\n", text));  
  }   
  else if (InputWordUnits.Length != rec.Words.Count)   
  {  
    MessageBox.Show(  
       String.Format("Length mismatch: Input was {0} words, Recognition has {1} words.\n}"));  
  }   
  else   
  {  
    for (int i = 0; i < InputWordUnits.Length; i++)   
    {  
  
      if (rec.Words[i].LexicalForm.ToLower() != InputWordUnits[i].LexicalForm.ToLower())   
      {  
        MessageBox.Show(  
          String.Format("Input word {0} \"{1}\" not found. Recognition output is {2}",  
          i, InputWordUnits[i].LexicalForm, rec.Words[i].LexicalForm));  
        continue;  
      }  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
        <related type="ExternalDocumentation" href="https://go.microsoft.com/fwlink/?LinkId=58363">Międzynarodowy alfabet fonetyczny</related>
      </Docs>
    </Member>
    <Member MemberName="Confidence">
      <MemberSignature Language="C#" Value="public float Confidence { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance float32 Confidence" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.Confidence" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Confidence As Single" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property float Confidence { float get(); };" />
      <MemberSignature Language="F#" Value="member this.Confidence : single" Usage="System.Speech.Recognition.RecognizedWordUnit.Confidence" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Single</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera wartość przypisaną przez aparat rozpoznawania, która reprezentuje prawdopodobieństwo, że rozpoznany wyraz jest zgodny z danymi wejściowymi.</summary>
        <value>Względna miara pewności poprawnego rozpoznawania wyrazu. Wartość jest z przedziału od 0,0 do 1,0, odpowiednio dla niskiego wysokiego poziomu zaufania.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Wyniki pewności nie wskazują absolutnego prawdopodobieństwa, że słowo zostało rozpoznane prawidłowo. Zamiast tego, wyniki pewności zapewniają mechanizm do porównywania dokładności względnej z wieloma alternatywami rozpoznawania dla danego danych wejściowych. Ułatwia to zwrócenie najbardziej dokładnego wyniku rozpoznawania. Na przykład, jeśli rozpoznany wyraz ma wynik pewności 0,8, nie oznacza to, że wyraz ma 80% szansy dla danych wejściowych.  Oznacza to, że słowo może być właściwym dopasowaniem dla danych wejściowych niż inne wyniki, które mają wartość mniejszą niż 0,8.  
  
 Wynik pewności nie ma znaczenia, chyba że masz alternatywne wyniki do porównania z, z tej samej operacji rozpoznawania lub z poprzednich ocen tych samych danych wejściowych.  
  
 Wartości zwracane przez <xref:System.Speech.Recognition.RecognizedWordUnit.Confidence%2A> są względne i unikatowe dla poszczególnych aparatów rozpoznawania. Nie istnieje definicja, jak wartości ufności między dwoma różnymi aparatami rozpoznawania są porównywane, ani <xref:System.Speech.Recognition.RecognizedWordUnit.Confidence%2A> jak poszczególne <xref:System.Speech.Recognition.RecognizedWordUnit> <xref:System.Speech.Recognition.RecognizedPhrase>obiekty definiują <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> .  
  
 Aparat rozpoznawania mowy może przypisywać niewielką ocenę do mówionych danych wejściowych z różnych powodów, takich jak zakłócenia w tle, zamiana mowy lub nieprzewidziane słowa albo sekwencje słów. Jeśli aplikacja używa <xref:System.Speech.Recognition.SpeechRecognitionEngine> wystąpienia, można zmodyfikować poziom pewności, przy którym dane wejściowe mowy są akceptowane lub odrzucane przy użyciu jednej <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> z metod. Progi zaufania udostępnionego aparatu rozpoznawania, zarządzane przez <xref:System.Speech.Recognition.SpeechRecognizer>, są skojarzone z profilem użytkownika i przechowywane w rejestrze systemu Windows. Aplikacje nie powinny zapisywać zmian w rejestrze dla właściwości udostępnionego aparatu rozpoznawania.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="DisplayAttributes">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.DisplayAttributes DisplayAttributes { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.DisplayAttributes DisplayAttributes" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property DisplayAttributes As DisplayAttributes" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::DisplayAttributes DisplayAttributes { System::Speech::Recognition::DisplayAttributes get(); };" />
      <MemberSignature Language="F#" Value="member this.DisplayAttributes : System.Speech.Recognition.DisplayAttributes" Usage="System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.DisplayAttributes</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera informacje o formatowaniu używane do tworzenia tekstu wyjściowego z bieżącego <see cref="T:System.Speech.Recognition.RecognizedWordUnit" /> wystąpienia.</summary>
        <value>Określa użycie białego znaku do wyświetlania zawartości <see cref="T:System.Speech.Recognition.RecognizedWordUnit" /> obiektu.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Recognition.DisplayAttributes> Obiekt zwrócony<xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> przez właściwość określa spacje początkowe i końcowe, które mają być używane z danym wyrazem, jeśli istnieje.  
  
 Aby uzyskać więcej informacji na temat sposobu korzystania z tych informacji o formatowaniu, zobacz <xref:System.Speech.Recognition.DisplayAttributes> Wyliczenie.  
  
   
  
## Examples  
 W poniższym przykładzie przedstawiono procedurę narzędziową (`stringFromWordArray`), która generuje ciąg, który jest sformatowany na jeden z trzech sposobów: leksykalnie ( <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>przy użyciu), znormalizowany ( <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>przy użyciu) lub fonetycznie ( <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>przy użyciu). Dane wyjściowe tekstu są uzyskiwane z <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> właściwości <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów, <xref:System.Speech.Recognition.RecognizedPhrase> które są uzyskiwane z <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwości obiektu.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
        ReadOnlyCollection<RecognizedWordUnit> words,   
        WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }  
    else if (type == WordType.Pronunciation)   
    {  
       wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
         String.Format("[0}: is not a valid input", type));  
    }  
  
    // Use display attribute  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)  
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)  
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="LexicalForm">
      <MemberSignature Language="C#" Value="public string LexicalForm { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string LexicalForm" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.LexicalForm" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property LexicalForm As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ LexicalForm { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.LexicalForm : string" Usage="System.Speech.Recognition.RecognizedWordUnit.LexicalForm" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera nieznormalizowany tekst rozpoznanego wyrazu.</summary>
        <value>Zwraca znak <see cref="T:System.String" /> zawierający tekst rozpoznanego wyrazu, bez normalizacji.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 W większości przypadków wartości zwracane przez <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A> i <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A> są identyczne. Jednak aparaty rozpoznawania mogą korzystać z normalizacji mowy w celu zwrócenia więcej przyjaznych dla użytkownika lub Colloquial tekstowych reprezentacji danych wejściowych audio.  
  
 Normalizacja mowy to użycie specjalnych konstrukcji lub symboli do wyrażania mowy na piśmie. Na przykład normalizacja może zastąpić słowa mówione "Dolar i szesnaste centy" "$1,16" w wyjściowym tekście.  
  
   
  
## Examples  
 Poniższy przykład pokazuje procedurę narzędziową, która generuje tekst w jednym z trzech formatów: leksykalny ( <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>using), znormalizowany (using <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>) i fonetyczny (using <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Dane wyjściowe tekstu są uzyskiwane z <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów, <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> które są uzyskiwane <xref:System.Speech.Recognition.RecognizedPhrase> z właściwości obiektu.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
         ReadOnlyCollection<RecognizedWordUnit> words,   
         WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
          String.Format("[0}: is not a valid input", type));  
    }  
  
    // Use display attribute  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)  
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)  
    {  
    wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="Pronunciation">
      <MemberSignature Language="C#" Value="public string Pronunciation { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Pronunciation" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.Pronunciation" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Pronunciation As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ Pronunciation { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Pronunciation : string" Usage="System.Speech.Recognition.RecognizedWordUnit.Pronunciation" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera tekst fonetyczny rozpoznawanego wyrazu.</summary>
        <value>Ciąg znaków z obsługiwanego alfabetu fonetycznego, takiego jak Międzynarodowy alfabet fonetyczny (IPA) lub uniwersalny zestaw telefonu (UPS).</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Zawartość <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A> wskazuje, która wymowy aparat rozpoznawania mowy służy do dopasowania danych wejściowych mowy do jednego z załadowanych <xref:System.Speech.Recognition.Grammar> obiektów. Wymowy mogą być zdefiniowane w wewnętrznym leksykonie aparatu rozpoznawania mowy, w dokumencie leksykonu, który jest powiązany z gramatyką rozpoznawania w załadowanym <xref:System.Speech.Recognition.Grammar> obiekcie lub wbudowany w gramatyki rozpoznawania w załadowanym <xref:System.Speech.Recognition.Grammar> obiekcie. Aparat rozpoznawania mowy może również tworzyć wymowy dla nietypowych słów, których wymowy nie są zdefiniowane w leksykonie lub gramatyce, do których aparat rozpoznawania mowy aktualnie ma dostęp.  
  
 Wiele czcionek Unicode opartych na systemie Windows, takich jak Courier New, obsługuje wyświetlanie ciągów IPA. Aby uzyskać więcej informacji, zobacz [Międzynarodowy alfabet fonetyczny](https://go.microsoft.com/fwlink/?LinkId=58363).  
  
   
  
## Examples  
 Poniższy przykład pokazuje procedurę narzędziową, która generuje ciąg z jednym z trzech możliwych formatów: leksykalny (using <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), znormalizowany (using <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>) i fonetyczny (using <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Dane wyjściowe tekstu są uzyskiwane z <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów, <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> które są uzyskiwane <xref:System.Speech.Recognition.RecognizedPhrase> z właściwości obiektu.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
          ReadOnlyCollection<RecognizedWordUnit> words,   
          WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
          String.Format("[0}: is not a valid input", type));  
    }  
    // Use display attribute  
  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)   
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)   
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
        <related type="ExternalDocumentation" href="https://go.microsoft.com/fwlink/?LinkId=58363">Międzynarodowy alfabet fonetyczny</related>
      </Docs>
    </Member>
    <Member MemberName="Text">
      <MemberSignature Language="C#" Value="public string Text { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Text" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.Text" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Text As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ Text { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Text : string" Usage="System.Speech.Recognition.RecognizedWordUnit.Text" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera znormalizowany tekst dla rozpoznanego wyrazu.</summary>
        <value>Ciąg, który zawiera znormalizowane dane wyjściowe tekstu dla danego wyrazu wejściowego.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 W większości przypadków wartości zwracane przez <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A> i <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A> będą identyczne. Jednak aparaty rozpoznawania mogą korzystać z normalizacji mowy w celu zwrócenia więcej przyjaznych dla użytkownika lub Colloquial tekstowych reprezentacji danych wejściowych audio.  
  
 Normalizacja mowy to użycie specjalnych konstrukcji lub symboli do wyrażania mowy na piśmie. Na przykład normalizacja może zastąpić słowa mówione "Dolar i szesnaste centy" "$1,16" w wyjściowym tekście.  
  
   
  
## Examples  
 Poniższy przykład pokazuje procedurę narzędziową, która generuje ciąg w jednym z trzech formatów: leksykalny (using <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), znormalizowany (using <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>) i fonetyczny (using <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Dane wyjściowe tekstu są uzyskiwane z <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> <xref:System.Speech.Recognition.RecognizedWordUnit> obiektów, <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> które są uzyskiwane <xref:System.Speech.Recognition.RecognizedPhrase> z właściwości obiektu.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
          ReadOnlyCollection<RecognizedWordUnit> words,   
          WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
           String.Format("[0}: is not a valid input", type));  
    }  
  
    // Use display attribute  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)   
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)   
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>
