<Type Name="RecognizerUpdateReachedEventArgs" FullName="System.Speech.Recognition.RecognizerUpdateReachedEventArgs">
  <Metadata><Meta Name="ms.openlocfilehash" Value="ffbb1d41c5030bc33e16286449c48d696f3fcf53" /><Meta Name="ms.sourcegitcommit" Value="055a4a82a0b08bfbdc21bd1347fb71f7fe2c099e" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="pl-PL" /><Meta Name="ms.lasthandoff" Value="08/15/2019" /><Meta Name="ms.locfileid" Value="69231119" /></Metadata><TypeSignature Language="C#" Value="public class RecognizerUpdateReachedEventArgs : EventArgs" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit RecognizerUpdateReachedEventArgs extends System.EventArgs" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
  <TypeSignature Language="VB.NET" Value="Public Class RecognizerUpdateReachedEventArgs&#xA;Inherits EventArgs" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognizerUpdateReachedEventArgs : EventArgs" />
  <TypeSignature Language="F#" Value="type RecognizerUpdateReachedEventArgs = class&#xA;    inherit EventArgs" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.EventArgs</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>Zwraca dane z <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" /> <see cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" /> lub zdarzenia.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 `RecognizerUpdateReached`zdarzenia zapewniają mechanizm wstrzymywania aparatu rozpoznawania mowy w celu zastosowania modyfikacji niepodzielnych i synchronicznych, takich jak ładowanie i wyładowywanie gramatyki.  
  
 Jeśli aplikacja używa <xref:System.Speech.Recognition.SpeechRecognitionEngine> wystąpienia do zarządzania rozpoznawaniem, może użyć jednej <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A?displayProperty=nameWithType> z metod, aby zażądać, aby aparat zatrzymał aktualizację. Wystąpienie zgłasza zdarzenie, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached?displayProperty=nameWithType> gdy jest gotowe do aktualizacji. <xref:System.Speech.Recognition.SpeechRecognitionEngine>  
  
 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> <xref:System.Speech.Recognition.Grammar> Gdy wystąpienie jest wstrzymane, można ładować, zwalniać, włączać i wyłączać obiekty oraz modyfikować wartości właściwości, i. <xref:System.Speech.Recognition.SpeechRecognitionEngine>  
  
 Jeśli aplikacja używa <xref:System.Speech.Recognition.SpeechRecognizer> wystąpienia do zarządzania rozpoznawaniem, może użyć jednej <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A?displayProperty=nameWithType> z metod, aby zażądać, aby aparat zatrzymał aktualizację. Wystąpienie zgłasza zdarzenie, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached?displayProperty=nameWithType> gdy jest gotowe do aktualizacji. <xref:System.Speech.Recognition.SpeechRecognizer>  
  
 Gdy wystąpienie jest wstrzymane, można ładować, zwalniać, włączać i wyłączać <xref:System.Speech.Recognition.Grammar> obiekty. <xref:System.Speech.Recognition.SpeechRecognizer>  
  
 Podczas obsługi <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached?displayProperty=nameWithType> i <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached?displayProperty=nameWithType> zdarzeń aparat rozpoznawania jest wstrzymywany do momentu, gdy program obsługi zdarzeń zwróci wartość.  
  
 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>pochodzi od <xref:System.EventArgs>.  
  
   
  
## Examples  
 W poniższym przykładzie przedstawiono aplikację konsolową, która ładuje i zwalnia <xref:System.Speech.Recognition.Grammar> obiekty. Aplikacja używa <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> metody, aby zażądać zatrzymania aparatu rozpoznawania mowy, aby można było odebrać aktualizację. Następnie aplikacja ładuje lub zwalnia <xref:System.Speech.Recognition.Grammar> obiekt.  
  
 W każdej aktualizacji program obsługi <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached?displayProperty=nameWithType> zdarzeń zapisuje nazwę i stan aktualnie załadowanych <xref:System.Speech.Recognition.Grammar> obiektów do konsoli programu. Ponieważ gramatyki są ładowane i zwalniane, aplikacja najpierw rozpoznaje nazwy zwierząt farmy, a następnie nazwy zwierząt farmy i nazwy owoców, a następnie tylko nazwy owoców.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine and configure its input.  
      using (recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US")))  
      {  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Create the first grammar - Farm.  
        Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
        GrammarBuilder farm = new GrammarBuilder(animals);  
        Grammar farmAnimals = new Grammar(farm);  
        farmAnimals.Name = "Farm";  
  
        // Create the second grammar - Fruit.  
        Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
        GrammarBuilder favorite = new GrammarBuilder(fruit);  
        Grammar favoriteFruit = new Grammar(favorite);  
        favoriteFruit.Name = "Fruit";  
  
        // Attach event handlers.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.RecognizerUpdateReached +=  
          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
        recognizer.SpeechRecognitionRejected +=  
          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  
  
        // Load the Farm grammar.  
        recognizer.LoadGrammar(farmAnimals);  
  
        // Start asynchronous, continuous recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
        Console.WriteLine("Starting asynchronous, continuous recognition");  
        Console.WriteLine("  Farm grammar is loaded and enabled.");  
  
        // Pause to recognize farm animals.  
        Thread.Sleep(7000);  
        Console.WriteLine();  
  
        // Request an update and load the Fruit grammar.  
        recognizer.RequestRecognizerUpdate();  
        recognizer.LoadGrammarAsync(favoriteFruit);  
        Thread.Sleep(7000);  
  
        // Request an update and unload the Farm grammar.  
        recognizer.RequestRecognizerUpdate();  
        recognizer.UnloadGrammar(farmAnimals);  
        Thread.Sleep(7000);  
      }  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // At the update, get the names and enabled status of the currently loaded grammars.  
    public static void recognizer_RecognizerUpdateReached(  
      object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  {0} grammar is loaded and {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("    Speech recognized: " + e.Result.Text);  
    }  
  
    // Write a message to the console when recognition fails.  
    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine("    Recognition attempt failed");  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
    <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate" />
    <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
  </Docs>
  <Members>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.AudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan AudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioPosition : TimeSpan" Usage="System.Speech.Recognition.RecognizerUpdateReachedEventArgs.AudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera pozycję audio skojarzoną ze zdarzeniem.</summary>
        <value>Zwraca lokalizację w buforze <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> mowy <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> lub w przypadku wstrzymania i wygeneruje zdarzenie <c>RecognizerUpdateReached</c> .</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aplikacje mogą używać lokalizacji wskazanej przez <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.AudioPosition%2A> program, aby uzyskać dostęp do danych wejściowych audio, które wystąpiły podczas wstrzymania aparatu rozpoznawania.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      </Docs>
    </Member>
    <Member MemberName="UserToken">
      <MemberSignature Language="C#" Value="public object UserToken { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance object UserToken" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property UserToken As Object" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Object ^ UserToken { System::Object ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.UserToken : obj" Usage="System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Object</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera <c>UserToken</c> przekazaną do systemu, gdy aplikacja wywołuje <see cref="Overload:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate" /> lub <see cref="Overload:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />.</summary>
        <value>Zwraca obiekt, który zawiera <c>UserToken</c>.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 `UserToken` Aplikacja określa, kiedy żąda generowania <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A?displayProperty=nameWithType> `RecognizerUpdateReached` zdarzenia przez wywołanie jednej z metod lub <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A?displayProperty=nameWithType> przyjmujących `userToken` parametr.  
  
   
  
## Examples  
 W poniższym przykładzie przedstawiono aplikację konsolową, która ładuje i zwalnia <xref:System.Speech.Recognition.Grammar> obiekty. Aplikacja używa <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> metody, aby zażądać zatrzymania aparatu rozpoznawania mowy, aby można było odebrać aktualizację. Metoda przekazuje <xref:System.String> obiekt `userToken` dla parametru, który opisuje elementy rozpoznawane przez aplikację po aktualizacji. Następnie aplikacja ładuje lub zwalnia <xref:System.Speech.Recognition.Grammar> obiekt.  
  
 W każdej aktualizacji program obsługi <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached?displayProperty=nameWithType> zdarzeń zapisuje `userToken` zawartość w konsoli programu. Ponieważ gramatyki są ładowane i zwalniane, aplikacja najpierw rozpoznaje nazwy zwierząt farmy, a następnie nazwy zwierząt farmy i nazwy owoców, a następnie tylko nazwy owoców.  
  
```  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine and configure its input.  
      using (recognizer = new SpeechRecognitionEngine(  
        new System.Globalization.CultureInfo("en-US")))  
      {  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Create the first grammar - Farm.  
        Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
        GrammarBuilder farm = new GrammarBuilder(animals);  
        Grammar farmAnimals = new Grammar(farm);  
        farmAnimals.Name = "Farm";  
  
        // Create the second grammar - Fruit.  
        Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
        GrammarBuilder favorite = new GrammarBuilder(fruit);  
        Grammar favoriteFruit = new Grammar(favorite);  
        favoriteFruit.Name = "Fruit";  
  
        // Attach event handlers.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.RecognizerUpdateReached +=  
          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
        recognizer.SpeechRecognitionRejected +=  
          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  
  
        // Load the farmAnimals grammar  
        recognizer.LoadGrammar(farmAnimals);  
  
        // Start continuous, asynchronous recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
        Console.WriteLine("Starting asynchronous recognition...");  
        Console.WriteLine("  Farm animals will now be recognized.");  
        Thread.Sleep(7000);  
        Console.WriteLine();  
  
        // Load the Fruit grammar.  
        string activeGrammars = "Farm animals and fruits will now be recognized.";  
        recognizer.RequestRecognizerUpdate(activeGrammars);  
        recognizer.LoadGrammarAsync(favoriteFruit);  
        Console.WriteLine();  
        Thread.Sleep(7000);  
        Console.WriteLine();  
  
        // Unload the Farm grammar.  
        string onlyFruit = "Only fruits will now be recognized.";  
        recognizer.RequestRecognizerUpdate(onlyFruit);  
        recognizer.UnloadGrammar(farmAnimals);  
        Thread.Sleep(7000);  
      }  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // At the update, describe what the application will recognize next.  
    public static void recognizer_RecognizerUpdateReached(object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      Console.WriteLine("  Update reached: " + e.UserToken);  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("    Speech recognized: " + e.Result.Text);  
    }  
  
    // Write a message to the console when recognition fails.  
    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine("    Recognition attempt failed");  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      </Docs>
    </Member>
  </Members>
</Type>
