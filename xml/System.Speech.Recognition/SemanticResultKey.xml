<Type Name="SemanticResultKey" FullName="System.Speech.Recognition.SemanticResultKey">
  <Metadata><Meta Name="ms.openlocfilehash" Value="9d41242796c25031134a175d7e82a84cb6e4c818" /><Meta Name="ms.sourcegitcommit" Value="055a4a82a0b08bfbdc21bd1347fb71f7fe2c099e" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="pl-PL" /><Meta Name="ms.lasthandoff" Value="08/15/2019" /><Meta Name="ms.locfileid" Value="69231068" /></Metadata><TypeSignature Language="C#" Value="public class SemanticResultKey" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit SemanticResultKey extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.SemanticResultKey" />
  <TypeSignature Language="VB.NET" Value="Public Class SemanticResultKey" />
  <TypeSignature Language="C++ CLI" Value="public ref class SemanticResultKey" />
  <TypeSignature Language="F#" Value="type SemanticResultKey = class" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute>
      <AttributeName>System.Diagnostics.DebuggerDisplay("{_semanticKey.DebugSummary}")</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Kojarzy ciąg klucza z <see cref="T:System.Speech.Recognition.SemanticResultValue" /> wartościami do definiowania <see cref="T:System.Speech.Recognition.SemanticValue" /> obiektów.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Podstawowa jednostka wyrażenia semantycznego w System. Speech to <xref:System.Speech.Recognition.SemanticValue>element, który jest parą klucz/wartość.  
  
 Korzystając <xref:System.Speech.Recognition.SemanticResultKey> z obiektów, należy <xref:System.Speech.Recognition.SemanticResultValue> oznakować wystąpienia <xref:System.Speech.Recognition.GrammarBuilder> zawarte w obiektach i ciągach, dzięki czemu wartości mogą <xref:System.Speech.Recognition.SemanticValue> być łatwo dostępne z wystąpień podczas rozpoznawania.  
  
 W połączeniu z <xref:System.Speech.Recognition.SemanticResultValue> <xref:System.Speech.Recognition.SemanticResultKey> obiektami<xref:System.Speech.Recognition.GrammarBuilder> i<xref:System.Speech.Recognition.Choices> można używać obiektów, aby definiować strukturę semantyczną dla gramatyki rozpoznawania mowy. Aby uzyskać dostęp do informacji semantycznych w wyniku rozpoznawania, należy uzyskać wystąpienie <xref:System.Speech.Recognition.SemanticValue> <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> przez właściwość na <xref:System.Speech.Recognition.RecognizedPhrase>.  
  
  
## Examples  
 Poniższy przykład tworzy <xref:System.Speech.Recognition.Grammar> , aby rozpoznawać dane wejściowe hasła formularza "moje hasło to...", gdzie rzeczywiste dane wejściowe są dopasowane do symbolu wieloznacznego.  
  
 Symbol wieloznaczny jest oznakowany kluczem semantycznym, <xref:System.Speech.Recognition.Grammar.SpeechRecognized> a procedura obsługi sprawdza obecność tego tagu w celu sprawdzenia, czy nastąpiło wprowadzenie hasła.  
  
```csharp  
private void pwdGrammar()   
{  
  GrammarBuilder pwdBuilder = new GrammarBuilder("My Password is");  
  GrammarBuilder wildcardBuilder = new GrammarBuilder();  
  wildcardBuilder.AppendWildcard();  
  SemanticResultKey wildcardKey= new SemanticResultKey("Password", wildcardBuilder);  
  pwdBuilder+=wildcardKey;  
  Grammar grammar = new Grammar(pwdBuilder);  
  grammar.Name = "Password input";  
  
  grammar.SpeechRecognized += delegate(object sender, SpeechRecognizedEventArgs eventArgs)   
  {  
    SemanticValue semantics = eventArgs.Result.Semantics;  
    RecognitionResult result=eventArgs.Result;  
  
    if (!semantics.ContainsKey("Password"))   
    {  
      SpeechUI.SendTextFeedback(eventArgs.Result, "No Password Provided", false);  
    }  
    else   
    {  
      RecognizedAudio pwdAudio = result.GetAudioForWordRange(result.Words[3], result.Words[result.Words.Count - 1]);  
      MemoryStream pwdMemoryStream = new MemoryStream();  
      pwdAudio.WriteToAudioStream(pwdMemoryStream);  
      if (!IsValidPwd(pwdMemoryStream))   
      {  
        string badPwd = System.IO.Path.GetTempPath() + "BadPwd" + (new Random()).Next().ToString() + ".wav";  
        FileStream waveStream = new FileStream(badPwd, FileMode.Create);  
        pwdAudio.WriteToWaveStream(waveStream);  
        waveStream.Flush();  
        waveStream.Close();  
        SpeechUI.SendTextFeedback(eventArgs.Result, "Invalid Password", false);  
  
      }  
    }  
  };  
  grammar.Enabled = true;  
  _recognizer.LoadGrammar(grammar);  
  UpdateGrammarTree(_grammarTreeView, _recognizer);  
  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.SemanticValue" />
    <altmember cref="T:System.Speech.Recognition.SemanticResultValue" />
    <related type="Article" href="https://docs.microsoft.com/previous-versions/office/developer/speech-technologies/hh361587(v%3doffice.14)">Używanie SemanticResultKey do wyodrębnienia SemanticResultValue</related>
  </Docs>
  <Members>
    <MemberGroup MemberName=".ctor">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Konstruuje wystąpienie <see cref="T:System.Speech.Recognition.SemanticResultKey" /> i kojarzy klucz z składnikami gramatyki.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Konstruktory dla <xref:System.Speech.Recognition.SemanticResultKey> Określ tag tekstowy (klucz semantyczny) i zestaw składników gramatyki, które mają zostać dodane do gramatyki rozpoznawania mowy.  
  
 Składniki gramatyki można określić jako tablicę <xref:System.Speech.Recognition.GrammarBuilder> obiektów lub <xref:System.String> tablicę wystąpień.  
  
 Jeśli składniki gramatyki są używane podczas rozpoznawania, można uzyskać dostęp do zwracanego <xref:System.Speech.Recognition.SemanticValue> przy użyciu znacznika tekstu dostarczonego do <xref:System.Speech.Recognition.SemanticResultKey> konstruktora jako klucz semantyczny. Właściwość wystąpienia zostanie określona przez składniki gramatyki <xref:System.Speech.Recognition.SemanticResultKey>używane w definicji. <xref:System.Speech.Recognition.SemanticValue> <xref:System.Speech.Recognition.SemanticValue.Value%2A>  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SemanticResultKey (string semanticResultKey, params System.Speech.Recognition.GrammarBuilder[] builders);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string semanticResultKey, class System.Speech.Recognition.GrammarBuilder[] builders) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SemanticResultKey.#ctor(System.String,System.Speech.Recognition.GrammarBuilder[])" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (semanticResultKey As String, ParamArray builders As GrammarBuilder())" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SemanticResultKey(System::String ^ semanticResultKey, ... cli::array &lt;System::Speech::Recognition::GrammarBuilder ^&gt; ^ builders);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.SemanticResultKey : string * System.Speech.Recognition.GrammarBuilder[] -&gt; System.Speech.Recognition.SemanticResultKey" Usage="new System.Speech.Recognition.SemanticResultKey (semanticResultKey, builders)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="semanticResultKey" Type="System.String" />
        <Parameter Name="builders" Type="System.Speech.Recognition.GrammarBuilder[]">
          <Attributes>
            <Attribute FrameworkAlternate="netframework-3.0">
              <AttributeName>System.ParamArray</AttributeName>
            </Attribute>
          </Attributes>
        </Parameter>
      </Parameters>
      <Docs>
        <param name="semanticResultKey">Tag, który ma być używany jako klucz semantyczny w celu <see cref="T:System.Speech.Recognition.SemanticValue" /> uzyskania dostępu do wystąpienia <see cref="T:System.Speech.Recognition.GrammarBuilder" /> skojarzonego z obiektami określonymi <paramref name="builders" /> przez argument.</param>
        <param name="builders">Tablica składników gramatyki, która zostanie skojarzona z <see cref="T:System.Speech.Recognition.SemanticValue" /> obiektem dostępnym ze znacznikiem zdefiniowanym w <paramref name="semanticResultKey" />elemencie.</param>
        <summary>Przypisuje klucz semantyczny do co najmniej <see cref="T:System.Speech.Recognition.GrammarBuilder" /> jednego obiektu używanego do tworzenia gramatyki rozpoznawania mowy.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Z powodu niejawnych konwersji `builders` argument obsługuje <xref:System.Speech.Recognition.SemanticResultValue>również <xref:System.Speech.Recognition.SemanticResultKey>obiekty <xref:System.Speech.Recognition.Choices>,, <xref:System.String> i. Aby uzyskać więcej informacji na temat konwersji niejawnych, zobacz <xref:System.Speech.Recognition.GrammarBuilder.op_Implicit%2A>.  
  
 Podczas wykonywania operacji <xref:System.Speech.Recognition.GrammarBuilder> rozpoznawania obiekty podane `builders` w argumencie są traktowane jako sekwencyjne. Na przykład jeśli poniższe <xref:System.Speech.Recognition.SemanticResultValue> dane są używane do <xref:System.Speech.Recognition.Grammar>konstruowania, wejście do aparatu rozpoznawania musi zawierać słowa "Quick Fox" w kolejności, w jakiej zostanie rozpoznany.  
  
```csharp  
SemanticResultKey stringTest=new SemanticResultKey(  
    "stringTest", new GrammarBuilder[] {  
    new GrammarBuilder("the"),  
    new GrammarBuilder("quick"),  
    new GrammarBuilder("brown"),  
    new GrammarBuilder("fox")});  
```  
  
 Argument zawiera tag używany do uzyskiwania dostępu do, <xref:System.Speech.Recognition.SemanticValue> który może zostać zwrócony. `semanticResultKey`  
  
 Wartość jest określana przez <xref:System.Speech.Recognition.GrammarBuilder> wystąpienia dostarczone przez `builders` parametr. <xref:System.Speech.Recognition.SemanticValue> <xref:System.Speech.Recognition.SemanticValue.Value%2A>  
  
 Jeśli obiekty nie zawierają definiowania <xref:System.Speech.Recognition.SemanticResultValue>wystąpień <xref:System.Speech.Recognition.SemanticValue> , wartość jest `null`. <xref:System.Speech.Recognition.GrammarBuilder>  
  
 `builders` <xref:System.Speech.Recognition.SemanticResultKey> <xref:System.Speech.Recognition.SemanticResultValue> Jeśli obiekty dostarczone w parametrze zapewniają nieoznakowane (nieskojarzone z wystąpieniem obiektu), <xref:System.Speech.Recognition.SemanticResultValue> które jest używane przez logikę rozpoznawania, to wystąpienie zostanie zdefiniowane <xref:System.Speech.Recognition.GrammarBuilder> <xref:System.Speech.Recognition.SemanticValue.Value%2A>Właściwość ,którajestgenerowana.<xref:System.Speech.Recognition.SemanticValue>  
  
 Powinien istnieć jeden i tylko jeden nieoznakowany <xref:System.Speech.Recognition.SemanticResultValue> wystąpienie <xref:System.Speech.Recognition.GrammarBuilder> w obiektach określonych przez `builders` parametr. Jeśli wiele wystąpień nieoznakowanych <xref:System.Speech.Recognition.SemanticResultValue> jest skojarzonych <xref:System.Speech.Recognition.SemanticResultKey>z, każda z nich podejmie próbę <xref:System.Speech.Recognition.SemanticValue> ustawienia wartości wygenerowanej w wyniku rozpoznawania. Nie jest to dozwolone, a aparat rozpoznawania generuje wyjątek, gdy zostanie podjęta próba użycia <xref:System.Speech.Recognition.Grammar> utworzonego przy użyciu <xref:System.Speech.Recognition.SemanticResultKey> takiego wystąpienia.  
  
 <xref:System.Speech.Recognition.SemanticResultKey> <xref:System.Speech.Recognition.SemanticResultKey> Wystąpienia zawarte w obiektach określonych przez `builders` parametr i już skojarzone z innym nie mają wpływu na bieżące wystąpienie. <xref:System.Speech.Recognition.GrammarBuilder> <xref:System.Speech.Recognition.SemanticResultValue>  
  
   
  
## Examples  
 Poniższy przykład tworzy <xref:System.Speech.Recognition.Grammar> , aby rozpoznawać dane wejściowe hasła formularza "moje hasło to...", gdzie rzeczywiste dane wejściowe są dopasowane do symbolu wieloznacznego.  
  
 Symbol wieloznaczny jest oznakowany przez <xref:System.Speech.Recognition.SpeechRecognizer> , którego wartość klucza jest "Password". <xref:System.Speech.Recognition.Grammar.SpeechRecognized> Program obsługi sprawdza obecność tego tagu, uzyskuje dane wejściowe audio i weryfikuje hasło.  
  
```csharp  
private void pwdGrammar()   
{  
  GrammarBuilder pwdBuilder = new GrammarBuilder("My Password is");  
  GrammarBuilder wildcardBuilder = new GrammarBuilder();  
  wildcardBuilder.AppendWildcard();  
  SemanticResultKey wildcardKey= new SemanticResultKey("Password", wildcardBuilder);  
  pwdBuilder+=wildcardKey;  
  Grammar grammar = new Grammar(pwdBuilder);  
  grammar.Name = "Password input";  
  
  grammar.SpeechRecognized +=   
    delegate(object sender, SpeechRecognizedEventArgs eventArgs)   
    {  
      SemanticValue semantics = eventArgs.Result.Semantics;  
      RecognitionResult result=eventArgs.Result;  
  
      if (!semantics.ContainsKey("Password"))   
      {  
        SpeechUI.SendTextFeedback(eventArgs.Result, "No Password Provided", false);  
      }  
      else   
      {  
        RecognizedAudio pwdAudio = result.GetAudioForWordRange(  
                  result.Words[3],  
                  result.Words[result.Words.Count - 1]);  
                  MemoryStream pwdMemoryStream = new MemoryStream();  
                  pwdAudio.WriteToAudioStream(pwdMemoryStream);  
        if (!IsValidPwd(pwdMemoryStream))   
        {  
          string badPwd = System.IO.Path.GetTempPath() + "BadPwd" + (new Random()).Next().ToString() + ".wav";  
          FileStream waveStream = new FileStream(badPwd, FileMode.Create);    
          pwdAudio.WriteToWaveStream(waveStream);  
          waveStream.Flush();  
          waveStream.Close();  
          SpeechUI.SendTextFeedback(eventArgs.Result, "Invalid Password", false);      
        }  
      }  
    };  
  
  grammar.Enabled = true;  
  _recognizer.LoadGrammar(grammar);  
  UpdateGrammarTree(_grammarTreeView, _recognizer);  
  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SemanticResultKey (string semanticResultKey, params string[] phrases);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string semanticResultKey, string[] phrases) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SemanticResultKey.#ctor(System.String,System.String[])" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (semanticResultKey As String, ParamArray phrases As String())" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SemanticResultKey(System::String ^ semanticResultKey, ... cli::array &lt;System::String ^&gt; ^ phrases);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.SemanticResultKey : string * string[] -&gt; System.Speech.Recognition.SemanticResultKey" Usage="new System.Speech.Recognition.SemanticResultKey (semanticResultKey, phrases)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="semanticResultKey" Type="System.String" />
        <Parameter Name="phrases" Type="System.String[]">
          <Attributes>
            <Attribute FrameworkAlternate="netframework-3.0">
              <AttributeName>System.ParamArray</AttributeName>
            </Attribute>
          </Attributes>
        </Parameter>
      </Parameters>
      <Docs>
        <param name="semanticResultKey">Tag, który ma być używany, <see cref="T:System.Speech.Recognition.SemanticValue" /> uzyskuje dostęp do <see cref="T:System.String" /> wystąpienia skojarzonego z obiektami <paramref name="phrases" /> określonymi przez argument.</param>
        <param name="phrases">Jeden lub więcej <see cref="T:System.String" /> obiektów, których połączony tekst zostanie skojarzony <see cref="T:System.Speech.Recognition.SemanticValue" /> z obiektem dostępnym ze znacznikiem zdefiniowanym w <paramref name="semanticResultKey" />elemencie.</param>
        <summary>Przypisuje klucz semantyczny do jednego lub <see cref="T:System.String" /> większej liczby wystąpień używanych do tworzenia gramatyki rozpoznawania mowy.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Podczas wykonywania operacji <xref:System.String> rozpoznawania obiekty użyte `phrases` w parametrze są traktowane jako sekwencyjne. Na przykład jeśli poniższe <xref:System.Speech.Recognition.SemanticResultValue> dane są używane do <xref:System.Speech.Recognition.Grammar>konstruowania, wejście do aparatu rozpoznawania musi zawierać słowa "Quick Fox" w kolejności, w jakiej zostanie rozpoznany.  
  
```csharp  
SemanticResultKey stringTest=new SemanticResultKey("stringTest",   
                                new string[] {  
                                               "the",  
                                               "quick",  
                                               "brown",  
                                               "fox"});  
```  
  
 Argument określa klucz używany do uzyskiwania dostępu do, <xref:System.Speech.Recognition.SemanticValue> który może zostać zwrócony. `semanticResultKey`  
  
 W przypadku konstruowania <xref:System.Speech.Recognition.Grammar> <xref:System.Speech.Recognition.GrammarBuilder> obiektu, który zawiera klucz semantyczny z tablicą <xref:System.Speech.Recognition.SemanticValue> obiektów String, <xref:System.Speech.Recognition.SemanticValue.Value%2A> wygenerowane przez operację rozpoznawania będzie ciągiem używanym do rozpoznawania. W poprzednim przykładzie oznacza to, że <xref:System.Speech.Recognition.SemanticValue.Value%2A> jest to "Quick Brown Fox".  
  
   
  
## Examples  
 Poniższy <xref:System.Speech.Recognition.Grammar> przykład tworzy <xref:System.Speech.Recognition.GrammarBuilder> obiekt z obiektu, który używa elementu <xref:System.Speech.Recognition.SemanticResultKey> <xref:System.String> , który jest zdefiniowany przez tablicę obiektów.  
  
 Aparat rozpoznawania korzystający z <xref:System.Speech.Recognition.Grammar> utworzonego rozwiązania rozpozna frazę "Color Red Green Blue zero". Semantyka <xref:System.Speech.Recognition.RecognizedPhrase> zwrócona przez rozpoznanie będzie zawierać element <xref:System.Speech.Recognition.SemanticValue> z <xref:System.Speech.Recognition.SemanticValue.Value%2A> czerwonym zielonym niebieską. Możesz uzyskać dostęp <xref:System.Speech.Recognition.SemanticValue> do za pomocą tagu "Code".  
  
 Ze `SemanticResultValue("zero", 5)` <xref:System.Speech.Recognition.SemanticValue> <xref:System.Speech.Recognition.RecognizedPhrase> względu na to, że obiekt główny w elemencie będzie miał wartość 5. <xref:System.Speech.Recognition.GrammarBuilder>  
  
```csharp  
private void keyTest()   
{  
  // Say "color red green blue zero"  
  GrammarBuilder gb = new GrammarBuilder("color") +  
                        new SemanticResultKey("code",   
                          (new string[] {"red", "green", "blue"})) +  
                        new SemanticResultValue("zero", 5);  
  Grammar g = new Grammar(gb);  
  g.Name = "keyTest";  
  _recognizer.LoadGrammar(g);  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="ToGrammarBuilder">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.GrammarBuilder ToGrammarBuilder ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.GrammarBuilder ToGrammarBuilder() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SemanticResultKey.ToGrammarBuilder" />
      <MemberSignature Language="VB.NET" Value="Public Function ToGrammarBuilder () As GrammarBuilder" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::GrammarBuilder ^ ToGrammarBuilder();" />
      <MemberSignature Language="F#" Value="member this.ToGrammarBuilder : unit -&gt; System.Speech.Recognition.GrammarBuilder" Usage="semanticResultKey.ToGrammarBuilder " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.GrammarBuilder</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Zwraca wystąpienie <see cref="T:System.Speech.Recognition.GrammarBuilder" /> skonstruowane z bieżącego <see cref="T:System.Speech.Recognition.SemanticResultKey" /> wystąpienia.</summary>
        <returns>Wystąpienie <see cref="T:System.Speech.Recognition.GrammarBuilder" /> skonstruowane z bieżącego <see langword="SemanticResultKey" /> wystąpienia.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Użycie <xref:System.Speech.Recognition.SemanticResultValue.ToGrammarBuilder%2A> jest równoważne <xref:System.Speech.Recognition.GrammarBuilder> użyciu konstruktora, który przyjmuje <xref:System.Speech.Recognition.SemanticResultKey> jako argument (<xref:System.Speech.Recognition.GrammarBuilder.%23ctor%28System.Speech.Recognition.SemanticResultKey%29>).  
  
   
  
## Examples  
 Poniższy przykład tworzy <xref:System.Speech.Recognition.Grammar> obiekt, który obsługuje polecenia, aby zmienić kolor tła.  
  
 Obiekt (`colorChoice`) zawierający listę opcji <xref:System.Speech.Recognition.Choices.Add%28System.Speech.Recognition.GrammarBuilder%5B%5D%29> kolorów tła jest wypełniany przy użyciu metody z <xref:System.Speech.Recognition.GrammarBuilder> wystąpieniami. <xref:System.Speech.Recognition.Choices> Wystąpienia są uzyskiwane <xref:System.Speech.Recognition.SemanticResultKey.ToGrammarBuilder> za pośrednictwem metody dla <xref:System.Speech.Recognition.SemanticResultValue> obiektów utworzonych na podstawie ciągów kolorów. <xref:System.Speech.Recognition.GrammarBuilder>  
  
 A <xref:System.Speech.Recognition.GrammarBuilder> następnie jest uzyskiwany przez <xref:System.Speech.Recognition.SemanticResultKey.ToGrammarBuilder> wywołanie na <xref:System.Speech.Recognition.SemanticResultKey> wystąpieniu, które zostanie użyte do wybrania semantycznych opcji w `colorChoice`.  
  
```csharp  
  
private Grammar CreateGrammarBuilderRGBSemantics()   
{  
  
  // Create a set of choices, each a lookup from a color name to RGB.  
  // Choices constructors do not take SemanticResultValue parameters, so cast   
  // the SemanticResultValue to GrammarBuilder.  
  Choices colorChoice = new Choices();  
  foreach (string colorName in System.Enum.GetNames(typeof(KnownColor)))   
  {  
    SemanticResultValue colorValue=new SemanticResultValue(colorName, Color.FromName(colorName).ToArgb());  
  
    // Use implicit conversion of SemanticResultValue to GrammarBuilder.  
    colorChoice.Add(colorValue.ToGrammarBuilder());      
  }  
  SemanticResultKey choiceKey = new SemanticResultKey("rgb", colorChoice);  
  GrammarBuilder choiceBuilder = choiceKey.ToGrammarBuilder();  
  
  // Create two intermediate grammars with introductory phrase and the color choice.  
  GrammarBuilder makeBackgroundBuilder = "Make background";  
  makeBackgroundBuilder.Append(choiceBuilder);  
  
  GrammarBuilder configureBackgroundBuilder = new GrammarBuilder("Configure background as");  
  configureBackgroundBuilder.Append((new SemanticResultKey("rgb", colorChoice)).ToGrammarBuilder());  
  
  // Create the Grammar object, which recognizes either intermediate grammar.  
  Grammar grammar = new Grammar(new Choices(new GrammarBuilder[] {makeBackgroundBuilder, configureBackgroundBuilder}));  
  grammar.Name = "Make Background /Configure background as";  
  
  return grammar;  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>
