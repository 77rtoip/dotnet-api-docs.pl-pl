<Type Name="RecognizedPhrase" FullName="System.Speech.Recognition.RecognizedPhrase">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="71464227f9486ed513c58cfb8029f276b246b4b8" />
    <Meta Name="ms.sourcegitcommit" Value="6a0b904069161bbaec4ffd02aa7d9cf38c61e72e" />
    <Meta Name="ms.translationtype" Value="MT" />
    <Meta Name="ms.contentlocale" Value="pl-PL" />
    <Meta Name="ms.lasthandoff" Value="06/24/2018" />
    <Meta Name="ms.locfileid" Value="36409372" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class RecognizedPhrase" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit RecognizedPhrase extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizedPhrase" />
  <TypeSignature Language="VB.NET" Value="Public Class RecognizedPhrase" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognizedPhrase" />
  <TypeSignature Language="F#" Value="type RecognizedPhrase = class" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute>
      <AttributeName>System.Diagnostics.DebuggerDisplay("{Text}")</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Zawiera szczegółowe informacje, generowane przez aparat rozpoznawania mowy o rozpoznanym danych wejściowych.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ta klasa zawiera szczegółowe informacje na temat słów i wyrażeń przetworzone podczas operacji rozpoznawania mowy, takie jak następujące:  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> Odwołań do właściwości <xref:System.Speech.Recognition.Grammar> czy aparat rozpoznawania używany do identyfikowania danych wejściowych.  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> Właściwość zawiera tekst znormalizowane wyrażenie.  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> Semantycznego informacje zawarte w wyniku odwołuje się do właściwości. Informacje semantyczne jest słownikiem nazwy kluczy i skojarzone dane semantycznego.  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Właściwość zawiera uporządkowaną kolekcję <xref:System.Speech.Recognition.RecognizedWordUnit> obiekty reprezentujące każdego rozpoznany programu word w danych wejściowych. Każdej jednostki word zawiera wymowy informacje dotyczące odpowiedniego programu word, format leksykalne i format wyświetlania.  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits%2A> Właściwość zawiera informacje dotyczące specjalnych word podstawienia.  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Homophones%2A> i <xref:System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId%2A> właściwości zawierają informacje o zastępców rozpoznawania, które mają takie same lub podobne wymowy.  
  
-   Wartość <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> właściwość wskazuje stopień pewności, przypisany przez aparat rozpoznawania mowy rozpoznaną frazę zgodność danych wejściowych.  
  
 Aparat rozpoznawania mowy zwraca wyniki rozpoznawania w <xref:System.Speech.Recognition.RecognitionResult> obiektu, który dziedziczy <xref:System.Speech.Recognition.RecognizedPhrase>. Wynik rozpoznawania <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> właściwość zawiera uporządkowaną kolekcję <xref:System.Speech.Recognition.RecognizedPhrase> obiektów, z których każdy jest możliwe dopasowania dla danych wejściowych dla aparatu rozpoznawania.  
  
   
  
## Examples  
 W poniższym przykładzie przedstawiono obsługi dla <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType>, lub <xref:System.Speech.Recognition.Grammar.SpeechRecognized?displayProperty=nameWithType> zdarzeń i niektóre informacje związane z <xref:System.Speech.Recognition.RecognitionResult> obiektu. <xref:System.Speech.Recognition.RecognitionResult> Pochodną klasy <xref:System.Speech.Recognition.RecognizedPhrase> klasy.  
  
```csharp  
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Recognition result summary:");  
  Console.WriteLine(  
    "  Recognized phrase: {0}\n" +   
    "  Confidence score {1}\n" +   
    "  Grammar used: {2}\n",   
    e.Result.Text, e.Result.Confidence, e.Result.Grammar.Name);  
  
  // Display the semantic values in the recognition result.  
  Console.WriteLine("  Semantic results:");  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine("    The {0} city is {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  Console.WriteLine("  Word summary: ");  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    Console.WriteLine(  
      "    Lexical form ({1})" +  
      " Pronunciation ({0})" +  
      " Display form ({2})",  
      word.Pronunciation, word.LexicalForm, word.DisplayAttributes);  
  }  
  
  // Display information about the audio in the recognition result.  
  Console.WriteLine("  Input audio summary:\n" +  
    "    Candidate Phrase at:       {0} mSec\n" +  
    "    Phrase Length:             {1} mSec\n" +  
    "    Input State Time:          {2}\n" +  
    "    Input Format:              {3}\n",  
    e.Result.Audio.AudioPosition,  
    e.Result.Audio.Duration,  
    e.Result.Audio.StartTime,  
    e.Result.Audio.Format.EncodingFormat);  
  
  // Display information about the alternate recognitions in the recognition result.  
  Console.WriteLine("  Alternate phrase collection:");  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine("    Phrase: " + phrase.Text);  
    Console.WriteLine("    Confidence score: " + phrase.Confidence);  
  }  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
    <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
  </Docs>
  <Members>
    <Member MemberName="Confidence">
      <MemberSignature Language="C#" Value="public float Confidence { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance float32 Confidence" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Confidence" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Confidence As Single" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property float Confidence { float get(); };" />
      <MemberSignature Language="F#" Value="member this.Confidence : single" Usage="System.Speech.Recognition.RecognizedPhrase.Confidence" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Single</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera wartość, przypisany przez aparat rozpoznawania, który reprezentuje prawdopodobieństwo który <see cref="T:System.Speech.Recognition.RecognizedPhrase" /> odpowiada określonych danych wejściowych.</summary>
        <value>Miara względnych pewności poprawne rozpoznawanie frazę. Wartość jest od 0,0 do 1,0, niski wysokiego zaufania, aby uzyskać odpowiednio.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Wyniki zaufania nie wskazują bezwzględną prawdopodobieństwo frazę rozpoznano poprawnie. Zamiast tego zaufania wyniki mechanizm umożliwiający porównanie względną dokładność wielu alternatyw rozpoznawania dla określonych danych wejściowych. Ułatwia to zwrócenia wyniku rozpoznawania najbardziej dokładna. Na przykład jeśli rozpoznaną frazę ma wynik zaufania 0,8, to oznacza, że wyrażenie ma prawidłowe dopasowania dla danych wejściowych jest ryzyko 80%.  Go oznacza, że wyrażenie więcej mogą być prawidłowe dopasowania dla danych wejściowych od innych wyników, które mają zaufanie wyników mniejsza niż 0,8.  
  
 Wynik zaufania na jego własnej nie ma sensu, chyba że masz alternatywnych wyniki do porównania z tej samej operacji rozpoznawania albo z poprzedniego uznania tego samego danych wejściowych. Wartości są używane do rank candidate alternatywnych fraz zwrócony przez <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> właściwość <xref:System.Speech.Recognition.RecognitionResult> obiektów.  
  
 Względne i unikatowe mają wartości zaufania każdego aparatu rozpoznawania. Nie można uzyskać wiarygodny porównać wartości zaufania zwrócony przez dwa aparatów rozpoznawania inny.  
  
 Aparat rozpoznawania mowy może przydzielić wynik niski zaufania dane głosowe różnych powodów, takich jak zakłócenia w tle, inarticulate mowy lub nieprzewidziane słowa lub sekwencji programu word. Jeśli aplikacja korzysta <xref:System.Speech.Recognition.SpeechRecognitionEngine> wystąpienia, można zmodyfikować poziom ufności, w których mowy danych wejściowych jest zaakceptowane lub odrzucone z jednym z <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> metody. Progi zaufania udostępniony aparat rozpoznawania zarządza <xref:System.Speech.Recognition.SpeechRecognizer>, są skojarzone z profilem użytkownika i przechowywane w rejestrze systemu Windows. Aplikacje nie należy zapisać zmiany w rejestrze dla właściwości udostępniony aparat rozpoznawania.  
  
 <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> Właściwość <xref:System.Speech.Recognition.RecognitionResult> uporządkowana kolekcja zawiera obiekt <xref:System.Speech.Recognition.RecognizedPhrase> obiektów, z których każdy jest możliwe dopasowania dla danych wejściowych dla aparatu rozpoznawania. Zastępcy są uporządkowane od najwyższego do najniższego zaufania.  
  
   
  
## Examples  
 W poniższym przykładzie przedstawiono obsługi dla <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType>, lub <xref:System.Speech.Recognition.Grammar.SpeechRecognized?displayProperty=nameWithType> zdarzeń. W przykładzie przedstawiono informacje związane z <xref:System.Speech.Recognition.RecognitionResult> obiektu, niektóre z nich jest pochodną <xref:System.Speech.Recognition.RecognizedPhrase>. Program obsługi wyświetla wyniki zaufania dla rozpoznaną frazę również podobnie jak w przypadku zastępców rozpoznawania.  
  
```csharp  
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Recognition result summary:");  
  Console.WriteLine(  
    "  Recognized phrase: {0}\n" +   
    "  Confidence score {1}\n" +   
    "  Grammar used: {2}\n",   
    e.Result.Text, e.Result.Confidence, e.Result.Grammar.Name);  
  
  // Display the semantic values in the recognition result.  
  Console.WriteLine("  Semantic results:");  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine("    The {0} city is {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  Console.WriteLine("  Word summary: ");  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    Console.WriteLine(  
      "    Lexical form ({1})" +  
      " Pronunciation ({0})" +  
      " Display form ({2})",  
      word.Pronunciation, word.LexicalForm, word.DisplayAttributes);  
  }  
  
  // Display information about the audio in the recognition result.  
  Console.WriteLine("  Input audio summary:\n" +  
    "    Candidate Phrase at:       {0} mSec\n" +  
    "    Phrase Length:             {1} mSec\n" +  
    "    Input State Time:          {2}\n" +  
    "    Input Format:              {3}\n",  
    e.Result.Audio.AudioPosition,  
    e.Result.Audio.Duration,  
    e.Result.Audio.StartTime,  
    e.Result.Audio.Format.EncodingFormat);  
  
  // Display information about the alternate recognitions in the recognition result.  
  Console.WriteLine("  Alternate phrase collection:");  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine("    Phrase: " + phrase.Text);  
    Console.WriteLine("    Confidence score: " + phrase.Confidence);  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
      </Docs>
    </Member>
    <Member MemberName="ConstructSmlFromSemantics">
      <MemberSignature Language="C#" Value="public System.Xml.XPath.IXPathNavigable ConstructSmlFromSemantics ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Xml.XPath.IXPathNavigable ConstructSmlFromSemantics() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognizedPhrase.ConstructSmlFromSemantics" />
      <MemberSignature Language="VB.NET" Value="Public Function ConstructSmlFromSemantics () As IXPathNavigable" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Xml::XPath::IXPathNavigable ^ ConstructSmlFromSemantics();" />
      <MemberSignature Language="F#" Value="member this.ConstructSmlFromSemantics : unit -&gt; System.Xml.XPath.IXPathNavigable" Usage="recognizedPhrase.ConstructSmlFromSemantics " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Xml.XPath.IXPathNavigable</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Zwracają dokument języka (SML) znaczników semantyki informacje semantyczne w <see cref="T:System.Speech.Recognition.RecognizedPhrase" /> obiektu.</summary>
        <returns>Zwraca opis SML semantykę <see cref="T:System.Speech.Recognition.RecognizedPhrase" /> jako [XPath] (http://msdn.microsoft.com/library/ms256115.aspx) obiektu można nawigować.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aby uzyskać informacje na temat języka znaczników semantyki (SML), zobacz [dokumentację języka znaczników semantyki](http://msdn.microsoft.com/library/f9d83443-2cac-49bc-a447-210feda62f5d).  
  
   
  
## Examples  
 W poniższym przykładzie metoda zwraca ciąg zawierający SML dla semantykę rozpoznaną frazę.  
  
```  
private string GetSemanticsSML(RecognizedPhrase result)  
{  
  if (result.Semantics.Count > 0)  
  {  
    return result.ConstructSmlFromSemantics().CreateNavigator().OuterXml;  
  }  
  else  
  {  
    return null;  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="Grammar">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.Grammar Grammar { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.Grammar Grammar" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Grammar" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Grammar As Grammar" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::Grammar ^ Grammar { System::Speech::Recognition::Grammar ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Grammar : System.Speech.Recognition.Grammar" Usage="System.Speech.Recognition.RecognizedPhrase.Grammar" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.Grammar</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera <see cref="T:System.Speech.Recognition.Grammar" /> używanego przez aparat rozpoznawania mowy do zwrócenia <see cref="T:System.Speech.Recognition.RecognizedPhrase" />.</summary>
        <value>Obiekt gramatyki rozpoznawania mowy umożliwia identyfikowanie danych wejściowych.</value>
        <remarks>To be added.</remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
      </Docs>
    </Member>
    <Member MemberName="HomophoneGroupId">
      <MemberSignature Language="C#" Value="public int HomophoneGroupId { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 HomophoneGroupId" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property HomophoneGroupId As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int HomophoneGroupId { int get(); };" />
      <MemberSignature Language="F#" Value="member this.HomophoneGroupId : int" Usage="System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera identyfikator grupy homophone frazy.</summary>
        <value>Identyfikator grupy homophone frazy.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aparat rozpoznawania mowy przypisuje identyfikator grupy wszystkich zastępców rozpoznawania mających wymowy tego samego. Dla każdego zastępcy ma unikatowy wymowy aparat rozpoznawania tworzy grupę homophone. Aparat rozpoznawania mowy generuje nową grupę identyfikatorów dla każdej operacji rozpoznawania, i identyfikatory nie może służyć do porównania alternatyw generowane na podstawie rozpoznawania osobne operacje.  
  
 Na przykład wyniku rozpoznawania, który zawiera zastępcy "wskaźnik", "fragmentu" i "ale", pierwsze dwa elementy alternatywne może należeć do jednej grupy homophone i ostatniego alternatywnego byłoby pojedynczy element członkowski drugiej grupy homophone.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Homophones" />
      </Docs>
    </Member>
    <Member MemberName="Homophones">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt; Homophones { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizedPhrase&gt; Homophones" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Homophones" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Homophones As ReadOnlyCollection(Of RecognizedPhrase)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ Homophones { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Homophones : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;" Usage="System.Speech.Recognition.RecognizedPhrase.Homophones" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera kolekcję alternatyw rozpoznawania mających tego samego wymowy jako ta fraza rozpoznany.</summary>
        <value>Kolekcja tylko do odczytu alternatyw rozpoznawania mających tego samego wymowy jako ta fraza rozpoznany.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ta właściwość zwraca wszystkie inne zastępców rozpoznawania mających tego samego wymowy jako ta fraza rozpoznany.  
  
 Na przykład dla wyników rozpoznawania zawierający zastępcy, "wskaźnik" i "fragmentu", Kolekcja homophones dla pierwszego alternatywnego "wskaźnik" zawiera drugi frazę "fragmentu". Kolekcja homophones dla drugiego alternatywnego "fragmentu" zawiera pierwszy frazę "wskaźnik".  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId" />
      </Docs>
    </Member>
    <Member MemberName="ReplacementWordUnits">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.Collection&lt;System.Speech.Recognition.ReplacementText&gt; ReplacementWordUnits { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.Collection`1&lt;class System.Speech.Recognition.ReplacementText&gt; ReplacementWordUnits" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property ReplacementWordUnits As Collection(Of ReplacementText)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::Collection&lt;System::Speech::Recognition::ReplacementText ^&gt; ^ ReplacementWordUnits { System::Collections::ObjectModel::Collection&lt;System::Speech::Recognition::ReplacementText ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.ReplacementWordUnits : System.Collections.ObjectModel.Collection&lt;System.Speech.Recognition.ReplacementText&gt;" Usage="System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.Collection&lt;System.Speech.Recognition.ReplacementText&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera informacje o tekst, który aparat rozpoznawania mowy zmienić jako część mowy na tekst normalizacji.</summary>
        <value>Kolekcja <see cref="T:System.Speech.Recognition.ReplacementText" /> obiektów, które opisują fragmentów tekstu, który aparat rozpoznawania mowy zastąpiony podczas jego znormalizowany rozpoznanym danych wejściowych.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 W ramach procesu rozpoznawania mowy aparat rozpoznawania mowy normalizuje rozpoznanym wprowadzania w formie wyświetlania.  
  
 Na przykład rozmowy dane wejściowe "dwadzieścia pięć dolarów", generuje wyniku rozpoznawania gdzie <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość zawiera wyrazy, "20", "5" i "kwoty" i <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> właściwość zawiera słowo "25,00". Aby uzyskać więcej informacji na temat normalizacji tekstu, zobacz <xref:System.Speech.Recognition.ReplacementText> klasy.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
        <altmember cref="T:System.Speech.Recognition.ReplacementText" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Text" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      </Docs>
    </Member>
    <Member MemberName="Semantics">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.SemanticValue Semantics { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.SemanticValue Semantics" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Semantics" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Semantics As SemanticValue" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::SemanticValue ^ Semantics { System::Speech::Recognition::SemanticValue ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Semantics : System.Speech.Recognition.SemanticValue" Usage="System.Speech.Recognition.RecognizedPhrase.Semantics" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.SemanticValue</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera informacje semantyczne, który jest skojarzony z rozpoznaną frazę.</summary>
        <value>Informacje semantycznego skojarzonego z rozpoznaną frazę.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Gramatyka rozpoznawania mowy mogą obejmować informacje semantyczne. Podczas rozpoznawania mowy wygeneruje wyniku rozpoznawania takich gramatyki, informacje semantyczne mogą zostać dołączone do wyniku rozpoznawania zgodnie z regułami gramatyki i dane wejściowe dla aparatu rozpoznawania. Aby uzyskać więcej informacji na temat informacje semantyczne, zobacz [opis wyników semantycznego](http://msdn.microsoft.com/library/2a9dbd8b-cf6d-42cd-bbb9-ca0b3e534005) i <xref:System.Speech.Recognition.SemanticResultKey> i <xref:System.Speech.Recognition.SemanticResultValue> klasy.  
  
   
  
## Examples  
 W poniższym przykładzie zdefiniowano metodę, która pobiera określone informacje semantyczne z rozpoznaną frazę. Po powrocie z tej metody zawiera wartość klucz semantyki lub wartość null, jeśli wartość nie została pobrana. Ta metoda sprawdza, czy tylko klucze najwyższego poziomu. Ponieważ semantycznego informacje są przechowywane w formie drzewa wartości, niższego poziomu muszą być dostępne za pośrednictwem zwrócona wartość semantycznego.  
  
```  
static bool TryGetSemanticValue(  
      RecognizedPhrase phrase, string key, out SemanticValue value)  
{  
  value = null;  
  bool found = phrase.Semantics.ContainsKey(key);  
  if (found)  
  {  
    value = phrase.Semantics[key];  
  }  
  
  return found;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SemanticResultKey" />
        <altmember cref="T:System.Speech.Recognition.SemanticResultValue" />
        <altmember cref="T:System.Speech.Recognition.SemanticValue" />
      </Docs>
    </Member>
    <Member MemberName="Text">
      <MemberSignature Language="C#" Value="public string Text { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Text" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Text" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Text As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ Text { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Text : string" Usage="System.Speech.Recognition.RecognizedPhrase.Text" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera tekst znormalizowane wygenerowany przez aparat rozpoznawania mowy z rozpoznanym danych wejściowych.</summary>
        <value>Tekst znormalizowane wygenerowany przez aparat rozpoznawania mowy z rozpoznanym danych wejściowych.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 W ramach procesu rozpoznawania mowy aparat rozpoznawania mowy wykonuje normalizacji mowy na tekst rozpoznany danych wejściowych do wyświetlania formularza.  
  
 Na przykład rozmowy dane wejściowe "dwadzieścia pięć dolarów", generuje wyniku rozpoznawania gdzie <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość zawiera wyrazy, "20", "5" i "kwoty" i <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> właściwość zawiera słowo "25,00". Aby uzyskać więcej informacji na temat normalizacji tekstu, zobacz <xref:System.Speech.Recognition.ReplacementText>.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      </Docs>
    </Member>
    <Member MemberName="Words">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedWordUnit&gt; Words { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizedWordUnit&gt; Words" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Words As ReadOnlyCollection(Of RecognizedWordUnit)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ Words { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Words : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedWordUnit&gt;" Usage="System.Speech.Recognition.RecognizedPhrase.Words" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedWordUnit&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Pobiera słowa wygenerowany przez aparat rozpoznawania mowy z rozpoznanym danych wejściowych.</summary>
        <value>Kolekcja <see cref="T:System.Speech.Recognition.RecognizedWordUnit" /> obiektów wygenerowany przez aparat rozpoznawania mowy dla rozpoznanego danych wejściowych.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ta właściwość zawiera wyrazy, utworzonej z danych wejściowych przez aparat rozpoznawania mowy przed aparat rozpoznawania mowy na tekst normalizacji wyniku.  
  
 Na przykład rozmowy dane wejściowe "dwadzieścia pięć dolarów", generuje wyniku rozpoznawania gdzie <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> właściwość zawiera wyrazy, "20", "5" i "kwoty" i <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> właściwość zawiera słowo "25,00". Aby uzyskać więcej informacji na temat normalizacji tekstu, zobacz <xref:System.Speech.Recognition.ReplacementText>.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Text" />
      </Docs>
    </Member>
  </Members>
</Type>