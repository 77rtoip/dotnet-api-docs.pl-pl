<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="SpeechRecognizer.xml" source-language="en-US" target-language="pl-PL">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-15c36f0" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">02cd5861-7ce2-4a82-b358-31f8435a0ac5bc77257cd77c3fc2c078698df4cc6e968d3bf09a.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">bc77257cd77c3fc2c078698df4cc6e968d3bf09a</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/03/2018</xliffext:ms.lasthandoff>
      <xliffext:moniker_ids xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">netframework-4.5.1,netframework-4.5.2,netframework-4.5,netframework-4.6.1,netframework-4.6.2,netframework-4.6,netframework-4.7.1,netframework-4.7</xliffext:moniker_ids>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Provides access to the shared speech recognition service available on the Windows desktop.</source>
          <target state="translated">Zapewnia dostęp do usługi rozpoznawania mowy udostępnionego dostępne na pulpicie systemu Windows.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Applications use the shared recognizer to access Windows Speech Recognition.</source>
          <target state="translated">Aplikacje umożliwia dostęp do rozpoznawania mowy udostępniony aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object to add to the Windows speech user experience.</source>
          <target state="translated">Użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> obiekt do dodania do środowisko użytkownika systemu Windows mowy.</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This class provides control over various aspects of the speech recognition process:</source>
          <target state="translated">Ta klasa umożliwia sterowanie różnych aspektów procesu rozpoznawania mowy:</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To manage speech recognition grammars, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph>.</source>
          <target state="translated">Aby zarządzać gramatyki rozpoznawania mowy, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph>, i <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To get information about current speech recognition operations, subscribe to the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>’s <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events.</source>
          <target state="translated">Aby uzyskać informacje o bieżącym mowy operacji rozpoznawania, subskrybować <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>w <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, i <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> zdarzenia.</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To view or modify the number of alternate results the recognizer returns, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> property.</source>
          <target state="translated">Aby wyświetlić lub zmodyfikować liczbę wyników alternatywnych zwraca aparat rozpoznawania, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer returns recognition results in a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated">Aparat rozpoznawania zwraca wyniki rozpoznawania w <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To access or monitor the state of the shared recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph>, <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph>, <ph id="ph6">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, and <ph id="ph7">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> properties and the <ph id="ph8">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated&gt;</ph>, <ph id="ph9">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred&gt;</ph>, <ph id="ph10">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged&gt;</ph>, and <ph id="ph11">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> events.</source>
          <target state="translated">Aby uzyskać dostęp, lub monitorować stan udostępniony aparat rozpoznawania, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph>, <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph>, <ph id="ph6">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, i <ph id="ph7">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> właściwości i <ph id="ph8">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated&gt;</ph>, <ph id="ph9">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred&gt;</ph>, <ph id="ph10">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged&gt;</ph>, i <ph id="ph11">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> zdarzenia.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To synchronize changes to the recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Aby zsynchronizować zmiany aparat rozpoznawania, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The shared recognizer uses more than one thread to perform tasks.</source>
          <target state="translated">Udostępniony aparat rozpoznawania używa więcej niż jeden wątek, do wykonywania zadań.</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To emulate input to the shared recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Aby emulować dane wejściowe udostępniony aparat rozpoznawania, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The configuration of Windows Speech Recognition is managed by the use of the <bpt id="p1">**</bpt>Speech Properties<ept id="p1">**</ept> dialog in the <bpt id="p2">**</bpt>Control Panel<ept id="p2">**</ept>.</source>
          <target state="translated">Konfiguracja rozpoznawanie mowy systemu Windows odbywa się przy użyciu <bpt id="p1">**</bpt>właściwości mowy<ept id="p1">**</ept> okno dialogowe w <bpt id="p2">**</bpt>Panelu sterowania<ept id="p2">**</ept>.</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This interface is used to select the default desktop speech recognition engine and language, the audio input device, and the sleep behavior of speech recognition.</source>
          <target state="translated">Ten interfejs jest używany, aby wybrać domyślny aparat rozpoznawania mowy pulpitu i języka, urządzenia wejściowego audio i zachowanie uśpienia rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the configuration of Windows Speech Recognition is changed while the application is running, (for instance, if speech recognition is disabled or the input language is changed), the change affects all <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> objects.</source>
          <target state="translated">Po zmianie konfiguracji rozpoznawanie mowy systemu Windows po uruchomieniu aplikacji (na przykład rozpoznawanie mowy jest wyłączona lub zmianie języka wprowadzania), zmiana wpływa na wszystkie <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To create an in-process speech recognizer that is independent of Windows Speech Recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> class.</source>
          <target state="translated">Aby utworzyć rozpoznawania mowy w procesie, która jest niezależna od rozpoznawanie mowy w systemie Windows, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> klasy.</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Always call <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A&gt;</ph> before you release your last reference to the speech recognizer.</source>
          <target state="translated">Wywoływanie zawsze <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A&gt;</ph> przed zwolnieniem ostatniego odwołania do rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Otherwise, the resources it is using will not be freed until the garbage collector calls the recognizer object's <ph id="ph1">`Finalize`</ph> method.</source>
          <target state="translated">W przeciwnym razie używa zasobów nie zostanie zwolniona, dopóki moduł garbage collector wywołuje obiekt aparatu rozpoznawania <ph id="ph1">`Finalize`</ph> metody.</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Poniższy przykład jest częścią aplikacji konsoli, który ładuje gramatyki rozpoznawania mowy i przedstawia asynchroniczne emulowanej danych wejściowych, wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Jeśli rozpoznawania mowy nie jest uruchomiona, następnie uruchomienie tej aplikacji powoduje również uruchomienie rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Jeśli rozpoznawanie mowy systemu Windows znajduje się w <bpt id="p1">**</bpt>uśpione<ept id="p1">**</ept> stanu, następnie <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> zawsze zwraca wartość null.</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> class.</source>
          <target state="translated">Inicjuje nowe wystąpienie klasy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> klasy.</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object maintains a separate set of speech recognition grammars.</source>
          <target state="translated">Każdy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> obiekt przechowuje osobny zestaw gramatyki rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Poniższy przykład jest częścią aplikacji konsoli, który ładuje gramatyki rozpoznawania mowy i przedstawia asynchroniczne emulowanej danych wejściowych, wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Jeśli rozpoznawania mowy nie jest uruchomiona, następnie uruchomienie tej aplikacji powoduje również uruchomienie rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Jeśli rozpoznawanie mowy systemu Windows znajduje się w <bpt id="p1">**</bpt>uśpione<ept id="p1">**</ept> stanu, następnie <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> zawsze zwraca wartość null.</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat">
          <source>Gets the format of the audio being received by the speech recognizer.</source>
          <target state="translated">Pobiera format audio odbierane przez aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat">
          <source>The audio input format for the speech recognizer, or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the input to the recognizer is not configured.</source>
          <target state="translated">Format wejściowy audio rozpoznawania mowy lub <ph id="ph1">&lt;see langword="null" /&gt;</ph> Jeśli dane wejściowe aparat rozpoznawania nie jest skonfigurowany.</target>       </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel">
          <source>Gets the level of the audio being received by the speech recognizer.</source>
          <target state="translated">Pobiera poziom dźwięku odbierane przez aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel">
          <source>The audio level of the input to the speech recognizer, from 0 through 100.</source>
          <target state="translated">Poziom audio w danych wejściowych rozpoznawania mowy od 0 do 100.</target>       </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>Occurs when the shared recognizer reports the level of its audio input.</source>
          <target state="translated">Występuje, gdy udostępniony aparat rozpoznawania zgłasza poziom jego wejście audio.</target>       </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The recognizer raises this event multiple times per second.</source>
          <target state="translated">Aparat rozpoznawania zgłasza zdarzenie, to wiele razy w ciągu sekundy.</target>       </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The frequency with which the event is raised depends on the computer on which the application is running.</source>
          <target state="translated">Częstotliwość, z którym zdarzenia zależy od komputera, na którym jest uruchomiona aplikacja.</target>       </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>To get the audio level at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ph>.</source>
          <target state="translated">Aby uzyskać poziom audio w czasie zdarzenia, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</ph> właściwości skojarzonego <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>To get the current audio level of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> property.</source>
          <target state="translated">Aby uzyskać bieżący poziom audio w danych wejściowych aparat rozpoznawania, należy użyć aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>When you create a delegate for an <ph id="ph1">`AudioLevelUpdated`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia obiektu delegowanego dla <ph id="ph1">`AudioLevelUpdated`</ph> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The following example adds a handler for the <ph id="ph1">`AudioLevelUpdated`</ph> event to a <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object.</source>
          <target state="translated">Poniższy przykład umożliwia dodanie obsługi dla <ph id="ph1">`AudioLevelUpdated`</ph> zdarzenia <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The handler outputs the new audio level to the console.</source>
          <target state="translated">Program obsługi generuje nowy poziom audio do konsoli.</target>       </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>Gets the current location in the audio stream being generated by the device that is providing input to the speech recognizer.</source>
          <target state="translated">Pobiera bieżącą lokalizację w strumieniem audio generowany przez urządzenie, który dostarcza dane wejściowe do rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>The current location in the speech recognizer's audio input stream through which it has received input.</source>
          <target state="translated">Bieżąca lokalizacja rozpoznawania mowy audio strumień wejściowy za pośrednictwem której otrzymał danych wejściowych.</target>       </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>The shared recognizer receives input while the desktop speech recognition is running.</source>
          <target state="translated">Udostępniony aparat rozpoznawania odbiera dane wejściowe podczas rozpoznawania mowy pulpitu.</target>       </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>The <ph id="ph1">`AudioPosition`</ph> property references the input device's position in its generated audio stream.</source>
          <target state="translated"><ph id="ph1">`AudioPosition`</ph> Właściwość odwołuje się do pozycji urządzenia wejściowego w jego wygenerowanego strumieniem audio.</target>       </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property references the recognizer's position in processing audio input.</source>
          <target state="translated">Z kolei <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> właściwość odwołuje się do pozycji aparat rozpoznawania podczas przetwarzania danych wejściowych audio.</target>       </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>These positions can be different.</source>
          <target state="translated">Te pozycje mogą być różne.</target>       </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property.</source>
          <target state="translated">Na przykład jeśli aparat rozpoznawania otrzymał wejściowych, do których nie ma jeszcze generowane w wyniku rozpoznawania, a następnie wartość <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> właściwości jest mniejsza niż wartość <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>In the following example, the shared speech recognizer uses a dictation grammar to match speech input.</source>
          <target state="translated">W poniższym przykładzie rozpoznawania mowy udostępnionego używa gramatyki dyktowania w celu dopasowania danych wejściowych mowy.</target>       </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event writes to the console the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, and  <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> when the speech recognizer detects speech at its input.</source>
          <target state="translated">Program obsługi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> zapisuje zdarzenie w konsoli <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> podczas rozpoznawania mowy wykrywa mowy na jej danych wejściowych.</target>       </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>Occurs when the recognizer encounters a problem in the audio signal.</source>
          <target state="translated">Występuje, gdy aparat rozpoznawania napotka problem w sygnału dźwiękowego.</target>       </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>To get which problem occurred, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ph>.</source>
          <target state="translated">Aby uzyskać, jaki problem wystąpił, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</ph> właściwości skojarzonego <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>When you create a delegate for an <ph id="ph1">`AudioSignalProblemOccurred`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia obiektu delegowanego dla <ph id="ph1">`AudioSignalProblemOccurred`</ph> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>The following example defines an event handler that gathers information about an <ph id="ph1">`AudioSignalProblemOccurred`</ph> event.</source>
          <target state="translated">W poniższym przykładzie zdefiniowano program obsługi zdarzeń, które zbiera informacje o <ph id="ph1">`AudioSignalProblemOccurred`</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioState">
          <source>Gets the state of the audio being received by the speech recognizer.</source>
          <target state="translated">Pobiera stan audio odbierane przez aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioState">
          <source>The state of the audio input to the speech recognizer.</source>
          <target state="translated">Stan wejście audio do rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>Occurs when the state changes in the audio being received by the recognizer.</source>
          <target state="translated">Występuje, gdy zmian stanu, które usłyszysz odbierane przez aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>To get the audio state at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ph>.</source>
          <target state="translated">Aby pobrać stan dźwięku w czasie zdarzenia, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</ph> właściwości skojarzonego <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>To get the current audio state of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> property.</source>
          <target state="translated">Aby uzyskać bieżący stan audio w danych wejściowych aparat rozpoznawania, należy użyć aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>For more information about audio state, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat stanu audio, zobacz <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> wyliczenia.</target>       </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>When you create a delegate for an <ph id="ph1">`AudioStateChanged`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia obiektu delegowanego dla <ph id="ph1">`AudioStateChanged`</ph> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>The following example uses a handler for the <ph id="ph1">`AudioStateChanged`</ph> event to write the recognizer's new <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> to the console each time it changes using a member of the <ph id="ph3">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated">W poniższym przykładzie użyto obsługi dla <ph id="ph1">`AudioStateChanged`</ph> zdarzenie, aby zapisać aparat rozpoznawania na nowy <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> konsoli każdego czasu zmiany przy użyciu członkiem <ph id="ph3">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> wyliczenia.</target>       </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Usuwa <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.Dispose">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Usuwa <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> to release both managed and unmanaged resources; <ph id="ph2">&lt;see langword="false" /&gt;</ph> to release only unmanaged resources.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph> Aby zwolnić zasoby zarządzane i niezarządzane; <ph id="ph2">&lt;see langword="false" /&gt;</ph> aby zwolnić tylko zasoby niezarządzane.</target>       </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object and releases resources used during the session.</source>
          <target state="translated">Usuwa <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> obiektu i zwalnia zasoby używane w podczas sesji.</target>       </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Emulates input to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</source>
          <target state="translated">Emuluje dane wejściowe do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy synchronicznego.</target>       </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>These methods bypass the system audio input.</source>
          <target state="translated">Te metody obejścia wejście audio systemu.</target>       </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This can be helpful when you are testing or debugging an application or grammar.</source>
          <target state="translated">Może to być przydatne podczas testowania i debugowania aplikacji oraz błędy gramatyczne.</target>       </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then these methods return <ph id="ph1">`null`</ph>.</source>
          <target state="translated">Jeśli rozpoznawanie mowy systemu Windows znajduje się w <bpt id="p1">**</bpt>uśpione<ept id="p1">**</ept> stanu, a następnie te metody zwracają <ph id="ph1">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The shared recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje udostępniony aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> zdarzeń tak, jakby nie jest emulowana operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Aparat rozpoznawania ignoruje nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</target>       </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object generated by the shared recognizer in response to emulated input has a value of <ph id="ph2">`null`</ph> for its <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> Generowane przez udostępniony aparat rozpoznawania w odpowiedzi na dane wejściowe emulowanej obiektu ma wartość <ph id="ph2">`null`</ph> dla jego <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To emulate asynchronous recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method.</source>
          <target state="translated">Aby emulować asynchroniczne rozpoznawanie, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The input for the recognition operation.</source>
          <target state="translated">Dane wejściowe dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</source>
          <target state="translated">Emuluje wprowadzania frazę do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy synchronicznego.</target>       </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The recognition result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
          <target state="translated">Wynik rozpoznawania dla operacji rozpoznawania, lub <ph id="ph1">&lt;see langword="null" /&gt;</ph>, jeśli operacja nie powiedzie się lub rozpoznawanie mowy systemu Windows jest w <bpt id="p1">**</bpt>uśpione<ept id="p1">**</ept> stanu.</target>       </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter i znaków szerokości, stosując reguły gramatyki do wprowadzania frazy.</target>       </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
          <target state="translated">Aby uzyskać więcej informacji o tym typie porównanie, zobacz <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> wartości wyliczenia <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> i <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i Traktuj znaki interpunkcyjne jako dane wejściowe literału.</target>       </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The following example loads a sample grammar to the shared recognizer and emulates input to the recognizer.</source>
          <target state="translated">W poniższym przykładzie ładuje gramatyki próbki do udostępniony aparat rozpoznawania i emuluje dane wejściowe dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Jeśli rozpoznawania mowy nie jest uruchomiona, następnie uruchomienie tej aplikacji powoduje również uruchomienie rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> always returns null.</source>
          <target state="translated">Jeśli rozpoznawanie mowy systemu Windows znajduje się w <bpt id="p1">**</bpt>uśpione<ept id="p1">**</ept> stanu, następnie <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> zawsze zwraca wartość null.</target>       </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">Tablica jednostki słowa zawierającego dane wejściowe dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</target>       </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>Emulates input of specific words to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">Emuluje wprowadzania słów do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy synchroniczne i określa sposób obsługi przez aparat rozpoznawania porównanie Unicode słów i gramatyki rozpoznawania mowy załadowany.</target>       </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognition result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
          <target state="translated">Wynik rozpoznawania dla operacji rozpoznawania, lub <ph id="ph1">&lt;see langword="null" /&gt;</ph>, jeśli operacja nie powiedzie się lub rozpoznawanie mowy systemu Windows jest w <bpt id="p1">**</bpt>uśpione<ept id="p1">**</ept> stanu.</target>       </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>This method creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object using the information provided in the <ph id="ph2">`wordUnits`</ph> parameter.</source>
          <target state="translated">Ta metoda tworzy <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> obiektów, korzystając z informacji podanych w <ph id="ph2">`wordUnits`</ph> parametru.</target>       </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Aparat rozpoznawania używa <ph id="ph1">`compareOptions`</ph> po stosuje reguły gramatyki do frazy wejściowych.</target>       </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> lub <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> ma wartość.</target>       </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Aparatów rozpoznawania zawsze Ignoruj szerokość znaku i nigdy nie Ignoruj typu znaki Kana.</target>       </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</target>       </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> wyliczenia.</target>       </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">Wyrażenie wejściowych dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</target>       </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">Emuluje wprowadzania frazę do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy synchroniczne i określa sposób obsługi przez aparat rozpoznawania Unicode porównanie frazę gramatyki rozpoznawania mowy załadowany.</target>       </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognition result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
          <target state="translated">Wynik rozpoznawania dla operacji rozpoznawania, lub <ph id="ph1">&lt;see langword="null" /&gt;</ph>, jeśli operacja nie powiedzie się lub rozpoznawanie mowy systemu Windows jest w <bpt id="p1">**</bpt>uśpione<ept id="p1">**</ept> stanu.</target>       </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Aparat rozpoznawania używa <ph id="ph1">`compareOptions`</ph> po stosuje reguły gramatyki do frazy wejściowych.</target>       </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> lub <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> ma wartość.</target>       </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Aparatów rozpoznawania zawsze Ignoruj szerokość znaku i nigdy nie Ignoruj typu znaki Kana.</target>       </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</target>       </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> wyliczenia.</target>       </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Emulates input to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</source>
          <target state="translated">Emuluje dane wejściowe do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy asynchronicznego.</target>       </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>These methods bypass the system audio input.</source>
          <target state="translated">Te metody obejścia wejście audio systemu.</target>       </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This can be helpful when you are testing or debugging an application or grammar.</source>
          <target state="translated">Może to być przydatne podczas testowania i debugowania aplikacji oraz błędy gramatyczne.</target>       </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The shared recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje udostępniony aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> zdarzeń tak, jakby nie jest emulowana operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Po ukończeniu operacji asynchronicznej rozpoznawania aparat rozpoznawania zgłasza <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Aparat rozpoznawania ignoruje nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</target>       </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then the shared recognizer does not process input and does not raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> and related events, but still raises the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Jeśli rozpoznawanie mowy systemu Windows znajduje się w <bpt id="p1">**</bpt>uśpione<ept id="p1">**</ept> stanu, a następnie udostępniony aparat rozpoznawania nie przetwarza danych wejściowych i nie zgłosi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> i zdarzenia powiązane, ale nadal zgłasza <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object generated by the shared recognizer in response to emulated input has a value of <ph id="ph2">`null`</ph> for its <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> Generowane przez udostępniony aparat rozpoznawania w odpowiedzi na dane wejściowe emulowanej obiektu ma wartość <ph id="ph2">`null`</ph> dla jego <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To emulate synchronous recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> method.</source>
          <target state="translated">Aby emulować rozpoznawania synchroniczne, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The input for the recognition operation.</source>
          <target state="translated">Dane wejściowe dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</source>
          <target state="translated">Emuluje wprowadzania frazę do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy asynchronicznego.</target>       </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter i znaków szerokości, stosując reguły gramatyki do wprowadzania frazy.</target>       </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
          <target state="translated">Aby uzyskać więcej informacji o tym typie porównanie, zobacz <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> wartości wyliczenia <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> i <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i Traktuj znaki interpunkcyjne jako dane wejściowe literału.</target>       </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Poniższy przykład jest częścią aplikacji konsoli, który ładuje gramatyki rozpoznawania mowy i przedstawia asynchroniczne emulowanej danych wejściowych, wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Jeśli rozpoznawania mowy nie jest uruchomiona, następnie uruchomienie tej aplikacji powoduje również uruchomienie rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Jeśli rozpoznawanie mowy systemu Windows znajduje się w <bpt id="p1">**</bpt>uśpione<ept id="p1">**</ept> stanu, następnie <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> zawsze zwraca wartość null.</target>       </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">Tablica jednostki słowa zawierającego dane wejściowe dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</target>       </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>Emulates input of specific words to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">Emuluje wprowadzania słów do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy asynchroniczne i określa sposób obsługi przez aparat rozpoznawania porównanie Unicode słów i gramatyki rozpoznawania mowy załadowany.</target>       </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>This method creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object using the information provided in the <ph id="ph2">`wordUnits`</ph> parameter.</source>
          <target state="translated">Ta metoda tworzy <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> obiektów, korzystając z informacji podanych w <ph id="ph2">`wordUnits`</ph> parametru.</target>       </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Aparat rozpoznawania używa <ph id="ph1">`compareOptions`</ph> po stosuje reguły gramatyki do frazy wejściowych.</target>       </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> lub <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> ma wartość.</target>       </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Aparatów rozpoznawania zawsze Ignoruj szerokość znaku i nigdy nie Ignoruj typu znaki Kana.</target>       </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</target>       </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> wyliczenia.</target>       </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">Wyrażenie wejściowych dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</target>       </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">Emuluje wprowadzania frazę do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy asynchroniczne i określa sposób obsługi przez aparat rozpoznawania Unicode porównanie frazę gramatyki rozpoznawania mowy załadowany.</target>       </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Aparat rozpoznawania używa <ph id="ph1">`compareOptions`</ph> po stosuje reguły gramatyki do frazy wejściowych.</target>       </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> lub <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> ma wartość.</target>       </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Aparatów rozpoznawania zawsze Ignoruj szerokość znaku i nigdy nie Ignoruj typu znaki Kana.</target>       </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</target>       </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> wyliczenia.</target>       </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>Occurs when the shared recognizer finalizes an asynchronous recognition operation for emulated input.</source>
          <target state="translated">Występuje, gdy udostępniony aparat rozpoznawania Kończenie znajdujących się w operacji asynchronicznych rozpoznawania emulowanej danych wejściowych.</target>       </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method begins an asynchronous recognition operation.</source>
          <target state="translated">Każdy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> metoda rozpoczyna operację asynchroniczną rozpoznawania.</target>       </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The recognizer raises the <ph id="ph1">`EmulateRecognizeCompleted`</ph> event when it finalizes the asynchronous operation.</source>
          <target state="translated">Generuje aparatu rozpoznawania <ph id="ph1">`EmulateRecognizeCompleted`</ph> zdarzenie, gdy jego Kończenie znajdujących się w operacji asynchronicznej.</target>       </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The asynchronous recognition operation can raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events.</source>
          <target state="translated">Wywołuje operację asynchroniczną rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> zdarzenia.</target>       </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event is the last such event that the recognizer raises for a given operation.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> Zdarzenie jest ostatni tych zdarzeń, że aparat rozpoznawania zgłasza dla danej operacji.</target>       </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>When you create a delegate for an <ph id="ph1">`EmulateRecognizeCompleted`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia obiektu delegowanego dla <ph id="ph1">`EmulateRecognizeCompleted`</ph> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Poniższy przykład jest częścią aplikacji konsoli, który ładuje gramatyki rozpoznawania mowy i przedstawia asynchroniczne emulowanej danych wejściowych, wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Jeśli rozpoznawania mowy nie jest uruchomiona, następnie uruchomienie tej aplikacji powoduje również uruchomienie rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> mode, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Jeśli rozpoznawanie mowy systemu Windows znajduje się w <bpt id="p1">**</bpt>uśpione<ept id="p1">**</ept> trybie, a następnie <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> zawsze zwraca wartość null.</target>       </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>Gets or sets a value that indicates whether this <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object is ready to process speech.</source>
          <target state="translated">Pobiera lub ustawia wartość wskazującą, czy to <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> obiekt jest gotowe do przetworzenia mowy.</target>       </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> if this <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object is performing speech recognition; otherwise, <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph> Jeśli <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> obiektu wykonuje rozpoznawanie mowy; w przeciwnym razie <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>Changes to this property do not affect other instances of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class.</source>
          <target state="translated">Zmiany w tej właściwości nie wpływają na inne wystąpienia <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> klasy.</target>       </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>By default, the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property is <ph id="ph2">`true`</ph> for a newly instantiated instance of <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>.</source>
          <target state="translated">Domyślnie wartość <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> właściwość jest <ph id="ph2">`true`</ph> dla nowo skonkretyzowanym wystąpienia <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>While the recognizer is disabled, none of the recognizer's speech recognition grammars are available for recognition operations.</source>
          <target state="translated">Gdy aparat rozpoznawania jest wyłączone, aparat rozpoznawania mowy rozpoznawania gramatyki nie jest dostępna żadna dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>Setting the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property has no effect on the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> property.</source>
          <target state="translated">Ustawienie aparatu rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> właściwość nie ma wpływu na aparat rozpoznawania <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>Gets a collection of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects that are loaded in this <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> instance.</source>
          <target state="translated">Pobiera kolekcję <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> obiektów, które są ładowane w tym <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> wystąpienia.</target>       </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>A collection of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects that the application loaded into the current instance of the shared recognizer.</source>
          <target state="translated">Kolekcja <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> obiektów, które aplikacji załadowane do bieżącego wystąpienia udostępniony aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>This property does not return any speech recognition grammars loaded by another application.</source>
          <target state="translated">Ta właściwość nie zwraca żadnych mowy gramatyki rozpoznawania załadowane przez inną aplikację.</target>       </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>The following example outputs information to the console for each speech recognition grammar loaded into the shared speech recognizer.</source>
          <target state="translated">Poniższy przykład danych wyjściowych informacji do konsoli dla każdego gramatyki rozpoznawania mowy ładowane do rozpoznawania mowy udostępnionego.</target>       </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">Rozpoznawanie mowy gramatyki do załadowania.</target>       </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>Loads a speech recognition grammar.</source>
          <target state="translated">Ładuje gramatyki rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The shared recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">Udostępniony aparat rozpoznawania zgłasza wyjątek, jeśli gramatyki rozpoznawania mowy jest już załadowany, jest ładowany asynchronicznie lub nie można załadować do dowolnego aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Jeśli aparat rozpoznawania jest uruchomiona, aplikacje muszą używać <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> wstrzymania aparat rozpoznawania mowy przed ładowania, zwalnianie, włączanie lub wyłączanie gramatyki.</target>       </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>To load a speech recognition grammar asynchronously, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Aby załadować gramatyki rozpoznawania mowy asynchronicznie, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Poniższy przykład jest częścią aplikacji konsoli, który ładuje gramatyki rozpoznawania mowy i przedstawia asynchroniczne emulowanej danych wejściowych, wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Jeśli rozpoznawania mowy nie jest uruchomiona, następnie uruchomienie tej aplikacji powoduje również uruchomienie rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Jeśli rozpoznawanie mowy systemu Windows znajduje się w <bpt id="p1">**</bpt>uśpione<ept id="p1">**</ept> stanu, następnie <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> zawsze zwraca wartość null.</target>       </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">Rozpoznawanie mowy gramatyki do załadowania.</target>       </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>Asynchronously loads a speech recognition grammar.</source>
          <target state="translated">Asynchronicznie ładuje gramatyki rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>When the recognizer completes this asynchronous operation, it raises a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> event.</source>
          <target state="translated">Po ukończeniu tej operacji asynchronicznej aparat rozpoznawania zgłasza <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">Aparat rozpoznawania zgłasza wyjątek, jeśli gramatyki rozpoznawania mowy jest już załadowany, jest ładowany asynchronicznie lub nie można załadować do dowolnego aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Jeśli aparat rozpoznawania jest uruchomiona, aplikacje muszą używać <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> wstrzymania aparat rozpoznawania mowy przed ładowania, zwalnianie, włączanie lub wyłączanie gramatyki.</target>       </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>To load a speech recognition grammar synchronously, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph> method.</source>
          <target state="translated">Aby załadować gramatyki rozpoznawania mowy synchronicznie, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>Occurs when the recognizer finishes the asynchronous loading of a speech recognition grammar.</source>
          <target state="translated">Występuje, gdy aparat rozpoznawania zakończy asynchroniczne ładowanie gramatyki rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> method initiates an asynchronous operation.</source>
          <target state="translated">Aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> metoda inicjuje operację asynchroniczną.</target>       </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The recognizer raises the <ph id="ph1">`LoadGrammarCompleted`</ph> event when it completes the operation.</source>
          <target state="translated">Generuje aparatu rozpoznawania <ph id="ph1">`LoadGrammarCompleted`</ph> zdarzeń po zakończeniu tej operacji.</target>       </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>To get the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object that the recognizer loaded, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;</ph> property of the associated <ph id="ph3">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ph>.</source>
          <target state="translated">Aby uzyskać <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekt, aby załadować aparat rozpoznawania, użyj <ph id="ph2">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;</ph> właściwości skojarzonego <ph id="ph3">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>To get the current <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects the recognizer has loaded, use the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph> property.</source>
          <target state="translated">Aby uzyskać bieżącą <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekty aparat rozpoznawania został załadowany, używają aparat rozpoznawania <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>When you create a delegate for a <ph id="ph1">`LoadGrammarCompleted`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia obiektu delegowanego dla <ph id="ph1">`LoadGrammarCompleted`</ph> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</source>
          <target state="translated">Poniższy przykład tworzy aparat rozpoznawania mowy udostępnionego, a następnie tworzy dwa typy gramatyki rozpoznawania słów i akceptowania dyktowania wolne.</target>       </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The example asynchronously loads all the created grammars to the recognizer.</source>
          <target state="translated">Przykład asynchronicznie ładuje wszystkie utworzone gramatyki do aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>Handlers for the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events write to the console the name of the grammar that was used to perform the recognition and the text of the recognition result, respectively.</source>
          <target state="translated">Programy obsługi dla aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> zdarzenia zapisu do konsoli nazwę gramatyki, która została użyta do wykonania odpowiednio uznania i tekst wyniku rozpoznawania.</target>       </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>Gets or sets the maximum number of alternate recognition results that the shared recognizer returns for each recognition operation.</source>
          <target state="translated">Pobiera lub ustawia maksymalną liczbę wyników rozpoznawania alternatywny, które zwraca udostępniony aparat rozpoznawania dla każdej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>The maximum number of alternate results that the speech recognizer returns for each recognition operation.</source>
          <target state="translated">Maksymalna liczba wyników alternatywny, które zwraca rozpoznawania mowy dla każdej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> class contains the collection of <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> objects that represent other candidate interpretations of the input.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> Właściwość <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> klasy zawiera kolekcję <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> obiekty reprezentujące interpretacji candidate innych danych wejściowych.</target>       </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>The default value for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> is 10.</source>
          <target state="translated">Wartość domyślna dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> wynosi 10.</target>       </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Gets or sets a value that indicates whether the shared recognizer pauses recognition operations while an application is handling a <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> event.</source>
          <target state="translated">Pobiera lub ustawia wartość wskazującą, czy udostępniony aparat rozpoznawania wstrzymuje operacji rozpoznawania, podczas gdy aplikacja jest obsługa <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> if the shared recognizer waits to process input while any application is handling the <ph id="ph2">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> event; otherwise, <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph> Jeśli udostępniony aparat rozpoznawania czeka można przetworzyć danych wejściowych, gdy obsługuje dowolnej aplikacji <ph id="ph2">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> zdarzeń; w przeciwnym razie <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Set this property to <ph id="ph1">`true`</ph>, if within the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler your application needs to change the state of the speech recognition service or change the loaded or enabled speech recognition grammars before the speech recognition service processes more input.</source>
          <target state="translated">Ta właściwość jest ustawiana <ph id="ph1">`true`</ph>, jeśli w ramach <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> obsługi zdarzeń, aplikacja musi zmienić stan usługi rozpoznawania mowy lub gramatyki rozpoznawania mowy załadowany lub włączone przed uruchomieniem usługi rozpoznawania mowy procesy więcej danych wejściowych.</target>       </trans-unit>
        <trans-unit id="298" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Setting the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> property to <ph id="ph2">`true`</ph> causes each <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler in every application to block the Windows speech recognition service.</source>
          <target state="translated">Ustawienie <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> właściwości <ph id="ph2">`true`</ph> powoduje, że każdy <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> obsługi zdarzeń w każdej aplikacji, aby zablokować usługa rozpoznawania mowy systemu Windows.</target>       </trans-unit>
        <trans-unit id="299" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>To synchronize the changes to the shared recognizer with your application state, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Aby zsynchronizować zmiany z udostępniony aparat rozpoznawania ze stanem aplikacji, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="300" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>When <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> is <ph id="ph2">`true`</ph>, during the execution of the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> handler the speech recognition service pauses and buffers new audio input as it arrives.</source>
          <target state="translated">Gdy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> jest <ph id="ph2">`true`</ph>, podczas wykonywania <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> obsługi usługi rozpoznawania mowy wstrzymuje i buforuje nowe wejście audio odbieraną.</target>       </trans-unit>
        <trans-unit id="301" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Once the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler exits, the speech recognition service resumes recognition and starts processing information from its input buffer.</source>
          <target state="translated">Raz <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> obsługi zdarzeń opuszcza rozpoznawania wznawia usługi rozpoznawania mowy i rozpoczyna przetwarzanie informacji z jego buforu wejściowego.</target>       </trans-unit>
        <trans-unit id="302" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>To enable or disable the speech recognition service, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property.</source>
          <target state="translated">Aby włączyć lub wyłączyć usługę rozpoznawania mowy, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="303" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>Gets the current location of the recognizer in the audio input that it is processing.</source>
          <target state="translated">Pobiera bieżącą lokalizację aparatu rozpoznawania w wejściowych danych audio, który przetwarzania.</target>       </trans-unit>
        <trans-unit id="304" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>The position of the recognizer in the audio input that it is processing.</source>
          <target state="translated">Pozycja rozpoznawania w wejściowych danych audio, który przetwarzania.</target>       </trans-unit>
        <trans-unit id="305" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>The <ph id="ph1">`RecognizerAudioPosition`</ph> property references the recognizer's position in processing its audio input.</source>
          <target state="translated"><ph id="ph1">`RecognizerAudioPosition`</ph> Właściwość odwołuje się do pozycji aparat rozpoznawania podczas przetwarzania jego wejście audio.</target>       </trans-unit>
        <trans-unit id="306" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property references the input device's position in its generated audio stream.</source>
          <target state="translated">Z kolei <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> właściwość odwołuje się do pozycji urządzenia wejściowego w jego wygenerowanego strumieniem audio.</target>       </trans-unit>
        <trans-unit id="307" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>These positions can be different.</source>
          <target state="translated">Te pozycje mogą być różne.</target>       </trans-unit>
        <trans-unit id="308" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property.</source>
          <target state="translated">Na przykład jeśli aparat rozpoznawania otrzymał wejściowych, do których nie ma jeszcze generowane w wyniku rozpoznawania, a następnie wartość <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> właściwości jest mniejsza niż wartość <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="309" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>Gets information about the shared speech recognizer.</source>
          <target state="translated">Pobiera informacje o rozpoznawania mowy udostępnionego.</target>       </trans-unit>
        <trans-unit id="310" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>Information about the shared speech recognizer.</source>
          <target state="translated">Informacje dotyczące aparatu rozpoznawania mowy udostępnionego.</target>       </trans-unit>
        <trans-unit id="311" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>This property returns information about the speech recognizer in use by Windows Speech Recognition.</source>
          <target state="translated">Ta właściwość zwraca informacje dotyczące aparatu rozpoznawania mowy używany przez rozpoznawanie mowy w systemie Windows.</target>       </trans-unit>
        <trans-unit id="312" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>The following example sends information about the shared recognizer to the console.</source>
          <target state="translated">Poniższy przykład wysyła informacje o udostępniony aparat rozpoznawania do konsoli.</target>       </trans-unit>
        <trans-unit id="313" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>Occurs when the recognizer pauses to synchronize recognition and other operations.</source>
          <target state="translated">Występuje, gdy aparat rozpoznawania wstrzymuje zsynchronizować rozpoznawania i innych operacji.</target>       </trans-unit>
        <trans-unit id="314" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>Applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause a running instance of <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> before modifying its <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Aplikacje muszą używać <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> wstrzymania działającego wystąpienia <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> przed zmodyfikowaniem jego <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="315" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>For example, while the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> is paused, you can load, unload, enable, and disable <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Na przykład <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> jest wstrzymana, możesz można załadować, zwolnienie, włączania i wyłączania <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="316" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> raises this event when it is ready to accept modifications.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> Zgłasza to zdarzenie, gdy będzie gotowy do akceptowania modyfikacje.</target>       </trans-unit>
        <trans-unit id="317" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia obiektu delegowanego dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="318" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="319" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="320" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="321" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The following example shows a console application that loads and unloads <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">W poniższym przykładzie przedstawiono aplikacji konsoli, który ładuje i zwalnia <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="322" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The application uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method to request the speech recognition engine to pause so it can receive an update.</source>
          <target state="translated">Aplikacja używa <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> metoda żądania wstrzymania, więc może ona odbierać aktualizacji aparatu rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="323" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The application then loads or unloads a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">Aplikacja, a następnie ładuje lub zwalnia <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="324" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>At each update, a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event writes the name and status of the currently loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the console.</source>
          <target state="translated">W każdej aktualizacji obsługi dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> zapisuje zdarzenia, nazwy i stan aktualnie załadowanych <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekty do konsoli.</target>       </trans-unit>
        <trans-unit id="325" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</source>
          <target state="translated">Jak gramatyki jest załadowany i zwolniony, najpierw rozpoznaje nazwy farmy zwierząt, nazwy farmy zwierząt oraz nazwy owoców, a następnie tylko nazwy owoców.</target>       </trans-unit>
        <trans-unit id="326" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Requests that the shared recognizer pause and update its state.</source>
          <target state="translated">Żądania, że udostępniony aparat rozpoznawania wstrzymać i zaktualizuj jego stan.</target>       </trans-unit>
        <trans-unit id="327" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Use this method to synchronize changes to the shared recognizer.</source>
          <target state="translated">Użyj tej metody, aby zsynchronizować zmiany udostępniony aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="328" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>For example, if you load or unload a speech recognition grammar while the recognizer is processing input, use this method and the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event to synchronize your application behavior with the state of the recognizer.</source>
          <target state="translated">Na przykład, jeśli załadować lub zwolnić gramatyki rozpoznawania mowy, gdy aparat rozpoznawania jest przetwarzania danych wejściowych, ta metoda i <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> zdarzenie, aby zsynchronizować Twoje zachowanie aplikacji z stanem aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="329" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>When this method is called, the recognizer pauses or completes asynchronous operations and generates a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Gdy ta metoda jest wywoływana, aparat rozpoznawania wstrzymuje lub zakończeniu operacji asynchronicznych i generuje <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="330" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>A <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event handler can then modify the state of the recognizer in between recognition operations.</source>
          <target state="translated">A <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> obsługi zdarzeń można zmodyfikować stanu rozpoznawania Between operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="331" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>When this method is called:</source>
          <target state="translated">Gdy ta metoda jest wywoływana:</target>       </trans-unit>
        <trans-unit id="332" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the recognizer is not processing input, the recognizer immediately generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Jeśli aparat rozpoznawania nie przetwarza danych wejściowych, aparat rozpoznawania natychmiast generuje <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="333" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the recognizer is processing input that consists of silence or background noise, the recognizer pauses the recognition operation and generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Jeśli aparat rozpoznawania jest przetwarzania danych wejściowych, który składa się z wyciszenia lub hałas w tle, aparat rozpoznawania wstrzymuje działanie rozpoznawania i generuje <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="334" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the recognizer is processing input that does not consist of silence or background noise, the recognizer completes the recognition operation and then generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Jeśli aparat rozpoznawania jest przetwarzania danych wejściowych, która składa się z wyciszenia lub hałas w tle, aparat rozpoznawania zakończeniu operacji rozpoznawania, a następnie generuje <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="335" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>While the recognizer is handling the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event:</source>
          <target state="translated">Gdy aparat rozpoznawania jest obsługa <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> zdarzeń:</target>       </trans-unit>
        <trans-unit id="336" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer does not process input, and the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property remains the same.</source>
          <target state="translated">Aparat rozpoznawania nie przetwarza danych wejściowych, a wartość <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> właściwości jest taka sama.</target>       </trans-unit>
        <trans-unit id="337" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer continues to collect input, and the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property can change.</source>
          <target state="translated">Aparat rozpoznawania kontynuuje zbieranie danych wejściowych i wartość <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> można zmienić właściwości.</target>       </trans-unit>
        <trans-unit id="338" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To change whether the shared recognizer pauses recognition operations while an application is handling a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> property.</source>
          <target state="translated">Aby określić, czy udostępniony aparat rozpoznawania wstrzymuje operacji rozpoznawania, podczas gdy aplikacja jest obsługa <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> zdarzenia, użyj <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="339" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The following example shows a console application that loads and unloads <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">W poniższym przykładzie przedstawiono aplikacji konsoli, który ładuje i zwalnia <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="340" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The application uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method to request the speech recognition engine to pause so it can receive an update.</source>
          <target state="translated">Aplikacja używa <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> metoda żądania wstrzymania, więc może ona odbierać aktualizacji aparatu rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="341" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The application then loads or unloads a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">Aplikacja, a następnie ładuje lub zwalnia <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="342" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>At each update, a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event writes the name and status of the currently loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the console.</source>
          <target state="translated">W każdej aktualizacji obsługi dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> zapisuje zdarzenia, nazwy i stan aktualnie załadowanych <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekty do konsoli.</target>       </trans-unit>
        <trans-unit id="343" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</source>
          <target state="translated">Jak gramatyki jest załadowany i zwolniony, najpierw rozpoznaje nazwy farmy zwierząt, nazwy farmy zwierząt oraz nazwy owoców, a następnie tylko nazwy owoców.</target>       </trans-unit>
        <trans-unit id="344" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>Requests that the shared recognizer pause and update its state.</source>
          <target state="translated">Żądania, że udostępniony aparat rozpoznawania wstrzymać i zaktualizuj jego stan.</target>       </trans-unit>
        <trans-unit id="345" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> is <ph id="ph4">`null`</ph>.</source>
          <target state="translated">Gdy aparat rozpoznawania generuje <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> zdarzenia <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> właściwość <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> jest <ph id="ph4">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="346" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>To provide a user token, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Aby dostarczyć token użytkownika, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="347" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Aby określić przesunięcie pozycji audio, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="348" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">Informacje zdefiniowane przez użytkownika, zawierający informacje dla tej operacji.</target>       </trans-unit>
        <trans-unit id="349" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>Requests that the shared recognizer pause and update its state and provides a user token for the associated event.</source>
          <target state="translated">Udostępniony aparat rozpoznawania wstrzymać i zaktualizuj jego stan i zapewnia token użytkownika skojarzonego zdarzenia, żądania.</target>       </trans-unit>
        <trans-unit id="350" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
          <target state="translated">Gdy aparat rozpoznawania generuje <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> zdarzenia <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> właściwość <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> zawiera wartość <ph id="ph4">`userToken`</ph> parametru.</target>       </trans-unit>
        <trans-unit id="351" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Aby określić przesunięcie pozycji audio, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="352" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">Informacje zdefiniowane przez użytkownika, zawierający informacje dla tej operacji.</target>       </trans-unit>
        <trans-unit id="353" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>The offset from the current <ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /&gt;</ph> to delay the request.</source>
          <target state="translated">Przesunięcie od bieżącej <ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /&gt;</ph> opóźnienia żądania.</target>       </trans-unit>
        <trans-unit id="354" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>Requests that the shared recognizer pause and update its state and provides an offset and a user token for the associated event.</source>
          <target state="translated">Udostępniony aparat rozpoznawania wstrzymać i zaktualizuj jego stan i zapewnia przesunięcia i token użytkownika skojarzonego zdarzenia, żądania.</target>       </trans-unit>
        <trans-unit id="355" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>The recognizer does not initiate the recognizer update request until the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> equals the current <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> plus the value of the <ph id="ph3">`audioPositionAheadToRaiseUpdate`</ph> parameter.</source>
          <target state="translated">Aparat rozpoznawania nie zainicjował żądanie aktualizacji aparatu rozpoznawania do aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> jest równe bieżącego <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> plus wartość <ph id="ph3">`audioPositionAheadToRaiseUpdate`</ph> parametru.</target>       </trans-unit>
        <trans-unit id="356" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
          <target state="translated">Gdy aparat rozpoznawania generuje <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> zdarzenia <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> właściwość <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> zawiera wartość <ph id="ph4">`userToken`</ph> parametru.</target>       </trans-unit>
        <trans-unit id="357" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>Occurs when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Występuje, gdy aparat rozpoznawania wykrywa danych wejściowych, którą można zidentyfikować jako mowy.</target>       </trans-unit>
        <trans-unit id="358" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The shared recognizer can raise this event in response to input.</source>
          <target state="translated">Udostępniony aparat rozpoznawania może wiązać się z tym zdarzeniem w odpowiedzi jako danych wejściowych.</target>       </trans-unit>
        <trans-unit id="359" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> object indicates location in the input stream where the recognizer detected speech.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</ph> Właściwości skojarzonego <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> obiektu wskazuje lokalizację, w przypadku wykrycia przez aparat rozpoznawania mowy strumień wejściowy.</target>       </trans-unit>
        <trans-unit id="360" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>For more information see the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> properties and the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Aby uzyskać więcej informacji, zobacz <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> właściwości i <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="361" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia obiektu delegowanego dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="362" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="363" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="364" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="365" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The following example is part of a console application for choosing origin and destination cities for a flight.</source>
          <target state="translated">Poniższy przykład jest częścią aplikacji konsoli dotyczące wybierania miast źródło i miejsce docelowe w locie.</target>       </trans-unit>
        <trans-unit id="366" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The application recognizes phrases such as "I want to fly from Miami to Chicago."</source>
          <target state="translated">Aplikacja rozpoznaje fraz, takie jak "Chcę udać z Miami do Chicago."</target>       </trans-unit>
        <trans-unit id="367" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The example uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event to report the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> each time speech is detected.</source>
          <target state="translated">W przykładzie użyto <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> zdarzeń do raportu <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> każdego mowy czas wykrycia.</target>       </trans-unit>
        <trans-unit id="368" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>Occurs when the recognizer has recognized a word or words that may be a component of multiple complete phrases in a grammar.</source>
          <target state="translated">Występuje, gdy aparat rozpoznawania rozpoznał wyrazów, które mogą być składnika wiele wyrażeń pełną w gramatyce.</target>       </trans-unit>
        <trans-unit id="369" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The shared recognizer can raise this event when the input is ambiguous.</source>
          <target state="translated">Udostępniony aparat rozpoznawania można Zgłoś to zdarzenie, gdy dane wejściowe są niejednoznaczne.</target>       </trans-unit>
        <trans-unit id="370" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</source>
          <target state="translated">Na przykład dla gramatyki rozpoznawania mowy, która obsługuje rozpoznawanie albo "nowe gier, skontaktuj" lub "nowej gry", "nowe gier, skontaktuj" jest wejściem jednoznaczne i "nowej gry" jest niejednoznaczny danych wejściowych.</target>       </trans-unit>
        <trans-unit id="371" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia obiektu delegowanego dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="372" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="373" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="374" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="375" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category".</source>
          <target state="translated">Poniższy przykład rozpoznaje fraz, takie jak "Wyświetlana lista artystów w kategorii jazz".</target>       </trans-unit>
        <trans-unit id="376" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The example uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> event to display incomplete phrase fragments in the console as they are recognized.</source>
          <target state="translated">W przykładzie użyto <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> zdarzeń, aby wyświetlić fragmenty niepełne wyrażenie w konsoli, jak są rozpoznawane.</target>       </trans-unit>
        <trans-unit id="377" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>Occurs when the recognizer receives input that does not match any of the speech recognition grammars it has loaded.</source>
          <target state="translated">Występuje, gdy aparat rozpoznawania otrzymuje dane wejściowe, który nie pasuje do żadnego gramatyki rozpoznawania mowy, który ma on załadowany.</target>       </trans-unit>
        <trans-unit id="378" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The shared recognizer raises this event if it determines that input does not match with sufficient confidence any of the loaded speech recognition grammars.</source>
          <target state="translated">Udostępniony aparat rozpoznawania zgłasza to zdarzenie, gdy ustali, że dane wejściowe nie jest zgodna z wystarczający poziom zaufania żadnego gramatyki rozpoznawania mowy załadować.</target>       </trans-unit>
        <trans-unit id="379" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the rejected <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> Właściwość <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> zawiera odrzucone <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="380" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>Confidence thresholds for the shared recognizer, managed by <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, are associated with a user profile and stored in the Windows registry.</source>
          <target state="translated">Progi zaufania udostępniony aparat rozpoznawania zarządza <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, są skojarzone z profilem użytkownika i przechowywane w rejestrze systemu Windows.</target>       </trans-unit>
        <trans-unit id="381" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>Applications should not write changes to the registry for the properties of the shared recognizer.</source>
          <target state="translated">Aplikacje nie należy zapisać zmiany w rejestrze dla właściwości udostępniony aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="382" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia obiektu delegowanego dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="383" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="384" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="385" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="386" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category" or "Display albums gospel".</source>
          <target state="translated">Poniższy przykład rozpoznaje "wyrażenia takie jak wyświetlać listę artystów w kategorii jazz" lub "gospel albumów".</target>       </trans-unit>
        <trans-unit id="387" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient confidence to produce a successful recognition.</source>
          <target state="translated">W przykładzie użyto obsługi dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> zdarzeń, aby wyświetlić powiadomienie w konsoli podczas wprowadzania mowy nie można dopasować do zawartości gramatyki wystarczający poziom zaufania, aby wygenerować pomyślne rozpoznawanie.</target>       </trans-unit>
        <trans-unit id="388" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Occurs when the recognizer receives input that matches one of its speech recognition grammars.</source>
          <target state="translated">Występuje, gdy aparat rozpoznawania otrzymuje dane wejściowe, który pasuje do jednej z jego gramatyki rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="389" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The recognizer raises the <ph id="ph1">`SpeechRecognized`</ph> event if it determines with sufficient confidence that input matches one of the loaded and enabled speech recognition grammars.</source>
          <target state="translated">Generuje aparatu rozpoznawania <ph id="ph1">`SpeechRecognized`</ph> zdarzeń, gdy ustali bez obaw wystarczające, czy dane wejściowe pasujący gramatyki rozpoznawania mowy załadowany i włączona.</target>       </trans-unit>
        <trans-unit id="390" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the accepted <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> Właściwość <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> zawiera zaakceptowane <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="391" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Confidence thresholds for the shared recognizer, managed by <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, are associated with a user profile and stored in the Windows registry.</source>
          <target state="translated">Progi zaufania udostępniony aparat rozpoznawania zarządza <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, są skojarzone z profilem użytkownika i przechowywane w rejestrze systemu Windows.</target>       </trans-unit>
        <trans-unit id="392" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Applications should not write changes to the registry for the properties of the shared recognizer.</source>
          <target state="translated">Aplikacje nie należy zapisać zmiany w rejestrze dla właściwości udostępniony aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="393" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>When the recognizer receives input that matches a grammar, the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object can raise the <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Gdy aparat rozpoznawania otrzymuje wejścia odpowiadającego gramatyki, <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> może wiązać się z obiektu <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="394" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object's <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event is raised prior to the speech recognizer's <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> Obiektu <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> zdarzenie jest wywoływane przed rozpoznawania mowy <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="395" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia obiektu delegowanego dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="396" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="397" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="398" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="399" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates speech input to the shared recognizer, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Poniższy przykład jest częścią aplikacji konsoli, który ładuje gramatyki rozpoznawania mowy i pokazuje wejście mowy udostępniony aparat rozpoznawania wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="400" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Jeśli rozpoznawania mowy nie jest uruchomiona, następnie uruchomienie tej aplikacji powoduje również uruchomienie rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="401" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Spoken input such as "I want to fly from Chicago to Miami" will trigger a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Używany danych wejściowych, takie jak "Chcę udać z Chicago do Miami" wyzwoli <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="402" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Speaking the phrase "Fly me from Houston to Chicago " will not trigger a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Mówiąc frazę "Udać me z Houston do Chicago" nie powoduje wyzwolenia <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="403" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event to display successfully recognized phrases and the semantics they contain in the console.</source>
          <target state="translated">W przykładzie użyto obsługi dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> zdarzeń do wyświetlenia pomyślnie rozpoznane fraz i semantyki zawierają w konsoli.</target>       </trans-unit>
        <trans-unit id="404" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>Gets the state of a <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Pobiera stan <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="405" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>The state of the <ph id="ph1">&lt;see langword="SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Stan <ph id="ph1">&lt;see langword="SpeechRecognizer" /&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="406" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>This read-only property indicates whether the shared recognizer resident in Windows is in the <ph id="ph1">`Stopped`</ph> or the <ph id="ph2">`Listening`</ph> state.</source>
          <target state="translated">Ta właściwość tylko do odczytu wskazuje, czy udostępniony aparat rozpoznawania znajdują się w systemie Windows jest <ph id="ph1">`Stopped`</ph> lub <ph id="ph2">`Listening`</ph> stanu.</target>       </trans-unit>
        <trans-unit id="407" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>For more information, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState&gt;</ph> enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji, zobacz <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState&gt;</ph> wyliczenia.</target>       </trans-unit>
        <trans-unit id="408" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>Occurs when the running state of the Windows Desktop Speech Technology recognition engine changes.</source>
          <target state="translated">Występuje, gdy stan działania aparatu rozpoznawania technologia mowy pulpitu systemu Windows.</target>       </trans-unit>
        <trans-unit id="409" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The shared recognizer raises this event when the state of Windows Speech Recognition changes to the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState.Listening&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerState.Stopped&gt;</ph> state.</source>
          <target state="translated">Udostępniony aparat rozpoznawania zgłasza to zdarzenie po zmianie stanu rozpoznawania mowy systemu Windows do <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState.Listening&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerState.Stopped&gt;</ph> stanu.</target>       </trans-unit>
        <trans-unit id="410" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>To get the state of the shared recognizer at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;</ph>.</source>
          <target state="translated">Aby pobrać stan udostępniony aparat rozpoznawania w czasie zdarzenia, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;</ph> właściwości skojarzonego <ph id="ph2">&lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="411" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>To get the current state of the shared recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> property.</source>
          <target state="translated">Aby uzyskać bieżący stan udostępniony aparat rozpoznawania, należy użyć aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="412" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia obiektu delegowanego dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="413" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="414" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="415" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="416" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</source>
          <target state="translated">Poniższy przykład tworzy aparat rozpoznawania mowy udostępnionego, a następnie tworzy dwa typy gramatyki rozpoznawania słów i akceptowania dyktowania wolne.</target>       </trans-unit>
        <trans-unit id="417" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The example asynchronously loads all the created grammars to the recognizer.</source>
          <target state="translated">Przykład asynchronicznie ładuje wszystkie utworzone gramatyki do aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="418" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> event uses the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method to put Windows Recognition in "listening" mode.</source>
          <target state="translated">Program obsługi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> używa zdarzeń <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> metodę put rozpoznawanie systemu Windows w trybie "nasłuchiwania".</target>       </trans-unit>
        <trans-unit id="419" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars">
          <source>Unloads all speech recognition grammars from the shared recognizer.</source>
          <target state="translated">Zwalnia wszystkich gramatykach rozpoznawanie mowy z udostępniony aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="420" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars">
          <source>If the recognizer is currently loading a grammar asynchronously, this method waits until the grammar is loaded, before it unloads all of the recognizer's grammars.</source>
          <target state="translated">Aparat rozpoznawania jest obecnie asynchronicznie ładowania gramatyki, ta metoda oczekuje, aż gramatyki jest załadowane przed zwalnia wszystkie gramatyki aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="421" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars">
          <source>To unload a specific grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph> method.</source>
          <target state="translated">Aby zwolnić określonego gramatyki, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="422" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>The grammar to unload.</source>
          <target state="translated">Gramatyka do zwolnienia.</target>       </trans-unit>
        <trans-unit id="423" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>Unloads a specified speech recognition grammar from the shared recognizer.</source>
          <target state="translated">Zwalnia gramatyki rozpoznawania mowy określonego z udostępniony aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="424" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Jeśli aparat rozpoznawania jest uruchomiona, aplikacje muszą używać <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> wstrzymania aparat rozpoznawania mowy przed ładowania, zwalnianie, włączanie lub wyłączanie gramatyki.</target>       </trans-unit>
        <trans-unit id="425" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>To unload all grammars, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph> method.</source>
          <target state="translated">Aby zwolnić wszystkich gramatykach, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph> metody.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>