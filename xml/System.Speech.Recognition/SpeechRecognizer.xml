<Type Name="SpeechRecognizer" FullName="System.Speech.Recognition.SpeechRecognizer">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="bc77257cd77c3fc2c078698df4cc6e968d3bf09a" />
    <Meta Name="ms.sourcegitcommit" Value="d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b" />
    <Meta Name="ms.translationtype" Value="MT" />
    <Meta Name="ms.contentlocale" Value="pl-PL" />
    <Meta Name="ms.lasthandoff" Value="04/03/2018" />
    <Meta Name="ms.locfileid" Value="30579907" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class SpeechRecognizer : IDisposable" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit SpeechRecognizer extends System.Object implements class System.IDisposable" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.SpeechRecognizer" />
  <TypeSignature Language="VB.NET" Value="Public Class SpeechRecognizer&#xA;Implements IDisposable" />
  <TypeSignature Language="C++ CLI" Value="public ref class SpeechRecognizer : IDisposable" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces>
    <Interface>
      <InterfaceName>System.IDisposable</InterfaceName>
    </Interface>
  </Interfaces>
  <Docs>
    <summary>
      <span data-ttu-id="4988b-101">Zapewnia dostęp do usługi rozpoznawania mowy udostępnionego dostępne na pulpicie systemu Windows.</span>
      <span class="sxs-lookup">
        <span data-stu-id="4988b-101">Provides access to the shared speech recognition service available on the Windows desktop.</span>
      </span>
    </summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-102">Aplikacje umożliwia dostęp do rozpoznawania mowy udostępniony aparat rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-102">Applications use the shared recognizer to access Windows Speech Recognition.</span></span> <span data-ttu-id="4988b-103">Użyj <xref:System.Speech.Recognition.SpeechRecognizer> obiekt do dodania do środowisko użytkownika systemu Windows mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-103">Use the <xref:System.Speech.Recognition.SpeechRecognizer> object to add to the Windows speech user experience.</span></span>  
  
 <span data-ttu-id="4988b-104">Ta klasa umożliwia sterowanie różnych aspektów procesu rozpoznawania mowy:</span><span class="sxs-lookup"><span data-stu-id="4988b-104">This class provides control over various aspects of the speech recognition process:</span></span>  
  
-   <span data-ttu-id="4988b-105">Aby zarządzać gramatyki rozpoznawania mowy, należy użyć <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>, i <xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>.</span><span class="sxs-lookup"><span data-stu-id="4988b-105">To manage speech recognition grammars, use the <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>, and <xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>.</span></span>  
  
-   <span data-ttu-id="4988b-106">Aby uzyskać informacje o bieżącym mowy operacji rozpoznawania, subskrybować <xref:System.Speech.Recognition.SpeechRecognizer>w <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, i <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> zdarzenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-106">To get information about current speech recognition operations, subscribe to the <xref:System.Speech.Recognition.SpeechRecognizer>’s <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> events.</span></span>  
  
-   <span data-ttu-id="4988b-107">Aby wyświetlić lub zmodyfikować liczbę wyników alternatywnych zwraca aparat rozpoznawania, użyj <xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A> właściwości.</span><span class="sxs-lookup"><span data-stu-id="4988b-107">To view or modify the number of alternate results the recognizer returns, use the <xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A> property.</span></span> <span data-ttu-id="4988b-108">Aparat rozpoznawania zwraca wyniki rozpoznawania w <xref:System.Speech.Recognition.RecognitionResult> obiektu.</span><span class="sxs-lookup"><span data-stu-id="4988b-108">The recognizer returns recognition results in a <xref:System.Speech.Recognition.RecognitionResult> object.</span></span>  
  
-   <span data-ttu-id="4988b-109">Aby uzyskać dostęp, lub monitorować stan udostępniony aparat rozpoznawania, użyj <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>, i <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> właściwości i <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged>, i <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> zdarzenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-109">To access or monitor the state of the shared recognizer, use the <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>, and <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> properties and the <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged>, and <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> events.</span></span>  
  
-   <span data-ttu-id="4988b-110">Aby zsynchronizować zmiany aparat rozpoznawania, użyj <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> metody.</span><span class="sxs-lookup"><span data-stu-id="4988b-110">To synchronize changes to the recognizer, use the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method.</span></span> <span data-ttu-id="4988b-111">Udostępniony aparat rozpoznawania używa więcej niż jeden wątek, do wykonywania zadań.</span><span class="sxs-lookup"><span data-stu-id="4988b-111">The shared recognizer uses more than one thread to perform tasks.</span></span>  
  
-   <span data-ttu-id="4988b-112">Aby emulować dane wejściowe udostępniony aparat rozpoznawania, użyj <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> i <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> metody.</span><span class="sxs-lookup"><span data-stu-id="4988b-112">To emulate input to the shared recognizer, use the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> and <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> methods.</span></span>  
  
 <span data-ttu-id="4988b-113">Konfiguracja rozpoznawanie mowy systemu Windows odbywa się przy użyciu **właściwości mowy** okno dialogowe w **Panelu sterowania**.</span><span class="sxs-lookup"><span data-stu-id="4988b-113">The configuration of Windows Speech Recognition is managed by the use of the **Speech Properties** dialog in the **Control Panel**.</span></span> <span data-ttu-id="4988b-114">Ten interfejs jest używany, aby wybrać domyślny aparat rozpoznawania mowy pulpitu i języka, urządzenia wejściowego audio i zachowanie uśpienia rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-114">This interface is used to select the default desktop speech recognition engine and language, the audio input device, and the sleep behavior of speech recognition.</span></span> <span data-ttu-id="4988b-115">Po zmianie konfiguracji rozpoznawanie mowy systemu Windows po uruchomieniu aplikacji (na przykład rozpoznawanie mowy jest wyłączona lub zmianie języka wprowadzania), zmiana wpływa na wszystkie <xref:System.Speech.Recognition.SpeechRecognizer> obiektów.</span><span class="sxs-lookup"><span data-stu-id="4988b-115">If the configuration of Windows Speech Recognition is changed while the application is running, (for instance, if speech recognition is disabled or the input language is changed), the change affects all <xref:System.Speech.Recognition.SpeechRecognizer> objects.</span></span>  
  
 <span data-ttu-id="4988b-116">Aby utworzyć rozpoznawania mowy w procesie, która jest niezależna od rozpoznawanie mowy w systemie Windows, należy użyć <xref:System.Speech.Recognition.SpeechRecognitionEngine> klasy.</span><span class="sxs-lookup"><span data-stu-id="4988b-116">To create an in-process speech recognizer that is independent of Windows Speech Recognition, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine> class.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="4988b-117">Wywoływanie zawsze <xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A> przed zwolnieniem ostatniego odwołania do rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-117">Always call <xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A> before you release your last reference to the speech recognizer.</span></span> <span data-ttu-id="4988b-118">W przeciwnym razie używa zasobów nie zostanie zwolniona, dopóki moduł garbage collector wywołuje obiekt aparatu rozpoznawania `Finalize` metody.</span><span class="sxs-lookup"><span data-stu-id="4988b-118">Otherwise, the resources it is using will not be freed until the garbage collector calls the recognizer object's `Finalize` method.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-119">Poniższy przykład jest częścią aplikacji konsoli, który ładuje gramatyki rozpoznawania mowy i przedstawia asynchroniczne emulowanej danych wejściowych, wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-119">The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</span></span>  <span data-ttu-id="4988b-120">Jeśli rozpoznawania mowy nie jest uruchomiona, następnie uruchomienie tej aplikacji powoduje również uruchomienie rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-120">If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</span></span> <span data-ttu-id="4988b-121">Jeśli rozpoznawanie mowy systemu Windows znajduje się w **uśpione** stanu, następnie <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> zawsze zwraca wartość null.</span><span class="sxs-lookup"><span data-stu-id="4988b-121">If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.   
        // This matches the grammar and generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.  
        // This does not match the grammar or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the SpeechRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
    <altmember cref="T:System.Speech.Recognition.Grammar" />
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SpeechRecognizer();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>
          <span data-ttu-id="4988b-122">Inicjuje nowe wystąpienie klasy <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> klasy.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-122">Initializes a new instance of the <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> class.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-123">Każdy <xref:System.Speech.Recognition.SpeechRecognizer> obiekt przechowuje osobny zestaw gramatyki rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-123">Each <xref:System.Speech.Recognition.SpeechRecognizer> object maintains a separate set of speech recognition grammars.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-124">Poniższy przykład jest częścią aplikacji konsoli, który ładuje gramatyki rozpoznawania mowy i przedstawia asynchroniczne emulowanej danych wejściowych, wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-124">The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</span></span> <span data-ttu-id="4988b-125">Jeśli rozpoznawania mowy nie jest uruchomiona, następnie uruchomienie tej aplikacji powoduje również uruchomienie rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-125">If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</span></span> <span data-ttu-id="4988b-126">Jeśli rozpoznawanie mowy systemu Windows znajduje się w **uśpione** stanu, następnie <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> zawsze zwraca wartość null.</span><span class="sxs-lookup"><span data-stu-id="4988b-126">If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.   
        // This matches the grammar and generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.  
        // This does not match the grammar or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the SpeechRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.Grammar" />
      </Docs>
    </Member>
    <Member MemberName="AudioFormat">
      <MemberSignature Language="C#" Value="public System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioFormat As SpeechAudioFormatInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::AudioFormat::SpeechAudioFormatInfo ^ AudioFormat { System::Speech::AudioFormat::SpeechAudioFormatInfo ^ get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.AudioFormat.SpeechAudioFormatInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-127">Pobiera format audio odbierane przez aparat rozpoznawania mowy.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-127">Gets the format of the audio being received by the speech recognizer.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="4988b-128">Format wejściowy audio rozpoznawania mowy lub <see langword="null" /> Jeśli dane wejściowe aparat rozpoznawania nie jest skonfigurowany.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-128">The audio input format for the speech recognizer, or <see langword="null" /> if the input to the recognizer is not configured.</span>
          </span>
        </value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AudioLevel">
      <MemberSignature Language="C#" Value="public int AudioLevel { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 AudioLevel" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioLevel As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int AudioLevel { int get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-129">Pobiera poziom dźwięku odbierane przez aparat rozpoznawania mowy.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-129">Gets the level of the audio being received by the speech recognizer.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="4988b-130">Poziom audio w danych wejściowych rozpoznawania mowy od 0 do 100.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-130">The audio level of the input to the speech recognizer, from 0 through 100.</span>
          </span>
        </value>
        <remarks>To be added.</remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated" />
      </Docs>
    </Member>
    <Member MemberName="AudioLevelUpdated">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; AudioLevelUpdated;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; AudioLevelUpdated" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioLevelUpdated As EventHandler(Of AudioLevelUpdatedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioLevelUpdatedEventArgs ^&gt; ^ AudioLevelUpdated;" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-131">Występuje, gdy udostępniony aparat rozpoznawania zgłasza poziom jego wejście audio.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-131">Occurs when the shared recognizer reports the level of its audio input.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-132">Aparat rozpoznawania zgłasza zdarzenie, to wiele razy w ciągu sekundy.</span><span class="sxs-lookup"><span data-stu-id="4988b-132">The recognizer raises this event multiple times per second.</span></span> <span data-ttu-id="4988b-133">Częstotliwość, z którym zdarzenia zależy od komputera, na którym jest uruchomiona aplikacja.</span><span class="sxs-lookup"><span data-stu-id="4988b-133">The frequency with which the event is raised depends on the computer on which the application is running.</span></span>  
  
 <span data-ttu-id="4988b-134">Aby uzyskać poziom audio w czasie zdarzenia, użyj <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> właściwości skojarzonego <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>.</span><span class="sxs-lookup"><span data-stu-id="4988b-134">To get the audio level at the time of the event, use the <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> property of the associated <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>.</span></span> <span data-ttu-id="4988b-135">Aby uzyskać bieżący poziom audio w danych wejściowych aparat rozpoznawania, należy użyć aparat rozpoznawania <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A> właściwości.</span><span class="sxs-lookup"><span data-stu-id="4988b-135">To get the current audio level of the input to the recognizer, use the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A> property.</span></span>  
  
 <span data-ttu-id="4988b-136">Podczas tworzenia obiektu delegowanego dla `AudioLevelUpdated` zdarzenia, należy określić metodę, która obsłuży zdarzenie.</span><span class="sxs-lookup"><span data-stu-id="4988b-136">When you create a delegate for an `AudioLevelUpdated` event, you identify the method that will handle the event.</span></span> <span data-ttu-id="4988b-137">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-137">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="4988b-138">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</span><span class="sxs-lookup"><span data-stu-id="4988b-138">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="4988b-139">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz [zdarzenia i delegatów](http://go.microsoft.com/fwlink/?LinkId=162418).</span><span class="sxs-lookup"><span data-stu-id="4988b-139">For more information about event-handler delegates, see [Events and Delegates](http://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-140">Poniższy przykład umożliwia dodanie obsługi dla `AudioLevelUpdated` zdarzenia <xref:System.Speech.Recognition.SpeechRecognizer> obiektu.</span><span class="sxs-lookup"><span data-stu-id="4988b-140">The following example adds a handler for the `AudioLevelUpdated` event to a <xref:System.Speech.Recognition.SpeechRecognizer> object.</span></span> <span data-ttu-id="4988b-141">Program obsługi generuje nowy poziom audio do konsoli.</span><span class="sxs-lookup"><span data-stu-id="4988b-141">The handler outputs the new audio level to the console.</span></span>  
  
```csharp  
private SpeechRecognizer recognizer;  
  
// Initialize the SpeechRecognizer object.   
private void Initialize()  
{  
  recognizer = new SpeechRecognizer();  
  
  // Add an event handler for the AudioLevelUpdated event.  
  recognizer.AudioLevelUpdated +=   
    new EventHandler<AudioLevelUpdatedEventArgs>(recognizer_AudioLevelUpdated);  
  
  // Add other initialization code here.  
  
}  
  
// Write the audio level to the console when the AudioLevelUpdated event is raised.  
void recognizer_AudioLevelUpdated(object sender, AudioLevelUpdatedEventArgs e)  
{  
  Console.WriteLine("The audio level is now: {0}.", e.AudioLevel);  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioLevelUpdatedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      </Docs>
    </Member>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan AudioPosition { TimeSpan get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-142">Pobiera bieżącą lokalizację w strumieniem audio generowany przez urządzenie, który dostarcza dane wejściowe do rozpoznawania mowy.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-142">Gets the current location in the audio stream being generated by the device that is providing input to the speech recognizer.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="4988b-143">Bieżąca lokalizacja rozpoznawania mowy audio strumień wejściowy za pośrednictwem której otrzymał danych wejściowych.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-143">The current location in the speech recognizer's audio input stream through which it has received input.</span>
          </span>
        </value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-144">Udostępniony aparat rozpoznawania odbiera dane wejściowe podczas rozpoznawania mowy pulpitu.</span><span class="sxs-lookup"><span data-stu-id="4988b-144">The shared recognizer receives input while the desktop speech recognition is running.</span></span>  
  
 <span data-ttu-id="4988b-145">`AudioPosition` Właściwość odwołuje się do pozycji urządzenia wejściowego w jego wygenerowanego strumieniem audio.</span><span class="sxs-lookup"><span data-stu-id="4988b-145">The `AudioPosition` property references the input device's position in its generated audio stream.</span></span> <span data-ttu-id="4988b-146">Z kolei <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> właściwość odwołuje się do pozycji aparat rozpoznawania podczas przetwarzania danych wejściowych audio.</span><span class="sxs-lookup"><span data-stu-id="4988b-146">By contrast, the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> property references the recognizer's position in processing audio input.</span></span> <span data-ttu-id="4988b-147">Te pozycje mogą być różne.</span><span class="sxs-lookup"><span data-stu-id="4988b-147">These positions can be different.</span></span>  <span data-ttu-id="4988b-148">Na przykład jeśli aparat rozpoznawania otrzymał wejściowych, do których nie ma jeszcze generowane w wyniku rozpoznawania, a następnie wartość <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> właściwości jest mniejsza niż wartość <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> właściwości.</span><span class="sxs-lookup"><span data-stu-id="4988b-148">For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> property is less than the value of the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> property.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-149">W poniższym przykładzie rozpoznawania mowy udostępnionego używa gramatyki dyktowania w celu dopasowania danych wejściowych mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-149">In the following example, the shared speech recognizer uses a dictation grammar to match speech input.</span></span> <span data-ttu-id="4988b-150">Program obsługi <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> zapisuje zdarzenie w konsoli <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>, i <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A> podczas rozpoznawania mowy wykrywa mowy na jej danych wejściowych.</span><span class="sxs-lookup"><span data-stu-id="4988b-150">A handler for the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> event writes to the console the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>, and  <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A> when the speech recognizer detects speech at its input.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Add handlers for events.  
      recognizer.LoadGrammarCompleted +=   
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
      recognizer.SpeechRecognized +=   
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.StateChanged +=   
        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
      recognizer.SpeechDetected +=   
        new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  
  
      // Create a dictation grammar.  
      Grammar dictation = new DictationGrammar();  
      dictation.Name = "Dictation";  
  
      // Load the grammar object to the recognizer.  
      recognizer.LoadGrammarAsync(dictation);  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Gather information about detected speech and write it to the console.  
    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Speech detected:");  
      Console.WriteLine("  Audio level: " + recognizer.AudioLevel);  
      Console.WriteLine("  Audio position: " + recognizer.AudioPosition);  
      Console.WriteLine("  Recognizer audio position: " + recognizer.RecognizerAudioPosition);  
    }  
  
    // Write the text of the recognition result to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {   
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Write the name of the loaded grammar to the console.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="AudioSignalProblemOccurred">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; AudioSignalProblemOccurred;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; AudioSignalProblemOccurred" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioSignalProblemOccurred As EventHandler(Of AudioSignalProblemOccurredEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioSignalProblemOccurredEventArgs ^&gt; ^ AudioSignalProblemOccurred;" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-151">Występuje, gdy aparat rozpoznawania napotka problem w sygnału dźwiękowego.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-151">Occurs when the recognizer encounters a problem in the audio signal.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-152">Aby uzyskać, jaki problem wystąpił, należy użyć <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A> właściwości skojarzonego <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>.</span><span class="sxs-lookup"><span data-stu-id="4988b-152">To get which problem occurred, use the <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A> property of the associated <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>.</span></span>  
  
 <span data-ttu-id="4988b-153">Podczas tworzenia obiektu delegowanego dla `AudioSignalProblemOccurred` zdarzenia, należy określić metodę, która obsłuży zdarzenie.</span><span class="sxs-lookup"><span data-stu-id="4988b-153">When you create a delegate for an `AudioSignalProblemOccurred` event, you identify the method that will handle the event.</span></span> <span data-ttu-id="4988b-154">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-154">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="4988b-155">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</span><span class="sxs-lookup"><span data-stu-id="4988b-155">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="4988b-156">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz [zdarzenia i delegatów](http://go.microsoft.com/fwlink/?LinkId=162418).</span><span class="sxs-lookup"><span data-stu-id="4988b-156">For more information about event-handler delegates, see [Events and Delegates](http://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-157">W poniższym przykładzie zdefiniowano program obsługi zdarzeń, które zbiera informacje o `AudioSignalProblemOccurred` zdarzeń.</span><span class="sxs-lookup"><span data-stu-id="4988b-157">The following example defines an event handler that gathers information about an `AudioSignalProblemOccurred` event.</span></span>  
  
```  
private SpeechRecognizer recognizer;  
  
// Initialize the speech recognition engine.  
private void Initialize()  
{  
  recognizer = new SpeechRecognizer();  
  
  // Add a handler for the AudioSignalProblemOccurred event.  
  recognizer.AudioSignalProblemOccurred +=   
    new EventHandler<AudioSignalProblemOccurredEventArgs>(  
      recognizer_AudioSignalProblemOccurred);  
}  
  
// Gather information when the AudioSignalProblemOccurred event is raised.  
void recognizer_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  
{  
  StringBuilder details = new StringBuilder();  
  
  details.AppendLine("Audio signal problem information:");  
  details.AppendFormat(  
    " Audio level:               {0}" + Environment.NewLine +  
    " Audio position:            {1}" + Environment.NewLine +  
    " Audio signal problem:      {2}" + Environment.NewLine +  
    " Recognition engine audio position: {3}" + Environment.NewLine,  
    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  
    e.recoEngineAudioPosition);  
  
  // Insert additional event handler code here.  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioSignalProblem" />
        <altmember cref="T:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs" />
      </Docs>
    </Member>
    <Member MemberName="AudioState">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.AudioState AudioState { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.AudioState AudioState" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioState" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioState As AudioState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::AudioState AudioState { System::Speech::Recognition::AudioState get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.AudioState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-158">Pobiera stan audio odbierane przez aparat rozpoznawania mowy.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-158">Gets the state of the audio being received by the speech recognizer.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="4988b-159">Stan wejście audio do rozpoznawania mowy.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-159">The state of the audio input to the speech recognizer.</span>
          </span>
        </value>
        <remarks>To be added.</remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged" />
      </Docs>
    </Member>
    <Member MemberName="AudioStateChanged">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; AudioStateChanged;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioStateChangedEventArgs&gt; AudioStateChanged" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioStateChanged As EventHandler(Of AudioStateChangedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioStateChangedEventArgs ^&gt; ^ AudioStateChanged;" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-160">Występuje, gdy zmian stanu, które usłyszysz odbierane przez aparat rozpoznawania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-160">Occurs when the state changes in the audio being received by the recognizer.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-161">Aby pobrać stan dźwięku w czasie zdarzenia, użyj <xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> właściwości skojarzonego <xref:System.Speech.Recognition.AudioStateChangedEventArgs>.</span><span class="sxs-lookup"><span data-stu-id="4988b-161">To get the audio state at the time of the event, use the <xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> property of the associated <xref:System.Speech.Recognition.AudioStateChangedEventArgs>.</span></span> <span data-ttu-id="4988b-162">Aby uzyskać bieżący stan audio w danych wejściowych aparat rozpoznawania, należy użyć aparat rozpoznawania <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> właściwości.</span><span class="sxs-lookup"><span data-stu-id="4988b-162">To get the current audio state of the input to the recognizer, use the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> property.</span></span> <span data-ttu-id="4988b-163">Aby uzyskać więcej informacji na temat stanu audio, zobacz <xref:System.Speech.Recognition.AudioState> wyliczenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-163">For more information about audio state, see the <xref:System.Speech.Recognition.AudioState> enumeration.</span></span>  
  
 <span data-ttu-id="4988b-164">Podczas tworzenia obiektu delegowanego dla `AudioStateChanged` zdarzenia, należy określić metodę, która obsłuży zdarzenie.</span><span class="sxs-lookup"><span data-stu-id="4988b-164">When you create a delegate for an `AudioStateChanged` event, you identify the method that will handle the event.</span></span> <span data-ttu-id="4988b-165">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-165">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="4988b-166">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</span><span class="sxs-lookup"><span data-stu-id="4988b-166">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="4988b-167">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz [zdarzenia i delegatów](http://go.microsoft.com/fwlink/?LinkId=162418).</span><span class="sxs-lookup"><span data-stu-id="4988b-167">For more information about event-handler delegates, see [Events and Delegates](http://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-168">W poniższym przykładzie użyto obsługi dla `AudioStateChanged` zdarzenie, aby zapisać aparat rozpoznawania na nowy <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> konsoli każdego czasu zmiany przy użyciu członkiem <xref:System.Speech.Recognition.AudioState> wyliczenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-168">The following example uses a handler for the `AudioStateChanged` event to write the recognizer's new <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> to the console each time it changes using a member of the <xref:System.Speech.Recognition.AudioState> enumeration.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
        // Create and load a grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation Grammar";  
        recognizer.LoadGrammar(dictation);  
  
        // Attach event handlers.  
        recognizer.AudioStateChanged +=  
          new EventHandler<AudioStateChangedEventArgs>(recognizer_AudioStateChanged);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.StateChanged +=  
          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
  
    // Handle the AudioStateChanged event.  
    static void recognizer_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  
    {  
      Console.WriteLine("The new audio state is: " + e.AudioState);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null && e.Result.Text != null)  
      {  
        Console.WriteLine();  
        Console.WriteLine("  Recognized text =  {0}", e.Result.Text);  
        Console.WriteLine();  
      }  
      else  
      {  
        Console.WriteLine("  Recognized text not available.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Done.");  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Put the recognizer into Listening mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        Console.WriteLine();  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioState" />
        <altmember cref="T:System.Speech.Recognition.AudioStateChangedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioState" />
      </Docs>
    </Member>
    <MemberGroup MemberName="Dispose">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-169">Usuwa <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> obiektu.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-169">Disposes the <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> object.</span>
          </span>
        </summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="public void Dispose ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance void Dispose() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.Dispose" />
      <MemberSignature Language="VB.NET" Value="Public Sub Dispose ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; virtual void Dispose();" />
      <MemberType>Method</MemberType>
      <Implements>
        <InterfaceMember>M:System.IDisposable.Dispose</InterfaceMember>
      </Implements>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
          <span data-ttu-id="4988b-170">Usuwa <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> obiektu.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-170">Disposes the <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> object.</span>
          </span>
        </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="protected virtual void Dispose (bool disposing);" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig newslot virtual instance void Dispose(bool disposing) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)" />
      <MemberSignature Language="VB.NET" Value="Protected Overridable Sub Dispose (disposing As Boolean)" />
      <MemberSignature Language="C++ CLI" Value="protected:&#xA; virtual void Dispose(bool disposing);" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="disposing" Type="System.Boolean" />
      </Parameters>
      <Docs>
        <param name="disposing">
          <span data-ttu-id="4988b-171">
            <see langword="true" /> Aby zwolnić zasoby zarządzane i niezarządzane; <see langword="false" /> aby zwolnić tylko zasoby niezarządzane.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-171">
              <see langword="true" /> to release both managed and unmanaged resources; <see langword="false" /> to release only unmanaged resources.</span>
          </span>
        </param>
        <summary>
          <span data-ttu-id="4988b-172">Usuwa <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> obiektu i zwalnia zasoby używane w podczas sesji.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-172">Disposes the <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> object and releases resources used during the session.</span>
          </span>
        </summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="EmulateRecognize">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-173">Emuluje dane wejściowe do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy synchronicznego.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-173">Emulates input to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-174">Te metody obejścia wejście audio systemu.</span><span class="sxs-lookup"><span data-stu-id="4988b-174">These methods bypass the system audio input.</span></span> <span data-ttu-id="4988b-175">Może to być przydatne podczas testowania i debugowania aplikacji oraz błędy gramatyczne.</span><span class="sxs-lookup"><span data-stu-id="4988b-175">This can be helpful when you are testing or debugging an application or grammar.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="4988b-176">Jeśli rozpoznawanie mowy systemu Windows znajduje się w **uśpione** stanu, a następnie te metody zwracają `null`.</span><span class="sxs-lookup"><span data-stu-id="4988b-176">If Windows Speech Recognition is in the **Sleeping** state, then these methods return `null`.</span></span>  
  
 <span data-ttu-id="4988b-177">Generuje udostępniony aparat rozpoznawania <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, i <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> zdarzeń tak, jakby nie jest emulowana operacji rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-177">The shared recognizer raises the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> events as if the recognition operation is not emulated.</span></span> <span data-ttu-id="4988b-178">Aparat rozpoznawania ignoruje nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</span><span class="sxs-lookup"><span data-stu-id="4988b-178">The recognizer ignores new lines and extra white space and treats punctuation as literal input.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="4988b-179"><xref:System.Speech.Recognition.RecognitionResult> Generowane przez udostępniony aparat rozpoznawania w odpowiedzi na dane wejściowe emulowanej obiektu ma wartość `null` dla jego <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> właściwości.</span><span class="sxs-lookup"><span data-stu-id="4988b-179">The <xref:System.Speech.Recognition.RecognitionResult> object generated by the shared recognizer in response to emulated input has a value of `null` for its <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> property.</span></span>  
  
 <span data-ttu-id="4988b-180">Aby emulować asynchroniczne rozpoznawanie, użyj <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> metody.</span><span class="sxs-lookup"><span data-stu-id="4988b-180">To emulate asynchronous recognition, use the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(string inputText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Function EmulateRecognize (inputText As String) As RecognitionResult" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(System::String ^ inputText);" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="inputText">
          <span data-ttu-id="4988b-181">Dane wejściowe dla operacji rozpoznawania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-181">The input for the recognition operation.</span>
          </span>
        </param>
        <summary>
          <span data-ttu-id="4988b-182">Emuluje wprowadzania frazę do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy synchronicznego.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-182">Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</span>
          </span>
        </summary>
        <returns>
          <span data-ttu-id="4988b-183">Wynik rozpoznawania dla operacji rozpoznawania, lub <see langword="null" />, jeśli operacja nie powiedzie się lub rozpoznawanie mowy systemu Windows jest w **uśpione** stanu.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-183">The recognition result for the recognition operation, or <see langword="null" />, if the operation is not successful or Windows Speech Recognition is in the **Sleeping** state.</span>
          </span>
        </returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-184">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter i znaków szerokości, stosując reguły gramatyki do wprowadzania frazy.</span><span class="sxs-lookup"><span data-stu-id="4988b-184">The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</span></span> <span data-ttu-id="4988b-185">Aby uzyskać więcej informacji o tym typie porównanie, zobacz <xref:System.Globalization.CompareOptions> wartości wyliczenia <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> i <xref:System.Globalization.CompareOptions.IgnoreWidth>.</span><span class="sxs-lookup"><span data-stu-id="4988b-185">For more information about this type of comparison, see the <xref:System.Globalization.CompareOptions> enumeration values <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> and <xref:System.Globalization.CompareOptions.IgnoreWidth>.</span></span> <span data-ttu-id="4988b-186">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i Traktuj znaki interpunkcyjne jako dane wejściowe literału.</span><span class="sxs-lookup"><span data-stu-id="4988b-186">The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-187">W poniższym przykładzie ładuje gramatyki próbki do udostępniony aparat rozpoznawania i emuluje dane wejściowe dla aparatu rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-187">The following example loads a sample grammar to the shared recognizer and emulates input to the recognizer.</span></span> <span data-ttu-id="4988b-188">Jeśli rozpoznawania mowy nie jest uruchomiona, następnie uruchomienie tej aplikacji powoduje również uruchomienie rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-188">If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</span></span> <span data-ttu-id="4988b-189">Jeśli rozpoznawanie mowy systemu Windows znajduje się w **uśpione** stanu, następnie <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> zawsze zwraca wartość null.</span><span class="sxs-lookup"><span data-stu-id="4988b-189">If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> always returns null.</span></span>  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        RecognitionResult result;  
  
        // This EmulateRecognize call matches the grammar and returns a  
        // recognition result.  
        result = recognizer.EmulateRecognize("testing testing");  
        OutputResult(result);  
  
        // This EmulateRecognize call does not match the grammar and   
        // returns null.  
        result = recognizer.EmulateRecognize("testing one two three");  
        OutputResult(result);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Output information about a recognition result to the console.  
    private static void OutputResult(RecognitionResult result)  
    {  
      if (result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(class System.Speech.Recognition.RecognizedWordUnit[] wordUnits, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(cli::array &lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ wordUnits, System::Globalization::CompareOptions compareOptions);" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="wordUnits" Type="System.Speech.Recognition.RecognizedWordUnit[]" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="wordUnits">
          <span data-ttu-id="4988b-190">Tablica jednostki słowa zawierającego dane wejściowe dla operacji rozpoznawania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-190">An array of word units that contains the input for the recognition operation.</span>
          </span>
        </param>
        <param name="compareOptions">
          <span data-ttu-id="4988b-191">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-191">A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</span>
          </span>
        </param>
        <summary>
          <span data-ttu-id="4988b-192">Emuluje wprowadzania słów do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy synchroniczne i określa sposób obsługi przez aparat rozpoznawania porównanie Unicode słów i gramatyki rozpoznawania mowy załadowany.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-192">Emulates input of specific words to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</span>
          </span>
        </summary>
        <returns>
          <span data-ttu-id="4988b-193">Wynik rozpoznawania dla operacji rozpoznawania, lub <see langword="null" />, jeśli operacja nie powiedzie się lub rozpoznawanie mowy systemu Windows jest w **uśpione** stanu.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-193">The recognition result for the recognition operation, or <see langword="null" />, if the operation is not successful or Windows Speech Recognition is in the **Sleeping** state.</span>
          </span>
        </returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-194">Ta metoda tworzy <xref:System.Speech.Recognition.RecognitionResult> obiektów, korzystając z informacji podanych w `wordUnits` parametru.</span><span class="sxs-lookup"><span data-stu-id="4988b-194">This method creates a <xref:System.Speech.Recognition.RecognitionResult> object using the information provided in the `wordUnits` parameter.</span></span>  
  
 <span data-ttu-id="4988b-195">Aparat rozpoznawania używa `compareOptions` po stosuje reguły gramatyki do frazy wejściowych.</span><span class="sxs-lookup"><span data-stu-id="4988b-195">The recognizer uses the `compareOptions` when it applies grammar rules to the input phrase.</span></span> <span data-ttu-id="4988b-196">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> lub <xref:System.Globalization.CompareOptions.IgnoreCase> ma wartość.</span><span class="sxs-lookup"><span data-stu-id="4988b-196">The recognizers that ship with Vista and Windows 7 ignore case if the <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> or <xref:System.Globalization.CompareOptions.IgnoreCase> value is present.</span></span> <span data-ttu-id="4988b-197">Aparatów rozpoznawania zawsze Ignoruj szerokość znaku i nigdy nie Ignoruj typu znaki Kana.</span><span class="sxs-lookup"><span data-stu-id="4988b-197">The recognizers always ignore the character width and never ignore the Kana type.</span></span> <span data-ttu-id="4988b-198">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</span><span class="sxs-lookup"><span data-stu-id="4988b-198">The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</span></span> <span data-ttu-id="4988b-199">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz <xref:System.Globalization.CompareOptions> wyliczenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-199">For more information about character width and Kana type, see the <xref:System.Globalization.CompareOptions> enumeration.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(string inputText, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(System::String ^ inputText, System::Globalization::CompareOptions compareOptions);" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="inputText">
          <span data-ttu-id="4988b-200">Wyrażenie wejściowych dla operacji rozpoznawania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-200">The input phrase for the recognition operation.</span>
          </span>
        </param>
        <param name="compareOptions">
          <span data-ttu-id="4988b-201">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-201">A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</span>
          </span>
        </param>
        <summary>
          <span data-ttu-id="4988b-202">Emuluje wprowadzania frazę do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy synchroniczne i określa sposób obsługi przez aparat rozpoznawania Unicode porównanie frazę gramatyki rozpoznawania mowy załadowany.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-202">Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</span>
          </span>
        </summary>
        <returns>
          <span data-ttu-id="4988b-203">Wynik rozpoznawania dla operacji rozpoznawania, lub <see langword="null" />, jeśli operacja nie powiedzie się lub rozpoznawanie mowy systemu Windows jest w **uśpione** stanu.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-203">The recognition result for the recognition operation, or <see langword="null" />, if the operation is not successful or Windows Speech Recognition is in the **Sleeping** state.</span>
          </span>
        </returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-204">Aparat rozpoznawania używa `compareOptions` po stosuje reguły gramatyki do frazy wejściowych.</span><span class="sxs-lookup"><span data-stu-id="4988b-204">The recognizer uses the `compareOptions` when it applies grammar rules to the input phrase.</span></span> <span data-ttu-id="4988b-205">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> lub <xref:System.Globalization.CompareOptions.IgnoreCase> ma wartość.</span><span class="sxs-lookup"><span data-stu-id="4988b-205">The recognizers that ship with Vista and Windows 7 ignore case if the <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> or <xref:System.Globalization.CompareOptions.IgnoreCase> value is present.</span></span> <span data-ttu-id="4988b-206">Aparatów rozpoznawania zawsze Ignoruj szerokość znaku i nigdy nie Ignoruj typu znaki Kana.</span><span class="sxs-lookup"><span data-stu-id="4988b-206">The recognizers always ignore the character width and never ignore the Kana type.</span></span> <span data-ttu-id="4988b-207">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</span><span class="sxs-lookup"><span data-stu-id="4988b-207">The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</span></span> <span data-ttu-id="4988b-208">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz <xref:System.Globalization.CompareOptions> wyliczenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-208">For more information about character width and Kana type, see the <xref:System.Globalization.CompareOptions> enumeration.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <MemberGroup MemberName="EmulateRecognizeAsync">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-209">Emuluje dane wejściowe do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy asynchronicznego.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-209">Emulates input to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-210">Te metody obejścia wejście audio systemu.</span><span class="sxs-lookup"><span data-stu-id="4988b-210">These methods bypass the system audio input.</span></span> <span data-ttu-id="4988b-211">Może to być przydatne podczas testowania i debugowania aplikacji oraz błędy gramatyczne.</span><span class="sxs-lookup"><span data-stu-id="4988b-211">This can be helpful when you are testing or debugging an application or grammar.</span></span>  
  
 <span data-ttu-id="4988b-212">Generuje udostępniony aparat rozpoznawania <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, i <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> zdarzeń tak, jakby nie jest emulowana operacji rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-212">The shared recognizer raises the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> events as if the recognition operation is not emulated.</span></span> <span data-ttu-id="4988b-213">Po ukończeniu operacji asynchronicznej rozpoznawania aparat rozpoznawania zgłasza <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted> zdarzeń.</span><span class="sxs-lookup"><span data-stu-id="4988b-213">When the recognizer completes the asynchronous recognition operation, it raises the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted> event.</span></span> <span data-ttu-id="4988b-214">Aparat rozpoznawania ignoruje nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</span><span class="sxs-lookup"><span data-stu-id="4988b-214">The recognizer ignores new lines and extra white space and treats punctuation as literal input.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="4988b-215">Jeśli rozpoznawanie mowy systemu Windows znajduje się w **uśpione** stanu, a następnie udostępniony aparat rozpoznawania nie przetwarza danych wejściowych i nie zgłosi <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> i zdarzenia powiązane, ale nadal zgłasza <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted> zdarzeń.</span><span class="sxs-lookup"><span data-stu-id="4988b-215">If Windows Speech Recognition is in the **Sleeping** state, then the shared recognizer does not process input and does not raise the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> and related events, but still raises the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted> event.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="4988b-216"><xref:System.Speech.Recognition.RecognitionResult> Generowane przez udostępniony aparat rozpoznawania w odpowiedzi na dane wejściowe emulowanej obiektu ma wartość `null` dla jego <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> właściwości.</span><span class="sxs-lookup"><span data-stu-id="4988b-216">The <xref:System.Speech.Recognition.RecognitionResult> object generated by the shared recognizer in response to emulated input has a value of `null` for its <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> property.</span></span>  
  
 <span data-ttu-id="4988b-217">Aby emulować rozpoznawania synchroniczne, użyj <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> metody.</span><span class="sxs-lookup"><span data-stu-id="4988b-217">To emulate synchronous recognition, use the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (string inputText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(string inputText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub EmulateRecognizeAsync (inputText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(System::String ^ inputText);" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="inputText">
          <span data-ttu-id="4988b-218">Dane wejściowe dla operacji rozpoznawania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-218">The input for the recognition operation.</span>
          </span>
        </param>
        <summary>
          <span data-ttu-id="4988b-219">Emuluje wprowadzania frazę do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy asynchronicznego.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-219">Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-220">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter i znaków szerokości, stosując reguły gramatyki do wprowadzania frazy.</span><span class="sxs-lookup"><span data-stu-id="4988b-220">The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</span></span> <span data-ttu-id="4988b-221">Aby uzyskać więcej informacji o tym typie porównanie, zobacz <xref:System.Globalization.CompareOptions> wartości wyliczenia <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> i <xref:System.Globalization.CompareOptions.IgnoreWidth>.</span><span class="sxs-lookup"><span data-stu-id="4988b-221">For more information about this type of comparison, see the <xref:System.Globalization.CompareOptions> enumeration values <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> and <xref:System.Globalization.CompareOptions.IgnoreWidth>.</span></span> <span data-ttu-id="4988b-222">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i Traktuj znaki interpunkcyjne jako dane wejściowe literału.</span><span class="sxs-lookup"><span data-stu-id="4988b-222">The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-223">Poniższy przykład jest częścią aplikacji konsoli, który ładuje gramatyki rozpoznawania mowy i przedstawia asynchroniczne emulowanej danych wejściowych, wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-223">The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</span></span> <span data-ttu-id="4988b-224">Jeśli rozpoznawania mowy nie jest uruchomiona, następnie uruchomienie tej aplikacji powoduje również uruchomienie rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-224">If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</span></span> <span data-ttu-id="4988b-225">Jeśli rozpoznawanie mowy systemu Windows znajduje się w **uśpione** stanu, następnie <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> zawsze zwraca wartość null.</span><span class="sxs-lookup"><span data-stu-id="4988b-225">If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar   
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the EmulateRecognizeCompleted event.   
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(class System.Speech.Recognition.RecognizedWordUnit[] wordUnits, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(cli::array &lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ wordUnits, System::Globalization::CompareOptions compareOptions);" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="wordUnits" Type="System.Speech.Recognition.RecognizedWordUnit[]" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="wordUnits">
          <span data-ttu-id="4988b-226">Tablica jednostki słowa zawierającego dane wejściowe dla operacji rozpoznawania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-226">An array of word units that contains the input for the recognition operation.</span>
          </span>
        </param>
        <param name="compareOptions">
          <span data-ttu-id="4988b-227">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-227">A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</span>
          </span>
        </param>
        <summary>
          <span data-ttu-id="4988b-228">Emuluje wprowadzania słów do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy asynchroniczne i określa sposób obsługi przez aparat rozpoznawania porównanie Unicode słów i gramatyki rozpoznawania mowy załadowany.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-228">Emulates input of specific words to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-229">Ta metoda tworzy <xref:System.Speech.Recognition.RecognitionResult> obiektów, korzystając z informacji podanych w `wordUnits` parametru.</span><span class="sxs-lookup"><span data-stu-id="4988b-229">This method creates a <xref:System.Speech.Recognition.RecognitionResult> object using the information provided in the `wordUnits` parameter.</span></span>  
  
 <span data-ttu-id="4988b-230">Aparat rozpoznawania używa `compareOptions` po stosuje reguły gramatyki do frazy wejściowych.</span><span class="sxs-lookup"><span data-stu-id="4988b-230">The recognizer uses the `compareOptions` when it applies grammar rules to the input phrase.</span></span> <span data-ttu-id="4988b-231">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> lub <xref:System.Globalization.CompareOptions.IgnoreCase> ma wartość.</span><span class="sxs-lookup"><span data-stu-id="4988b-231">The recognizers that ship with Vista and Windows 7 ignore case if the <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> or <xref:System.Globalization.CompareOptions.IgnoreCase> value is present.</span></span> <span data-ttu-id="4988b-232">Aparatów rozpoznawania zawsze Ignoruj szerokość znaku i nigdy nie Ignoruj typu znaki Kana.</span><span class="sxs-lookup"><span data-stu-id="4988b-232">The recognizers always ignore the character width and never ignore the Kana type.</span></span> <span data-ttu-id="4988b-233">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</span><span class="sxs-lookup"><span data-stu-id="4988b-233">The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</span></span> <span data-ttu-id="4988b-234">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz <xref:System.Globalization.CompareOptions> wyliczenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-234">For more information about character width and Kana type, see the <xref:System.Globalization.CompareOptions> enumeration.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (string inputText, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(string inputText, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(System::String ^ inputText, System::Globalization::CompareOptions compareOptions);" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="inputText">
          <span data-ttu-id="4988b-235">Wyrażenie wejściowych dla operacji rozpoznawania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-235">The input phrase for the recognition operation.</span>
          </span>
        </param>
        <param name="compareOptions">
          <span data-ttu-id="4988b-236">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-236">A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</span>
          </span>
        </param>
        <summary>
          <span data-ttu-id="4988b-237">Emuluje wprowadzania frazę do aparatu rozpoznawania mowy udostępnionego, przy użyciu tekstu zamiast audio rozpoznawania mowy asynchroniczne i określa sposób obsługi przez aparat rozpoznawania Unicode porównanie frazę gramatyki rozpoznawania mowy załadowany.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-237">Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-238">Aparat rozpoznawania używa `compareOptions` po stosuje reguły gramatyki do frazy wejściowych.</span><span class="sxs-lookup"><span data-stu-id="4988b-238">The recognizer uses the `compareOptions` when it applies grammar rules to the input phrase.</span></span> <span data-ttu-id="4988b-239">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> lub <xref:System.Globalization.CompareOptions.IgnoreCase> ma wartość.</span><span class="sxs-lookup"><span data-stu-id="4988b-239">The recognizers that ship with Vista and Windows 7 ignore case if the <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> or <xref:System.Globalization.CompareOptions.IgnoreCase> value is present.</span></span> <span data-ttu-id="4988b-240">Aparatów rozpoznawania zawsze Ignoruj szerokość znaku i nigdy nie Ignoruj typu znaki Kana.</span><span class="sxs-lookup"><span data-stu-id="4988b-240">The recognizers always ignore the character width and never ignore the Kana type.</span></span> <span data-ttu-id="4988b-241">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</span><span class="sxs-lookup"><span data-stu-id="4988b-241">The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</span></span> <span data-ttu-id="4988b-242">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz <xref:System.Globalization.CompareOptions> wyliczenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-242">For more information about character width and Kana type, see the <xref:System.Globalization.CompareOptions> enumeration.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; EmulateRecognizeCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; EmulateRecognizeCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Event EmulateRecognizeCompleted As EventHandler(Of EmulateRecognizeCompletedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::EmulateRecognizeCompletedEventArgs ^&gt; ^ EmulateRecognizeCompleted;" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-243">Występuje, gdy udostępniony aparat rozpoznawania Kończenie znajdujących się w operacji asynchronicznych rozpoznawania emulowanej danych wejściowych.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-243">Occurs when the shared recognizer finalizes an asynchronous recognition operation for emulated input.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-244">Każdy <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> metoda rozpoczyna operację asynchroniczną rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-244">Each <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> method begins an asynchronous recognition operation.</span></span> <span data-ttu-id="4988b-245">Generuje aparatu rozpoznawania `EmulateRecognizeCompleted` zdarzenie, gdy jego Kończenie znajdujących się w operacji asynchronicznej.</span><span class="sxs-lookup"><span data-stu-id="4988b-245">The recognizer raises the `EmulateRecognizeCompleted` event when it finalizes the asynchronous operation.</span></span>  
  
 <span data-ttu-id="4988b-246">Wywołuje operację asynchroniczną rozpoznawania <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, i <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> zdarzenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-246">The asynchronous recognition operation can raise the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> events.</span></span> <span data-ttu-id="4988b-247"><xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted> Zdarzenie jest ostatni tych zdarzeń, że aparat rozpoznawania zgłasza dla danej operacji.</span><span class="sxs-lookup"><span data-stu-id="4988b-247">The <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted> event is the last such event that the recognizer raises for a given operation.</span></span>  
  
 <span data-ttu-id="4988b-248">Podczas tworzenia obiektu delegowanego dla `EmulateRecognizeCompleted` zdarzenia, należy określić metodę, która obsłuży zdarzenie.</span><span class="sxs-lookup"><span data-stu-id="4988b-248">When you create a delegate for an `EmulateRecognizeCompleted` event, you identify the method that will handle the event.</span></span> <span data-ttu-id="4988b-249">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-249">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="4988b-250">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</span><span class="sxs-lookup"><span data-stu-id="4988b-250">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="4988b-251">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz [zdarzenia i delegatów](http://go.microsoft.com/fwlink/?LinkId=162418).</span><span class="sxs-lookup"><span data-stu-id="4988b-251">For more information about event-handler delegates, see [Events and Delegates](http://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-252">Poniższy przykład jest częścią aplikacji konsoli, który ładuje gramatyki rozpoznawania mowy i przedstawia asynchroniczne emulowanej danych wejściowych, wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-252">The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</span></span> <span data-ttu-id="4988b-253">Jeśli rozpoznawania mowy nie jest uruchomiona, następnie uruchomienie tej aplikacji powoduje również uruchomienie rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-253">If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</span></span> <span data-ttu-id="4988b-254">Jeśli rozpoznawanie mowy systemu Windows znajduje się w **uśpione** trybie, a następnie <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> zawsze zwraca wartość null.</span><span class="sxs-lookup"><span data-stu-id="4988b-254">If Windows Speech Recognition is in the **Sleeping** mode, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=   
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar  
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the EmulateRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="Enabled">
      <MemberSignature Language="C#" Value="public bool Enabled { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool Enabled" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
      <MemberSignature Language="VB.NET" Value="Public Property Enabled As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool Enabled { bool get(); void set(bool value); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-255">Pobiera lub ustawia wartość wskazującą, czy to <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> obiekt jest gotowe do przetworzenia mowy.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-255">Gets or sets a value that indicates whether this <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> object is ready to process speech.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="4988b-256">
            <see langword="true" /> Jeśli <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> obiektu wykonuje rozpoznawanie mowy; w przeciwnym razie <see langword="false" />.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-256">
              <see langword="true" /> if this <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> object is performing speech recognition; otherwise, <see langword="false" />.</span>
          </span>
        </value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-257">Zmiany w tej właściwości nie wpływają na inne wystąpienia <xref:System.Speech.Recognition.SpeechRecognizer> klasy.</span><span class="sxs-lookup"><span data-stu-id="4988b-257">Changes to this property do not affect other instances of the <xref:System.Speech.Recognition.SpeechRecognizer> class.</span></span>  
  
 <span data-ttu-id="4988b-258">Domyślnie wartość <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> właściwość jest `true` dla nowo skonkretyzowanym wystąpienia <xref:System.Speech.Recognition.SpeechRecognizer>.</span><span class="sxs-lookup"><span data-stu-id="4988b-258">By default, the value of the <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> property is `true` for a newly instantiated instance of <xref:System.Speech.Recognition.SpeechRecognizer>.</span></span> <span data-ttu-id="4988b-259">Gdy aparat rozpoznawania jest wyłączone, aparat rozpoznawania mowy rozpoznawania gramatyki nie jest dostępna żadna dla operacji rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-259">While the recognizer is disabled, none of the recognizer's speech recognition grammars are available for recognition operations.</span></span> <span data-ttu-id="4988b-260">Ustawienie aparatu rozpoznawania <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> właściwość nie ma wpływu na aparat rozpoznawania <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> właściwości.</span><span class="sxs-lookup"><span data-stu-id="4988b-260">Setting the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> property has no effect on the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> property.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      </Docs>
    </Member>
    <Member MemberName="Grammars">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt; Grammars { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.Grammar&gt; Grammars" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Grammars As ReadOnlyCollection(Of Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::Grammar ^&gt; ^ Grammars { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::Grammar ^&gt; ^ get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-261">Pobiera kolekcję <see cref="T:System.Speech.Recognition.Grammar" /> obiektów, które są ładowane w tym <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> wystąpienia.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-261">Gets a collection of the <see cref="T:System.Speech.Recognition.Grammar" /> objects that are loaded in this <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> instance.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="4988b-262">Kolekcja <see cref="T:System.Speech.Recognition.Grammar" /> obiektów, które aplikacji załadowane do bieżącego wystąpienia udostępniony aparat rozpoznawania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-262">A collection of the <see cref="T:System.Speech.Recognition.Grammar" /> objects that the application loaded into the current instance of the shared recognizer.</span>
          </span>
        </value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-263">Ta właściwość nie zwraca żadnych mowy gramatyki rozpoznawania załadowane przez inną aplikację.</span><span class="sxs-lookup"><span data-stu-id="4988b-263">This property does not return any speech recognition grammars loaded by another application.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-264">Poniższy przykład danych wyjściowych informacji do konsoli dla każdego gramatyki rozpoznawania mowy ładowane do rozpoznawania mowy udostępnionego.</span><span class="sxs-lookup"><span data-stu-id="4988b-264">The following example outputs information to the console for each speech recognition grammar loaded into the shared speech recognizer.</span></span>  
  
```csharp  
  
using System;  
using System.Collections.Generic;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        Grammar sampleGrammar = new Grammar(new GrammarBuilder("sample phrase"));  
        sampleGrammar.Name = "Sample Grammar";  
        recognizer.LoadGrammar(sampleGrammar);  
  
        OutputGrammarList(recognizer);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    private static void OutputGrammarList(SpeechRecognizer recognizer)  
    {  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      if (grammars.Count > 0)  
      {  
        Console.WriteLine("Loaded grammars:");  
        foreach (Grammar g in grammars)  
        {  
          Console.WriteLine("  Grammar: {0}",  
            (g.Name != null) ? g.Name : "<no name>");  
        }  
      }  
      else  
      {  
        Console.WriteLine("No grammars loaded.");  
      }  
    }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammar">
      <MemberSignature Language="C#" Value="public void LoadGrammar (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void LoadGrammar(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void LoadGrammar(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar">
          <span data-ttu-id="4988b-265">Rozpoznawanie mowy gramatyki do załadowania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-265">The speech recognition grammar to load.</span>
          </span>
        </param>
        <summary>
          <span data-ttu-id="4988b-266">Ładuje gramatyki rozpoznawania mowy.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-266">Loads a speech recognition grammar.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-267">Udostępniony aparat rozpoznawania zgłasza wyjątek, jeśli gramatyki rozpoznawania mowy jest już załadowany, jest ładowany asynchronicznie lub nie można załadować do dowolnego aparatu rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-267">The shared recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</span></span> <span data-ttu-id="4988b-268">Jeśli aparat rozpoznawania jest uruchomiona, aplikacje muszą używać <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> wstrzymania aparat rozpoznawania mowy przed ładowania, zwalnianie, włączanie lub wyłączanie gramatyki.</span><span class="sxs-lookup"><span data-stu-id="4988b-268">If the recognizer is running, applications must use <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</span></span>  
  
 <span data-ttu-id="4988b-269">Aby załadować gramatyki rozpoznawania mowy asynchronicznie, należy użyć <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> metody.</span><span class="sxs-lookup"><span data-stu-id="4988b-269">To load a speech recognition grammar asynchronously, use the <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> method.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-270">Poniższy przykład jest częścią aplikacji konsoli, który ładuje gramatyki rozpoznawania mowy i przedstawia asynchroniczne emulowanej danych wejściowych, wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-270">The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</span></span> <span data-ttu-id="4988b-271">Jeśli rozpoznawania mowy nie jest uruchomiona, następnie uruchomienie tej aplikacji powoduje również uruchomienie rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-271">If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</span></span> <span data-ttu-id="4988b-272">Jeśli rozpoznawanie mowy systemu Windows znajduje się w **uśpione** stanu, następnie <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> zawsze zwraca wartość null.</span><span class="sxs-lookup"><span data-stu-id="4988b-272">If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar   
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }   
  
    // Handle the EmulateRecognizeCompleted event.   
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammarAsync">
      <MemberSignature Language="C#" Value="public void LoadGrammarAsync (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void LoadGrammarAsync(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void LoadGrammarAsync(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar">
          <span data-ttu-id="4988b-273">Rozpoznawanie mowy gramatyki do załadowania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-273">The speech recognition grammar to load.</span>
          </span>
        </param>
        <summary>
          <span data-ttu-id="4988b-274">Asynchronicznie ładuje gramatyki rozpoznawania mowy.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-274">Asynchronously loads a speech recognition grammar.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-275">Po ukończeniu tej operacji asynchronicznej aparat rozpoznawania zgłasza <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted> zdarzeń.</span><span class="sxs-lookup"><span data-stu-id="4988b-275">When the recognizer completes this asynchronous operation, it raises a <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted> event.</span></span> <span data-ttu-id="4988b-276">Aparat rozpoznawania zgłasza wyjątek, jeśli gramatyki rozpoznawania mowy jest już załadowany, jest ładowany asynchronicznie lub nie można załadować do dowolnego aparatu rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-276">The recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</span></span> <span data-ttu-id="4988b-277">Jeśli aparat rozpoznawania jest uruchomiona, aplikacje muszą używać <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> wstrzymania aparat rozpoznawania mowy przed ładowania, zwalnianie, włączanie lub wyłączanie gramatyki.</span><span class="sxs-lookup"><span data-stu-id="4988b-277">If the recognizer is running, applications must use <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</span></span>  
  
 <span data-ttu-id="4988b-278">Aby załadować gramatyki rozpoznawania mowy synchronicznie, należy użyć <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A> metody.</span><span class="sxs-lookup"><span data-stu-id="4988b-278">To load a speech recognition grammar synchronously, use the <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammarCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; LoadGrammarCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; LoadGrammarCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Event LoadGrammarCompleted As EventHandler(Of LoadGrammarCompletedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::LoadGrammarCompletedEventArgs ^&gt; ^ LoadGrammarCompleted;" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-279">Występuje, gdy aparat rozpoznawania zakończy asynchroniczne ładowanie gramatyki rozpoznawania mowy.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-279">Occurs when the recognizer finishes the asynchronous loading of a speech recognition grammar.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-280">Aparat rozpoznawania <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> metoda inicjuje operację asynchroniczną.</span><span class="sxs-lookup"><span data-stu-id="4988b-280">The recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> method initiates an asynchronous operation.</span></span> <span data-ttu-id="4988b-281">Generuje aparatu rozpoznawania `LoadGrammarCompleted` zdarzeń po zakończeniu tej operacji.</span><span class="sxs-lookup"><span data-stu-id="4988b-281">The recognizer raises the `LoadGrammarCompleted` event when it completes the operation.</span></span> <span data-ttu-id="4988b-282">Aby uzyskać <xref:System.Speech.Recognition.Grammar> obiekt, aby załadować aparat rozpoznawania, użyj <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A> właściwości skojarzonego <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>.</span><span class="sxs-lookup"><span data-stu-id="4988b-282">To get the <xref:System.Speech.Recognition.Grammar> object that the recognizer loaded, use the <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A> property of the associated <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>.</span></span> <span data-ttu-id="4988b-283">Aby uzyskać bieżącą <xref:System.Speech.Recognition.Grammar> obiekty aparat rozpoznawania został załadowany, używają aparat rozpoznawania <xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A> właściwości.</span><span class="sxs-lookup"><span data-stu-id="4988b-283">To get the current <xref:System.Speech.Recognition.Grammar> objects the recognizer has loaded, use the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A> property.</span></span>  
  
 <span data-ttu-id="4988b-284">Podczas tworzenia obiektu delegowanego dla `LoadGrammarCompleted` zdarzenia, należy określić metodę, która obsłuży zdarzenie.</span><span class="sxs-lookup"><span data-stu-id="4988b-284">When you create a delegate for a `LoadGrammarCompleted` event, you identify the method that will handle the event.</span></span> <span data-ttu-id="4988b-285">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-285">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="4988b-286">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</span><span class="sxs-lookup"><span data-stu-id="4988b-286">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="4988b-287">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz [zdarzenia i delegatów](http://go.microsoft.com/fwlink/?LinkId=162418).</span><span class="sxs-lookup"><span data-stu-id="4988b-287">For more information about event-handler delegates, see [Events and Delegates](http://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-288">Poniższy przykład tworzy aparat rozpoznawania mowy udostępnionego, a następnie tworzy dwa typy gramatyki rozpoznawania słów i akceptowania dyktowania wolne.</span><span class="sxs-lookup"><span data-stu-id="4988b-288">The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</span></span> <span data-ttu-id="4988b-289">Przykład asynchronicznie ładuje wszystkie utworzone gramatyki do aparatu rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-289">The example asynchronously loads all the created grammars to the recognizer.</span></span> <span data-ttu-id="4988b-290">Programy obsługi dla aparat rozpoznawania <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted> i <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> zdarzenia zapisu do konsoli nazwę gramatyki, która została użyta do wykonania odpowiednio uznania i tekst wyniku rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-290">Handlers for the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted> and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> events write to the console the name of the grammar that was used to perform the recognition and the text of the recognition result, respectively.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Add a handler for the StateChanged event.  
        recognizer.StateChanged +=  
          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
        // Create "yesno" grammar.  
        Choices yesChoices = new Choices(new string[] { "yes", "yup", "yeah}" });  
        SemanticResultValue yesValue =  
            new SemanticResultValue(yesChoices, (bool)true);  
        Choices noChoices = new Choices(new string[] { "no", "nope", "neah" });  
        SemanticResultValue noValue =  
            new SemanticResultValue(noChoices, (bool)false);  
        SemanticResultKey yesNoKey =  
            new SemanticResultKey("yesno", new Choices(new GrammarBuilder[] { yesValue, noValue }));  
        Grammar yesnoGrammar = new Grammar(yesNoKey);  
        yesnoGrammar.Name = "yesNo";  
  
        // Create "done" grammar.  
        Grammar doneGrammar =  
          new Grammar(new Choices(new string[] { "done", "exit", "quit", "stop" }));  
        doneGrammar.Name = "Done";  
  
        // Create dictation grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation";  
  
        // Load grammars to the recognizer.  
        recognizer.LoadGrammarAsync(yesnoGrammar);  
        recognizer.LoadGrammarAsync(doneGrammar);  
        recognizer.LoadGrammarAsync(dictation);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded.",  
      grammarName, (grammarLoaded) ? "is" : "is not");  
    }  
  
    // Put the shared speech recognizer into "listening" mode.   
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.LoadGrammarCompletedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="MaxAlternates">
      <MemberSignature Language="C#" Value="public int MaxAlternates { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 MaxAlternates" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates" />
      <MemberSignature Language="VB.NET" Value="Public Property MaxAlternates As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int MaxAlternates { int get(); void set(int value); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-291">Pobiera lub ustawia maksymalną liczbę wyników rozpoznawania alternatywny, które zwraca udostępniony aparat rozpoznawania dla każdej operacji rozpoznawania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-291">Gets or sets the maximum number of alternate recognition results that the shared recognizer returns for each recognition operation.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="4988b-292">Maksymalna liczba wyników alternatywny, które zwraca rozpoznawania mowy dla każdej operacji rozpoznawania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-292">The maximum number of alternate results that the speech recognizer returns for each recognition operation.</span>
          </span>
        </value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-293"><xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> Właściwość <xref:System.Speech.Recognition.RecognitionResult> klasy zawiera kolekcję <xref:System.Speech.Recognition.RecognizedPhrase> obiekty reprezentujące interpretacji candidate innych danych wejściowych.</span><span class="sxs-lookup"><span data-stu-id="4988b-293">The <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> property of the <xref:System.Speech.Recognition.RecognitionResult> class contains the collection of <xref:System.Speech.Recognition.RecognizedPhrase> objects that represent other candidate interpretations of the input.</span></span>  
  
 <span data-ttu-id="4988b-294">Wartość domyślna dla <xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A> wynosi 10.</span><span class="sxs-lookup"><span data-stu-id="4988b-294">The default value for <xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A> is 10.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="PauseRecognizerOnRecognition">
      <MemberSignature Language="C#" Value="public bool PauseRecognizerOnRecognition { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool PauseRecognizerOnRecognition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      <MemberSignature Language="VB.NET" Value="Public Property PauseRecognizerOnRecognition As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool PauseRecognizerOnRecognition { bool get(); void set(bool value); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-295">Pobiera lub ustawia wartość wskazującą, czy udostępniony aparat rozpoznawania wstrzymuje operacji rozpoznawania, podczas gdy aplikacja jest obsługa <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> zdarzeń.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-295">Gets or sets a value that indicates whether the shared recognizer pauses recognition operations while an application is handling a <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> event.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="4988b-296">
            <see langword="true" /> Jeśli udostępniony aparat rozpoznawania czeka można przetworzyć danych wejściowych, gdy obsługuje dowolnej aplikacji <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> zdarzeń; w przeciwnym razie <see langword="false" />.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-296">
              <see langword="true" /> if the shared recognizer waits to process input while any application is handling the <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> event; otherwise, <see langword="false" />.</span>
          </span>
        </value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-297">Ta właściwość jest ustawiana `true`, jeśli w ramach <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> obsługi zdarzeń, aplikacja musi zmienić stan usługi rozpoznawania mowy lub gramatyki rozpoznawania mowy załadowany lub włączone przed uruchomieniem usługi rozpoznawania mowy procesy więcej danych wejściowych.</span><span class="sxs-lookup"><span data-stu-id="4988b-297">Set this property to `true`, if within the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event handler your application needs to change the state of the speech recognition service or change the loaded or enabled speech recognition grammars before the speech recognition service processes more input.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="4988b-298">Ustawienie <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> właściwości `true` powoduje, że każdy <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> obsługi zdarzeń w każdej aplikacji, aby zablokować usługa rozpoznawania mowy systemu Windows.</span><span class="sxs-lookup"><span data-stu-id="4988b-298">Setting the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> property to `true` causes each <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event handler in every application to block the Windows speech recognition service.</span></span>  
  
 <span data-ttu-id="4988b-299">Aby zsynchronizować zmiany z udostępniony aparat rozpoznawania ze stanem aplikacji, należy użyć <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> metody.</span><span class="sxs-lookup"><span data-stu-id="4988b-299">To synchronize the changes to the shared recognizer with your application state, use the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method.</span></span>  
  
 <span data-ttu-id="4988b-300">Gdy <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A> jest `true`, podczas wykonywania <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> obsługi usługi rozpoznawania mowy wstrzymuje i buforuje nowe wejście audio odbieraną.</span><span class="sxs-lookup"><span data-stu-id="4988b-300">When <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A> is `true`, during the execution of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> handler the speech recognition service pauses and buffers new audio input as it arrives.</span></span> <span data-ttu-id="4988b-301">Raz <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> obsługi zdarzeń opuszcza rozpoznawania wznawia usługi rozpoznawania mowy i rozpoczyna przetwarzanie informacji z jego buforu wejściowego.</span><span class="sxs-lookup"><span data-stu-id="4988b-301">Once the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event handler exits, the speech recognition service resumes recognition and starts processing information from its input buffer.</span></span>  
  
 <span data-ttu-id="4988b-302">Aby włączyć lub wyłączyć usługę rozpoznawania mowy, należy użyć <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> właściwości.</span><span class="sxs-lookup"><span data-stu-id="4988b-302">To enable or disable the speech recognition service, use the <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> property.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerAudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan RecognizerAudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan RecognizerAudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerAudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan RecognizerAudioPosition { TimeSpan get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-303">Pobiera bieżącą lokalizację aparatu rozpoznawania w wejściowych danych audio, który przetwarzania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-303">Gets the current location of the recognizer in the audio input that it is processing.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="4988b-304">Pozycja rozpoznawania w wejściowych danych audio, który przetwarzania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-304">The position of the recognizer in the audio input that it is processing.</span>
          </span>
        </value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-305">`RecognizerAudioPosition` Właściwość odwołuje się do pozycji aparat rozpoznawania podczas przetwarzania jego wejście audio.</span><span class="sxs-lookup"><span data-stu-id="4988b-305">The `RecognizerAudioPosition` property references the recognizer's position in processing its audio input.</span></span> <span data-ttu-id="4988b-306">Z kolei <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> właściwość odwołuje się do pozycji urządzenia wejściowego w jego wygenerowanego strumieniem audio.</span><span class="sxs-lookup"><span data-stu-id="4988b-306">By contrast, the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> property references the input device's position in its generated audio stream.</span></span> <span data-ttu-id="4988b-307">Te pozycje mogą być różne.</span><span class="sxs-lookup"><span data-stu-id="4988b-307">These positions can be different.</span></span> <span data-ttu-id="4988b-308">Na przykład jeśli aparat rozpoznawania otrzymał wejściowych, do których nie ma jeszcze generowane w wyniku rozpoznawania, a następnie wartość <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> właściwości jest mniejsza niż wartość <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> właściwości.</span><span class="sxs-lookup"><span data-stu-id="4988b-308">For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> property is less than the value of the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> property.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerInfo">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizerInfo RecognizerInfo { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.RecognizerInfo RecognizerInfo" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerInfo As RecognizerInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizerInfo ^ RecognizerInfo { System::Speech::Recognition::RecognizerInfo ^ get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-309">Pobiera informacje o rozpoznawania mowy udostępnionego.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-309">Gets information about the shared speech recognizer.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="4988b-310">Informacje dotyczące aparatu rozpoznawania mowy udostępnionego.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-310">Information about the shared speech recognizer.</span>
          </span>
        </value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-311">Ta właściwość zwraca informacje dotyczące aparatu rozpoznawania mowy używany przez rozpoznawanie mowy w systemie Windows.</span><span class="sxs-lookup"><span data-stu-id="4988b-311">This property returns information about the speech recognizer in use by Windows Speech Recognition.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-312">Poniższy przykład wysyła informacje o udostępniony aparat rozpoznawania do konsoli.</span><span class="sxs-lookup"><span data-stu-id="4988b-312">The following example sends information about the shared recognizer to the console.</span></span>  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        Console.WriteLine("Recognizer information for the shared recognizer:");  
        Console.WriteLine("  Name: {0}", recognizer.RecognizerInfo.Name);  
        Console.WriteLine("  Culture: {0}", recognizer.RecognizerInfo.Culture.ToString());  
        Console.WriteLine("  Description: {0}", recognizer.RecognizerInfo.Description);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerInfo" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerUpdateReached">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; RecognizerUpdateReached;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; RecognizerUpdateReached" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
      <MemberSignature Language="VB.NET" Value="Public Event RecognizerUpdateReached As EventHandler(Of RecognizerUpdateReachedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::RecognizerUpdateReachedEventArgs ^&gt; ^ RecognizerUpdateReached;" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-313">Występuje, gdy aparat rozpoznawania wstrzymuje zsynchronizować rozpoznawania i innych operacji.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-313">Occurs when the recognizer pauses to synchronize recognition and other operations.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-314">Aplikacje muszą używać <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> wstrzymania działającego wystąpienia <xref:System.Speech.Recognition.SpeechRecognizer> przed zmodyfikowaniem jego <xref:System.Speech.Recognition.Grammar> obiektów.</span><span class="sxs-lookup"><span data-stu-id="4988b-314">Applications must use <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> to pause a running instance of <xref:System.Speech.Recognition.SpeechRecognizer> before modifying its <xref:System.Speech.Recognition.Grammar> objects.</span></span> <span data-ttu-id="4988b-315">Na przykład <xref:System.Speech.Recognition.SpeechRecognizer> jest wstrzymana, możesz można załadować, zwolnienie, włączania i wyłączania <xref:System.Speech.Recognition.Grammar> obiektów.</span><span class="sxs-lookup"><span data-stu-id="4988b-315">For example, while the <xref:System.Speech.Recognition.SpeechRecognizer> is paused, you can load, unload, enable, and disable <xref:System.Speech.Recognition.Grammar> objects.</span></span> <span data-ttu-id="4988b-316"><xref:System.Speech.Recognition.SpeechRecognizer> Zgłasza to zdarzenie, gdy będzie gotowy do akceptowania modyfikacje.</span><span class="sxs-lookup"><span data-stu-id="4988b-316">The <xref:System.Speech.Recognition.SpeechRecognizer> raises this event when it is ready to accept modifications.</span></span>  
  
 <span data-ttu-id="4988b-317">Podczas tworzenia obiektu delegowanego dla <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</span><span class="sxs-lookup"><span data-stu-id="4988b-317">When you create a delegate for a <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event, you identify the method that will handle the event.</span></span> <span data-ttu-id="4988b-318">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-318">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="4988b-319">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</span><span class="sxs-lookup"><span data-stu-id="4988b-319">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="4988b-320">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz [zdarzenia i delegatów](http://go.microsoft.com/fwlink/?LinkId=162418).</span><span class="sxs-lookup"><span data-stu-id="4988b-320">For more information about event-handler delegates, see [Events and Delegates](http://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-321">W poniższym przykładzie przedstawiono aplikacji konsoli, który ładuje i zwalnia <xref:System.Speech.Recognition.Grammar> obiektów.</span><span class="sxs-lookup"><span data-stu-id="4988b-321">The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects.</span></span> <span data-ttu-id="4988b-322">Aplikacja używa <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> metoda żądania wstrzymania, więc może ona odbierać aktualizacji aparatu rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-322">The application uses the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method to request the speech recognition engine to pause so it can receive an update.</span></span> <span data-ttu-id="4988b-323">Aplikacja, a następnie ładuje lub zwalnia <xref:System.Speech.Recognition.Grammar> obiektu.</span><span class="sxs-lookup"><span data-stu-id="4988b-323">The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.</span></span>  
  
 <span data-ttu-id="4988b-324">W każdej aktualizacji obsługi dla <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> zapisuje zdarzenia, nazwy i stan aktualnie załadowanych <xref:System.Speech.Recognition.Grammar> obiekty do konsoli.</span><span class="sxs-lookup"><span data-stu-id="4988b-324">At each update, a handler for <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console.</span></span> <span data-ttu-id="4988b-325">Jak gramatyki jest załadowany i zwolniony, najpierw rozpoznaje nazwy farmy zwierząt, nazwy farmy zwierząt oraz nazwy owoców, a następnie tylko nazwy owoców.</span><span class="sxs-lookup"><span data-stu-id="4988b-325">As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Create the first grammar - Farm.  
      Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
      GrammarBuilder farm = new GrammarBuilder(animals);  
      Grammar farmAnimals = new Grammar(farm);  
      farmAnimals.Name = "Farm";  
  
      // Create the second grammar - Fruit.  
      Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
      GrammarBuilder favorite = new GrammarBuilder(fruit);  
      Grammar favoriteFruit = new Grammar(favorite);  
      favoriteFruit.Name = "Fruit";  
  
      // Attach event handlers.  
      recognizer.SpeechRecognized +=  
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.RecognizerUpdateReached +=  
        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
      recognizer.StateChanged +=   
        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
      // Load the Farm grammar.  
      recognizer.LoadGrammar(farmAnimals);  
      Console.WriteLine("Grammar Farm is loaded");  
  
      // Pause to recognize farm animals.  
      Thread.Sleep(7000);  
      Console.WriteLine();  
  
      // Request an update and load the Fruit grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.LoadGrammarAsync(favoriteFruit);  
      Thread.Sleep(5000);  
  
      // Request an update and unload the Farm grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.UnloadGrammar(farmAnimals);  
      Thread.Sleep(5000);  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  
    // At the update, get the names and enabled status of the currently loaded grammars.  
    public static void recognizer_RecognizerUpdateReached(  
      object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  Grammar {0} is loaded and is {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("  Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
      </Docs>
    </Member>
    <MemberGroup MemberName="RequestRecognizerUpdate">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-326">Żądania, że udostępniony aparat rozpoznawania wstrzymać i zaktualizuj jego stan.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-326">Requests that the shared recognizer pause and update its state.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-327">Użyj tej metody, aby zsynchronizować zmiany udostępniony aparat rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-327">Use this method to synchronize changes to the shared recognizer.</span></span> <span data-ttu-id="4988b-328">Na przykład, jeśli załadować lub zwolnić gramatyki rozpoznawania mowy, gdy aparat rozpoznawania jest przetwarzania danych wejściowych, ta metoda i <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> zdarzenie, aby zsynchronizować Twoje zachowanie aplikacji z stanem aparat rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-328">For example, if you load or unload a speech recognition grammar while the recognizer is processing input, use this method and the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event to synchronize your application behavior with the state of the recognizer.</span></span>  
  
 <span data-ttu-id="4988b-329">Gdy ta metoda jest wywoływana, aparat rozpoznawania wstrzymuje lub zakończeniu operacji asynchronicznych i generuje <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> zdarzeń.</span><span class="sxs-lookup"><span data-stu-id="4988b-329">When this method is called, the recognizer pauses or completes asynchronous operations and generates a <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event.</span></span> <span data-ttu-id="4988b-330">A <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> obsługi zdarzeń można zmodyfikować stanu rozpoznawania Between operacji rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-330">A <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event handler can then modify the state of the recognizer in between recognition operations.</span></span>  
  
 <span data-ttu-id="4988b-331">Gdy ta metoda jest wywoływana:</span><span class="sxs-lookup"><span data-stu-id="4988b-331">When this method is called:</span></span>  
  
-   <span data-ttu-id="4988b-332">Jeśli aparat rozpoznawania nie przetwarza danych wejściowych, aparat rozpoznawania natychmiast generuje <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> zdarzeń.</span><span class="sxs-lookup"><span data-stu-id="4988b-332">If the recognizer is not processing input, the recognizer immediately generates the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event.</span></span>  
  
-   <span data-ttu-id="4988b-333">Jeśli aparat rozpoznawania jest przetwarzania danych wejściowych, który składa się z wyciszenia lub hałas w tle, aparat rozpoznawania wstrzymuje działanie rozpoznawania i generuje <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> zdarzeń.</span><span class="sxs-lookup"><span data-stu-id="4988b-333">If the recognizer is processing input that consists of silence or background noise, the recognizer pauses the recognition operation and generates the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event.</span></span>  
  
-   <span data-ttu-id="4988b-334">Jeśli aparat rozpoznawania jest przetwarzania danych wejściowych, która składa się z wyciszenia lub hałas w tle, aparat rozpoznawania zakończeniu operacji rozpoznawania, a następnie generuje <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> zdarzeń.</span><span class="sxs-lookup"><span data-stu-id="4988b-334">If the recognizer is processing input that does not consist of silence or background noise, the recognizer completes the recognition operation and then generates the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event.</span></span>  
  
 <span data-ttu-id="4988b-335">Gdy aparat rozpoznawania jest obsługa <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> zdarzeń:</span><span class="sxs-lookup"><span data-stu-id="4988b-335">While the recognizer is handling the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event:</span></span>  
  
-   <span data-ttu-id="4988b-336">Aparat rozpoznawania nie przetwarza danych wejściowych, a wartość <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> właściwości jest taka sama.</span><span class="sxs-lookup"><span data-stu-id="4988b-336">The recognizer does not process input, and the value of the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> property remains the same.</span></span>  
  
-   <span data-ttu-id="4988b-337">Aparat rozpoznawania kontynuuje zbieranie danych wejściowych i wartość <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> można zmienić właściwości.</span><span class="sxs-lookup"><span data-stu-id="4988b-337">The recognizer continues to collect input, and the value of the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> property can change.</span></span>  
  
 <span data-ttu-id="4988b-338">Aby określić, czy udostępniony aparat rozpoznawania wstrzymuje operacji rozpoznawania, podczas gdy aplikacja jest obsługa <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> zdarzenia, użyj <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A> właściwości.</span><span class="sxs-lookup"><span data-stu-id="4988b-338">To change whether the shared recognizer pauses recognition operations while an application is handling a <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> event, use the <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A> property.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-339">W poniższym przykładzie przedstawiono aplikacji konsoli, który ładuje i zwalnia <xref:System.Speech.Recognition.Grammar> obiektów.</span><span class="sxs-lookup"><span data-stu-id="4988b-339">The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects.</span></span> <span data-ttu-id="4988b-340">Aplikacja używa <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> metoda żądania wstrzymania, więc może ona odbierać aktualizacji aparatu rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-340">The application uses the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method to request the speech recognition engine to pause so it can receive an update.</span></span> <span data-ttu-id="4988b-341">Aplikacja, a następnie ładuje lub zwalnia <xref:System.Speech.Recognition.Grammar> obiektu.</span><span class="sxs-lookup"><span data-stu-id="4988b-341">The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.</span></span>  
  
 <span data-ttu-id="4988b-342">W każdej aktualizacji obsługi dla <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> zapisuje zdarzenia, nazwy i stan aktualnie załadowanych <xref:System.Speech.Recognition.Grammar> obiekty do konsoli.</span><span class="sxs-lookup"><span data-stu-id="4988b-342">At each update, a handler for <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console.</span></span> <span data-ttu-id="4988b-343">Jak gramatyki jest załadowany i zwolniony, najpierw rozpoznaje nazwy farmy zwierząt, nazwy farmy zwierząt oraz nazwy owoców, a następnie tylko nazwy owoców.</span><span class="sxs-lookup"><span data-stu-id="4988b-343">As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</span></span>  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine and configure its input.  
      recognizer = new SpeechRecognizer();  
  
      // Create the first grammar - Farm.  
      Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
      GrammarBuilder farm = new GrammarBuilder(animals);  
      Grammar farmAnimals = new Grammar(farm);  
      farmAnimals.Name = "Farm";  
  
      // Create the second grammar - Fruit.  
      Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
      GrammarBuilder favorite = new GrammarBuilder(fruit);  
      Grammar favoriteFruit = new Grammar(favorite);  
      favoriteFruit.Name = "Fruit";  
  
      // Attach event handlers.  
      recognizer.SpeechRecognized +=  
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.RecognizerUpdateReached +=  
        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
  
      // Check to see if recognizer is loaded, wait if it is not loaded.  
      if (recognizer.State != RecognizerState.Listening)  
      {  
        Thread.Sleep(5000);  
  
        // Put recognizer in listening state.  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
  
      // Load the Farm grammar.  
      recognizer.LoadGrammar(farmAnimals);  
      Console.WriteLine("Grammar Farm is loaded");  
  
      // Pause to recognize farm animals.  
      Thread.Sleep(7000);  
      Console.WriteLine();  
  
      // Request an update and load the Fruit grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.LoadGrammarAsync(favoriteFruit);  
      Thread.Sleep(5000);  
  
      // Request an update and unload the Farm grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.UnloadGrammar(farmAnimals);  
      Thread.Sleep(5000);  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    public static void recognizer_RecognizerUpdateReached(object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      // At the update, get the names and enabled status of the currently loaded grammars.  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  Grammar {0} is loaded and is {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("  Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
      </Docs>
    </MemberGroup>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate();" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
          <span data-ttu-id="4988b-344">Żądania, że udostępniony aparat rozpoznawania wstrzymać i zaktualizuj jego stan.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-344">Requests that the shared recognizer pause and update its state.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-345">Gdy aparat rozpoznawania generuje <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> zdarzenia <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> właściwość <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> jest `null`.</span><span class="sxs-lookup"><span data-stu-id="4988b-345">When the recognizer generates the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event, the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> property of the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> is `null`.</span></span>  
  
 <span data-ttu-id="4988b-346">Aby dostarczyć token użytkownika, użyj <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> lub <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> metody.</span><span class="sxs-lookup"><span data-stu-id="4988b-346">To provide a user token, use the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> or <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method.</span></span> <span data-ttu-id="4988b-347">Aby określić przesunięcie pozycji audio, użyj <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> metody.</span><span class="sxs-lookup"><span data-stu-id="4988b-347">To specify an audio position offset, use the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate (object userToken);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate(object userToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate (userToken As Object)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate(System::Object ^ userToken);" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="userToken" Type="System.Object" />
      </Parameters>
      <Docs>
        <param name="userToken">
          <span data-ttu-id="4988b-348">Informacje zdefiniowane przez użytkownika, zawierający informacje dla tej operacji.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-348">User-defined information that contains information for the operation.</span>
          </span>
        </param>
        <summary>
          <span data-ttu-id="4988b-349">Udostępniony aparat rozpoznawania wstrzymać i zaktualizuj jego stan i zapewnia token użytkownika skojarzonego zdarzenia, żądania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-349">Requests that the shared recognizer pause and update its state and provides a user token for the associated event.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-350">Gdy aparat rozpoznawania generuje <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> zdarzenia <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> właściwość <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> zawiera wartość `userToken` parametru.</span><span class="sxs-lookup"><span data-stu-id="4988b-350">When the recognizer generates the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event, the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> property of the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> contains the value of the `userToken` parameter.</span></span>  
  
 <span data-ttu-id="4988b-351">Aby określić przesunięcie pozycji audio, użyj <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> metody.</span><span class="sxs-lookup"><span data-stu-id="4988b-351">To specify an audio position offset, use the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate (object userToken, TimeSpan audioPositionAheadToRaiseUpdate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate(object userToken, valuetype System.TimeSpan audioPositionAheadToRaiseUpdate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate (userToken As Object, audioPositionAheadToRaiseUpdate As TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate(System::Object ^ userToken, TimeSpan audioPositionAheadToRaiseUpdate);" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="userToken" Type="System.Object" />
        <Parameter Name="audioPositionAheadToRaiseUpdate" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="userToken">
          <span data-ttu-id="4988b-352">Informacje zdefiniowane przez użytkownika, zawierający informacje dla tej operacji.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-352">User-defined information that contains information for the operation.</span>
          </span>
        </param>
        <param name="audioPositionAheadToRaiseUpdate">
          <span data-ttu-id="4988b-353">Przesunięcie od bieżącej <see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /> opóźnienia żądania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-353">The offset from the current <see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /> to delay the request.</span>
          </span>
        </param>
        <summary>
          <span data-ttu-id="4988b-354">Udostępniony aparat rozpoznawania wstrzymać i zaktualizuj jego stan i zapewnia przesunięcia i token użytkownika skojarzonego zdarzenia, żądania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-354">Requests that the shared recognizer pause and update its state and provides an offset and a user token for the associated event.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-355">Aparat rozpoznawania nie zainicjował żądanie aktualizacji aparatu rozpoznawania do aparat rozpoznawania <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> jest równe bieżącego <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> plus wartość `audioPositionAheadToRaiseUpdate` parametru.</span><span class="sxs-lookup"><span data-stu-id="4988b-355">The recognizer does not initiate the recognizer update request until the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> equals the current <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> plus the value of the `audioPositionAheadToRaiseUpdate` parameter.</span></span>  
  
 <span data-ttu-id="4988b-356">Gdy aparat rozpoznawania generuje <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> zdarzenia <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> właściwość <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> zawiera wartość `userToken` parametru.</span><span class="sxs-lookup"><span data-stu-id="4988b-356">When the recognizer generates the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event, the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> property of the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> contains the value of the `userToken` parameter.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="SpeechDetected">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; SpeechDetected;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechDetectedEventArgs&gt; SpeechDetected" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechDetected As EventHandler(Of SpeechDetectedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechDetectedEventArgs ^&gt; ^ SpeechDetected;" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-357">Występuje, gdy aparat rozpoznawania wykrywa danych wejściowych, którą można zidentyfikować jako mowy.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-357">Occurs when the recognizer detects input that it can identify as speech.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-358">Udostępniony aparat rozpoznawania może wiązać się z tym zdarzeniem w odpowiedzi jako danych wejściowych.</span><span class="sxs-lookup"><span data-stu-id="4988b-358">The shared recognizer can raise this event in response to input.</span></span> <span data-ttu-id="4988b-359"><xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A> Właściwości skojarzonego <xref:System.Speech.Recognition.SpeechDetectedEventArgs> obiektu wskazuje lokalizację, w przypadku wykrycia przez aparat rozpoznawania mowy strumień wejściowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-359">The <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A> property of the associated <xref:System.Speech.Recognition.SpeechDetectedEventArgs> object indicates location in the input stream where the recognizer detected speech.</span></span> <span data-ttu-id="4988b-360">Aby uzyskać więcej informacji, zobacz <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> i <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> właściwości i <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> i <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> metody.</span><span class="sxs-lookup"><span data-stu-id="4988b-360">For more information see the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> and <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> properties and the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> and <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> methods.</span></span>  
  
 <span data-ttu-id="4988b-361">Podczas tworzenia obiektu delegowanego dla <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</span><span class="sxs-lookup"><span data-stu-id="4988b-361">When you create a delegate for a <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> event, you identify the method that will handle the event.</span></span> <span data-ttu-id="4988b-362">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-362">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="4988b-363">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</span><span class="sxs-lookup"><span data-stu-id="4988b-363">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="4988b-364">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz [zdarzenia i delegatów](http://go.microsoft.com/fwlink/?LinkId=162418).</span><span class="sxs-lookup"><span data-stu-id="4988b-364">For more information about event-handler delegates, see [Events and Delegates](http://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-365">Poniższy przykład jest częścią aplikacji konsoli dotyczące wybierania miast źródło i miejsce docelowe w locie.</span><span class="sxs-lookup"><span data-stu-id="4988b-365">The following example is part of a console application for choosing origin and destination cities for a flight.</span></span> <span data-ttu-id="4988b-366">Aplikacja rozpoznaje fraz, takie jak "Chcę udać z Miami do Chicago."</span><span class="sxs-lookup"><span data-stu-id="4988b-366">The application recognizes phrases such as "I want to fly from Miami to Chicago."</span></span>  <span data-ttu-id="4988b-367">W przykładzie użyto <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> zdarzeń do raportu <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> każdego mowy czas wykrycia.</span><span class="sxs-lookup"><span data-stu-id="4988b-367">The example uses the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> event to report the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> each time speech is detected.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        Choices cities = new Choices(new string[] {   
          "Los Angeles", "New York", "Chicago", "San Francisco", "Miami", "Dallas" });  
  
        GrammarBuilder gb = new GrammarBuilder();  
        gb.Append("I would like to fly from");  
        gb.Append(cities);  
        gb.Append("to");  
        gb.Append(cities);  
  
        // Create a Grammar object and load it to the recognizer.  
        Grammar g = new Grammar(gb);  
        g.Name = ("City Chooser");  
        recognizer.LoadGrammarAsync(g);  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechDetected +=   
          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechDetected event.  
    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine("Speech detected at AudioPosition = {0}", e.AudioPosition);  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechDetectedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="SpeechHypothesized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; SpeechHypothesized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; SpeechHypothesized" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeechHypothesized As EventHandler(Of SpeechHypothesizedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechHypothesizedEventArgs ^&gt; ^ SpeechHypothesized;" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-368">Występuje, gdy aparat rozpoznawania rozpoznał wyrazów, które mogą być składnika wiele wyrażeń pełną w gramatyce.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-368">Occurs when the recognizer has recognized a word or words that may be a component of multiple complete phrases in a grammar.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-369">Udostępniony aparat rozpoznawania można Zgłoś to zdarzenie, gdy dane wejściowe są niejednoznaczne.</span><span class="sxs-lookup"><span data-stu-id="4988b-369">The shared recognizer can raise this event when the input is ambiguous.</span></span> <span data-ttu-id="4988b-370">Na przykład dla gramatyki rozpoznawania mowy, która obsługuje rozpoznawanie albo "nowe gier, skontaktuj" lub "nowej gry", "nowe gier, skontaktuj" jest wejściem jednoznaczne i "nowej gry" jest niejednoznaczny danych wejściowych.</span><span class="sxs-lookup"><span data-stu-id="4988b-370">For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</span></span>  
  
 <span data-ttu-id="4988b-371">Podczas tworzenia obiektu delegowanego dla <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</span><span class="sxs-lookup"><span data-stu-id="4988b-371">When you create a delegate for a <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> event, you identify the method that will handle the event.</span></span> <span data-ttu-id="4988b-372">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-372">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="4988b-373">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</span><span class="sxs-lookup"><span data-stu-id="4988b-373">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="4988b-374">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz [zdarzenia i delegatów](http://go.microsoft.com/fwlink/?LinkId=162418).</span><span class="sxs-lookup"><span data-stu-id="4988b-374">For more information about event-handler delegates, see [Events and Delegates](http://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-375">Poniższy przykład rozpoznaje fraz, takie jak "Wyświetlana lista artystów w kategorii jazz".</span><span class="sxs-lookup"><span data-stu-id="4988b-375">The following example recognizes phrases such as "Display the list of artists in the jazz category".</span></span> <span data-ttu-id="4988b-376">W przykładzie użyto <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> zdarzeń, aby wyświetlić fragmenty niepełne wyrażenie w konsoli, jak są rozpoznawane.</span><span class="sxs-lookup"><span data-stu-id="4988b-376">The example uses the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> event to display incomplete phrase fragments in the console as they are recognized.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        //  Create lists of alternative choices.  
        Choices listTypes = new Choices(new string[] { "albums", "artists" });  
        Choices genres = new Choices(new string[] {   
          "blues", "classical", "gospel", "jazz", "rock" });  
  
        //  Create a GrammarBuilder object and assemble the grammar components.  
        GrammarBuilder mediaMenu = new GrammarBuilder("Display the list of");  
        mediaMenu.Append(listTypes);  
        mediaMenu.Append("in the");  
        mediaMenu.Append(genres);  
        mediaMenu.Append("category.");  
  
        //  Build a Grammar object from the GrammarBuilder.  
        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  
        mediaMenuGrammar.Name = "Media Chooser";  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.SpeechHypothesized +=   
          new EventHandler<SpeechHypothesizedEventArgs>(recognizer_SpeechHypothesized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(mediaMenuGrammar);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechHypothesized event.  
    static void recognizer_SpeechHypothesized(object sender, SpeechHypothesizedEventArgs e)  
    {  
      Console.WriteLine("Speech hypothesized: " + e.Result.Text);  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechHypothesizedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognitionRejected">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; SpeechRecognitionRejected;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; SpeechRecognitionRejected" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechRecognitionRejected As EventHandler(Of SpeechRecognitionRejectedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechRecognitionRejectedEventArgs ^&gt; ^ SpeechRecognitionRejected;" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-377">Występuje, gdy aparat rozpoznawania otrzymuje dane wejściowe, który nie pasuje do żadnego gramatyki rozpoznawania mowy, który ma on załadowany.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-377">Occurs when the recognizer receives input that does not match any of the speech recognition grammars it has loaded.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-378">Udostępniony aparat rozpoznawania zgłasza to zdarzenie, gdy ustali, że dane wejściowe nie jest zgodna z wystarczający poziom zaufania żadnego gramatyki rozpoznawania mowy załadować.</span><span class="sxs-lookup"><span data-stu-id="4988b-378">The shared recognizer raises this event if it determines that input does not match with sufficient confidence any of the loaded speech recognition grammars.</span></span> <span data-ttu-id="4988b-379"><xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> Właściwość <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> zawiera odrzucone <xref:System.Speech.Recognition.RecognitionResult> obiektu.</span><span class="sxs-lookup"><span data-stu-id="4988b-379">The <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> property of the <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> contains the rejected <xref:System.Speech.Recognition.RecognitionResult> object.</span></span>  
  
 <span data-ttu-id="4988b-380">Progi zaufania udostępniony aparat rozpoznawania zarządza <xref:System.Speech.Recognition.SpeechRecognizer>, są skojarzone z profilem użytkownika i przechowywane w rejestrze systemu Windows.</span><span class="sxs-lookup"><span data-stu-id="4988b-380">Confidence thresholds for the shared recognizer, managed by <xref:System.Speech.Recognition.SpeechRecognizer>, are associated with a user profile and stored in the Windows registry.</span></span> <span data-ttu-id="4988b-381">Aplikacje nie należy zapisać zmiany w rejestrze dla właściwości udostępniony aparat rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-381">Applications should not write changes to the registry for the properties of the shared recognizer.</span></span>  
  
 <span data-ttu-id="4988b-382">Podczas tworzenia obiektu delegowanego dla <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</span><span class="sxs-lookup"><span data-stu-id="4988b-382">When you create a delegate for a <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> event, you identify the method that will handle the event.</span></span> <span data-ttu-id="4988b-383">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-383">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="4988b-384">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</span><span class="sxs-lookup"><span data-stu-id="4988b-384">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="4988b-385">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz [zdarzenia i delegatów](http://go.microsoft.com/fwlink/?LinkId=162418).</span><span class="sxs-lookup"><span data-stu-id="4988b-385">For more information about event-handler delegates, see [Events and Delegates](http://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-386">Poniższy przykład rozpoznaje "wyrażenia takie jak wyświetlać listę artystów w kategorii jazz" lub "gospel albumów".</span><span class="sxs-lookup"><span data-stu-id="4988b-386">The following example recognizes phrases such as "Display the list of artists in the jazz category" or "Display albums gospel".</span></span> <span data-ttu-id="4988b-387">W przykładzie użyto obsługi dla <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> zdarzeń, aby wyświetlić powiadomienie w konsoli podczas wprowadzania mowy nie można dopasować do zawartości gramatyki wystarczający poziom zaufania, aby wygenerować pomyślne rozpoznawanie.</span><span class="sxs-lookup"><span data-stu-id="4988b-387">The example uses a handler for the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient confidence to produce a successful recognition.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        //  Create lists of alternative choices.  
        Choices listTypes = new Choices(new string[] { "albums", "artists" });  
        Choices genres = new Choices(new string[] {   
          "blues", "classical", "gospel", "jazz", "rock" });  
  
        //  Create a GrammarBuilder object and assemble the grammar components.  
        GrammarBuilder mediaMenu = new GrammarBuilder("Display");  
        mediaMenu.Append("the list of", 0, 1);  
        mediaMenu.Append(listTypes);  
        mediaMenu.Append("in the", 0, 1);  
        mediaMenu.Append(genres);  
        mediaMenu.Append("category", 0, 1);  
  
        //  Build a Grammar object from the GrammarBuilder.  
        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  
        mediaMenuGrammar.Name = "Media Chooser";  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.SpeechRecognitionRejected +=   
          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(mediaMenuGrammar);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechRecognitionRejected event.  
    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine("Speech input was rejected.");  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; SpeechRecognized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechRecognizedEventArgs&gt; SpeechRecognized" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechRecognized As EventHandler(Of SpeechRecognizedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechRecognizedEventArgs ^&gt; ^ SpeechRecognized;" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-388">Występuje, gdy aparat rozpoznawania otrzymuje dane wejściowe, który pasuje do jednej z jego gramatyki rozpoznawania mowy.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-388">Occurs when the recognizer receives input that matches one of its speech recognition grammars.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-389">Generuje aparatu rozpoznawania `SpeechRecognized` zdarzeń, gdy ustali bez obaw wystarczające, czy dane wejściowe pasujący gramatyki rozpoznawania mowy załadowany i włączona.</span><span class="sxs-lookup"><span data-stu-id="4988b-389">The recognizer raises the `SpeechRecognized` event if it determines with sufficient confidence that input matches one of the loaded and enabled speech recognition grammars.</span></span> <span data-ttu-id="4988b-390"><xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> Właściwość <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> zawiera zaakceptowane <xref:System.Speech.Recognition.RecognitionResult> obiektu.</span><span class="sxs-lookup"><span data-stu-id="4988b-390">The <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> property of the <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> contains the accepted <xref:System.Speech.Recognition.RecognitionResult> object.</span></span>  
  
 <span data-ttu-id="4988b-391">Progi zaufania udostępniony aparat rozpoznawania zarządza <xref:System.Speech.Recognition.SpeechRecognizer>, są skojarzone z profilem użytkownika i przechowywane w rejestrze systemu Windows.</span><span class="sxs-lookup"><span data-stu-id="4988b-391">Confidence thresholds for the shared recognizer, managed by <xref:System.Speech.Recognition.SpeechRecognizer>, are associated with a user profile and stored in the Windows registry.</span></span> <span data-ttu-id="4988b-392">Aplikacje nie należy zapisać zmiany w rejestrze dla właściwości udostępniony aparat rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-392">Applications should not write changes to the registry for the properties of the shared recognizer.</span></span>  
  
 <span data-ttu-id="4988b-393">Gdy aparat rozpoznawania otrzymuje wejścia odpowiadającego gramatyki, <xref:System.Speech.Recognition.Grammar> może wiązać się z obiektu <xref:System.Speech.Recognition.Grammar.SpeechRecognized> zdarzeń.</span><span class="sxs-lookup"><span data-stu-id="4988b-393">When the recognizer receives input that matches a grammar, the <xref:System.Speech.Recognition.Grammar> object can raise the <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event.</span></span> <span data-ttu-id="4988b-394"><xref:System.Speech.Recognition.Grammar> Obiektu <xref:System.Speech.Recognition.Grammar.SpeechRecognized> zdarzenie jest wywoływane przed rozpoznawania mowy <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> zdarzeń.</span><span class="sxs-lookup"><span data-stu-id="4988b-394">The <xref:System.Speech.Recognition.Grammar> object's <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event is raised prior to the speech recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> event.</span></span>  
  
 <span data-ttu-id="4988b-395">Podczas tworzenia obiektu delegowanego dla <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</span><span class="sxs-lookup"><span data-stu-id="4988b-395">When you create a delegate for a <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> event, you identify the method that will handle the event.</span></span> <span data-ttu-id="4988b-396">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-396">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="4988b-397">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</span><span class="sxs-lookup"><span data-stu-id="4988b-397">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="4988b-398">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz [zdarzenia i delegatów](http://go.microsoft.com/fwlink/?LinkId=162418).</span><span class="sxs-lookup"><span data-stu-id="4988b-398">For more information about event-handler delegates, see [Events and Delegates](http://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-399">Poniższy przykład jest częścią aplikacji konsoli, który ładuje gramatyki rozpoznawania mowy i pokazuje wejście mowy udostępniony aparat rozpoznawania wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-399">The following example is part of a console application that loads a speech recognition grammar and demonstrates speech input to the shared recognizer, the associated recognition results, and the associated events raised by the speech recognizer.</span></span> <span data-ttu-id="4988b-400">Jeśli rozpoznawania mowy nie jest uruchomiona, następnie uruchomienie tej aplikacji powoduje również uruchomienie rozpoznawania mowy.</span><span class="sxs-lookup"><span data-stu-id="4988b-400">If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</span></span>  
  
 <span data-ttu-id="4988b-401">Używany danych wejściowych, takie jak "Chcę udać z Chicago do Miami" wyzwoli <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> zdarzeń.</span><span class="sxs-lookup"><span data-stu-id="4988b-401">Spoken input such as "I want to fly from Chicago to Miami" will trigger a <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> event.</span></span> <span data-ttu-id="4988b-402">Mówiąc frazę "Udać me z Houston do Chicago" nie powoduje wyzwolenia <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> zdarzeń.</span><span class="sxs-lookup"><span data-stu-id="4988b-402">Speaking the phrase "Fly me from Houston to Chicago " will not trigger a <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> event.</span></span>  
  
 <span data-ttu-id="4988b-403">W przykładzie użyto obsługi dla <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> zdarzeń do wyświetlenia pomyślnie rozpoznane fraz i semantyki zawierają w konsoli.</span><span class="sxs-lookup"><span data-stu-id="4988b-403">The example uses a handler for the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> event to display successfully recognized phrases and the semantics they contain in the console.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create SemanticResultValue objects that contain cities and airport codes.  
        SemanticResultValue chicago = new SemanticResultValue("Chicago", "ORD");  
        SemanticResultValue boston = new SemanticResultValue("Boston", "BOS");  
        SemanticResultValue miami = new SemanticResultValue("Miami", "MIA");  
        SemanticResultValue dallas = new SemanticResultValue("Dallas", "DFW");  
  
        // Create a Choices object and add the SemanticResultValue objects, using  
        // implicit conversion from SemanticResultValue to GrammarBuilder  
        Choices cities = new Choices();  
        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  
  
        // Build the phrase and add SemanticResultKeys.  
        GrammarBuilder chooseCities = new GrammarBuilder();  
        chooseCities.Append("I want to fly from");  
        chooseCities.Append(new SemanticResultKey("origin", cities));  
        chooseCities.Append("to");  
        chooseCities.Append(new SemanticResultKey("destination", cities));  
  
        // Build a Grammar object from the GrammarBuilder.  
        Grammar bookFlight = new Grammar(chooseCities);  
        bookFlight.Name = "Book Flight";  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(bookFlight);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
      Console.WriteLine();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized:  " + e.Result.Text);  
      Console.WriteLine();  
      Console.WriteLine("Semantic results:");  
      Console.WriteLine("  The flight origin is " + e.Result.Semantics["origin"].Value);  
      Console.WriteLine("  The flight destination is " + e.Result.Semantics["destination"].Value);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
      </Docs>
    </Member>
    <Member MemberName="State">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizerState State { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.RecognizerState State" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.State" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property State As RecognizerState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizerState State { System::Speech::Recognition::RecognizerState get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-404">Pobiera stan <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> obiektu.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-404">Gets the state of a <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> object.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="4988b-405">Stan <see langword="SpeechRecognizer" /> obiektu.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-405">The state of the <see langword="SpeechRecognizer" /> object.</span>
          </span>
        </value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-406">Ta właściwość tylko do odczytu wskazuje, czy udostępniony aparat rozpoznawania znajdują się w systemie Windows jest `Stopped` lub `Listening` stanu.</span><span class="sxs-lookup"><span data-stu-id="4988b-406">This read-only property indicates whether the shared recognizer resident in Windows is in the `Stopped` or the `Listening` state.</span></span> <span data-ttu-id="4988b-407">Aby uzyskać więcej informacji, zobacz <xref:System.Speech.Recognition.RecognizerState> wyliczenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-407">For more information, see the <xref:System.Speech.Recognition.RecognizerState> enumeration.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerState" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
      </Docs>
    </Member>
    <Member MemberName="StateChanged">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; StateChanged;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.StateChangedEventArgs&gt; StateChanged" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
      <MemberSignature Language="VB.NET" Value="Public Event StateChanged As EventHandler(Of StateChangedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::StateChangedEventArgs ^&gt; ^ StateChanged;" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="4988b-408">Występuje, gdy stan działania aparatu rozpoznawania technologia mowy pulpitu systemu Windows.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-408">Occurs when the running state of the Windows Desktop Speech Technology recognition engine changes.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-409">Udostępniony aparat rozpoznawania zgłasza to zdarzenie po zmianie stanu rozpoznawania mowy systemu Windows do <xref:System.Speech.Recognition.RecognizerState.Listening> lub <xref:System.Speech.Recognition.RecognizerState.Stopped> stanu.</span><span class="sxs-lookup"><span data-stu-id="4988b-409">The shared recognizer raises this event when the state of Windows Speech Recognition changes to the <xref:System.Speech.Recognition.RecognizerState.Listening> or <xref:System.Speech.Recognition.RecognizerState.Stopped> state.</span></span>  
  
 <span data-ttu-id="4988b-410">Aby pobrać stan udostępniony aparat rozpoznawania w czasie zdarzenia, użyj <xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A> właściwości skojarzonego <xref:System.Speech.Recognition.StateChangedEventArgs>.</span><span class="sxs-lookup"><span data-stu-id="4988b-410">To get the state of the shared recognizer at the time of the event, use the <xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A> property of the associated <xref:System.Speech.Recognition.StateChangedEventArgs>.</span></span> <span data-ttu-id="4988b-411">Aby uzyskać bieżący stan udostępniony aparat rozpoznawania, należy użyć aparat rozpoznawania <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> właściwości.</span><span class="sxs-lookup"><span data-stu-id="4988b-411">To get the current state of the shared recognizer, use the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> property.</span></span>  
  
 <span data-ttu-id="4988b-412">Podczas tworzenia obiektu delegowanego dla <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> zdarzenia, należy określić metodę, która obsłuży zdarzenie.</span><span class="sxs-lookup"><span data-stu-id="4988b-412">When you create a delegate for a <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> event, you identify the method that will handle the event.</span></span> <span data-ttu-id="4988b-413">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</span><span class="sxs-lookup"><span data-stu-id="4988b-413">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="4988b-414">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</span><span class="sxs-lookup"><span data-stu-id="4988b-414">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="4988b-415">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz [zdarzenia i delegatów](http://go.microsoft.com/fwlink/?LinkId=162418).</span><span class="sxs-lookup"><span data-stu-id="4988b-415">For more information about event-handler delegates, see [Events and Delegates](http://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="4988b-416">Poniższy przykład tworzy aparat rozpoznawania mowy udostępnionego, a następnie tworzy dwa typy gramatyki rozpoznawania słów i akceptowania dyktowania wolne.</span><span class="sxs-lookup"><span data-stu-id="4988b-416">The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</span></span> <span data-ttu-id="4988b-417">Przykład asynchronicznie ładuje wszystkie utworzone gramatyki do aparatu rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-417">The example asynchronously loads all the created grammars to the recognizer.</span></span>  <span data-ttu-id="4988b-418">Program obsługi <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> używa zdarzeń <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> metodę put rozpoznawanie systemu Windows w trybie "nasłuchiwania".</span><span class="sxs-lookup"><span data-stu-id="4988b-418">A handler for the <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> event uses the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> method to put Windows Recognition in "listening" mode.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted += new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the SpeechRecognized event.  
      recognizer.SpeechRecognized += new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
      // Add a handler for the StateChanged event.  
      recognizer.StateChanged += new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
      // Create "yesno" grammar.  
      Choices yesChoices = new Choices(new string[] { "yes", "yup", "yah}" });  
      SemanticResultValue yesValue =  
          new SemanticResultValue(yesChoices, (bool)true);  
      Choices noChoices = new Choices(new string[] { "no", "nope", "nah" });  
      SemanticResultValue noValue = new SemanticResultValue(noChoices, (bool)false);  
      SemanticResultKey yesNoKey =  
          new SemanticResultKey("yesno", new Choices(new GrammarBuilder[] { yesValue, noValue }));  
      Grammar yesnoGrammar = new Grammar(yesNoKey);  
      yesnoGrammar.Name = "yesNo";  
  
      // Create "done" grammar.  
      Grammar doneGrammar =  
        new Grammar(new Choices(new string[] { "done", "exit", "quit", "stop" }));  
      doneGrammar.Name = "Done";  
  
      // Create dictation grammar.  
      Grammar dictation = new DictationGrammar();  
      dictation.Name = "Dictation";  
  
      // Load grammars to the recognizer.  
      recognizer.LoadGrammarAsync(yesnoGrammar);  
      recognizer.LoadGrammarAsync(doneGrammar);  
      recognizer.LoadGrammarAsync(dictation);  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void  recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
     if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void  recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
     Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void  recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
     string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
      }  
  
      // Add exception handling code here.  
      Console.WriteLine("Grammar {0} {1} loaded.",  
      grammarName, (grammarLoaded) ? "is" : "is not");  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerState" />
        <altmember cref="T:System.Speech.Recognition.StateChangedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
      </Docs>
    </Member>
    <Member MemberName="UnloadAllGrammars">
      <MemberSignature Language="C#" Value="public void UnloadAllGrammars ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UnloadAllGrammars() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
      <MemberSignature Language="VB.NET" Value="Public Sub UnloadAllGrammars ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UnloadAllGrammars();" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
          <span data-ttu-id="4988b-419">Zwalnia wszystkich gramatykach rozpoznawanie mowy z udostępniony aparat rozpoznawania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-419">Unloads all speech recognition grammars from the shared recognizer.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-420">Aparat rozpoznawania jest obecnie asynchronicznie ładowania gramatyki, ta metoda oczekuje, aż gramatyki jest załadowane przed zwalnia wszystkie gramatyki aparat rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="4988b-420">If the recognizer is currently loading a grammar asynchronously, this method waits until the grammar is loaded, before it unloads all of the recognizer's grammars.</span></span>  
  
 <span data-ttu-id="4988b-421">Aby zwolnić określonego gramatyki, użyj <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A> metody.</span><span class="sxs-lookup"><span data-stu-id="4988b-421">To unload a specific grammar, use the <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="UnloadGrammar">
      <MemberSignature Language="C#" Value="public void UnloadGrammar (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UnloadGrammar(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UnloadGrammar(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar">
          <span data-ttu-id="4988b-422">Gramatyka do zwolnienia.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-422">The grammar to unload.</span>
          </span>
        </param>
        <summary>
          <span data-ttu-id="4988b-423">Zwalnia gramatyki rozpoznawania mowy określonego z udostępniony aparat rozpoznawania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="4988b-423">Unloads a specified speech recognition grammar from the shared recognizer.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="4988b-424">Jeśli aparat rozpoznawania jest uruchomiona, aplikacje muszą używać <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> wstrzymania aparat rozpoznawania mowy przed ładowania, zwalnianie, włączanie lub wyłączanie gramatyki.</span><span class="sxs-lookup"><span data-stu-id="4988b-424">If the recognizer is running, applications must use <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</span></span> <span data-ttu-id="4988b-425">Aby zwolnić wszystkich gramatykach, należy użyć <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A> metody.</span><span class="sxs-lookup"><span data-stu-id="4988b-425">To unload all grammars, use the <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
      </Docs>
    </Member>
  </Members>
</Type>