<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="RecognizeCompletedEventArgs.xml" source-language="en-US" target-language="pl-PL">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-15c36f0" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">02cd5861-7ce2-4a82-b358-31f8435a0ac51c9f1bb16857484c72c4d3a88b03a91be62a3a13.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1c9f1bb16857484c72c4d3a88b03a91be62a3a13</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/03/2018</xliffext:ms.lasthandoff>
      <xliffext:moniker_ids xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">netframework-4.5.1,netframework-4.5.2,netframework-4.5,netframework-4.6.1,netframework-4.6.2,netframework-4.6,netframework-4.7.1,netframework-4.7</xliffext:moniker_ids>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.RecognizeCompletedEventArgs">
          <source>Provides data for the <ph id="ph1">&lt;see langword="RecognizeCompleted" /&gt;</ph> event raised by a <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> or a <ph id="ph3">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Udostępnia dane dla <ph id="ph1">&lt;see langword="RecognizeCompleted" /&gt;</ph> zdarzenie zgłaszane przez <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> lub <ph id="ph3">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognizeCompletedEventArgs">
          <source>An instance of <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> is created when the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> or the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object raises its <ph id="ph4">`SpeechRecognized`</ph> event after completing a <ph id="ph5">`RecognizeAsync`</ph> operation.</source>
          <target state="translated">Wystąpienie <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> jest tworzone, gdy <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> lub <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> obiekt zgłasza jego <ph id="ph4">`SpeechRecognized`</ph> zdarzeń po zakończeniu <ph id="ph5">`RecognizeAsync`</ph> operacji.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognizeCompletedEventArgs">
          <source>For more information about speech recognition events, see <bpt id="p1">[</bpt>Using Speech Recognition Events<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji o zdarzeniach rozpoznawania mowy, zobacz <bpt id="p1">[</bpt>przy użyciu zdarzenia rozpoznawania mowy<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept>.</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognizeCompletedEventArgs">
          <source>The following example performs asynchronous speech recognition on a speech recognition grammar, using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType&gt;</ph> method with the in-process recognizer.</source>
          <target state="translated">Poniższy przykład przeprowadzają rozpoznawanie mowy asynchroniczne gramatyki rozpoznawania mowy przy użyciu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType&gt;</ph> metody z wewnątrzprocesowy aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognizeCompletedEventArgs">
          <source>The example uses <ph id="ph1">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> objects to create the speech recognition grammar before building it into a <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">W przykładzie użyto <ph id="ph1">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> obiektów można utworzyć gramatyki rozpoznawania mowy przed zbudowaniem go do <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.RecognizeCompletedEventArgs">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType&gt;</ph> event outputs information about the recognition operation to the console.</source>
          <target state="translated">Program obsługi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType&gt;</ph> zdarzeń wyświetla informacje na temat operacji rozpoznawania do konsoli.</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition">
          <source>Gets the location in the input device's audio stream associated with the <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /&gt;</ph> event.</source>
          <target state="translated">Pobiera lokalizację w strumieniu audio urządzenia wejściowego skojarzone z <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition">
          <source>The location in the input device's audio stream associated with the <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /&gt;</ph> event.</source>
          <target state="translated">Lokalizacji w strumieniu audio urządzenia wejściowego skojarzone z <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition">
          <source>This property references the position at the beginning of the recognized phrase in the input device's generated audio stream.</source>
          <target state="translated">Ta właściwość odwołuje się do pozycji na początku rozpoznaną frazę w wygenerowanym strumieniem audio urządzenia wejściowego.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> property references the recognizer's position within its audio input.</source>
          <target state="translated">Z kolei <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> właściwość odwołuje się do pozycji aparat rozpoznawania w jego wejście audio.</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition">
          <source>These positions can be different.</source>
          <target state="translated">Te pozycje mogą być różne.</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition">
          <source>For more information, see <bpt id="p1">[</bpt>Using Speech Recognition Events<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji, zobacz <bpt id="p1">[</bpt>przy użyciu zdarzenia rozpoznawania mowy<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept>.</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition">
          <source>The following example performs asynchronous speech recognition on a speech recognition grammar, using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType&gt;</ph> method with the in-process recognizer.</source>
          <target state="translated">Poniższy przykład przeprowadzają rozpoznawanie mowy asynchroniczne gramatyki rozpoznawania mowy przy użyciu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType&gt;</ph> metody z wewnątrzprocesowy aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition">
          <source>The example uses <ph id="ph1">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> objects to create the speech recognition grammar before building it into a <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">W przykładzie użyto <ph id="ph1">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> obiektów można utworzyć gramatyki rozpoznawania mowy przed zbudowaniem go do <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType&gt;</ph> event outputs information about the recognition operation to the console.</source>
          <target state="translated">Program obsługi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType&gt;</ph> zdarzeń wyświetla informacje na temat operacji rozpoznawania do konsoli.</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout">
          <source>Gets a value that indicates whether a babble timeout generated the <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /&gt;</ph> event.</source>
          <target state="translated">Pobiera wartość wskazującą, czy przekroczono limit babble wygenerowane <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> if the <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> has detected only background noise for longer than was specified by its <ph id="ph3">&lt;see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" /&gt;</ph> property; otherwise <ph id="ph4">&lt;see langword="false." /&gt;</ph></source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph> Jeśli <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> wykrył tylko szumu tła przez dłuższy czas nie został określony przez jego <ph id="ph3">&lt;see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" /&gt;</ph> właściwość; w przeciwnym razie <ph id="ph4">&lt;see langword="false." /&gt;</ph></target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout">
          <source>The following example performs asynchronous speech recognition on a speech recognition grammar, using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType&gt;</ph> method with the in-process recognizer.</source>
          <target state="translated">Poniższy przykład przeprowadzają rozpoznawanie mowy asynchroniczne gramatyki rozpoznawania mowy przy użyciu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType&gt;</ph> metody z wewnątrzprocesowy aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout">
          <source>The example uses <ph id="ph1">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> objects to create the speech recognition grammar before building it into a <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">W przykładzie użyto <ph id="ph1">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> obiektów można utworzyć gramatyki rozpoznawania mowy przed zbudowaniem go do <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType&gt;</ph> event outputs information about the recognition operation to the console.</source>
          <target state="translated">Program obsługi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType&gt;</ph> zdarzeń wyświetla informacje na temat operacji rozpoznawania do konsoli.</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout">
          <source>Gets a value that indicates whether an initial silence timeout generated the <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /&gt;</ph> event.</source>
          <target state="translated">Pobiera wartość wskazującą, czy wygenerowane przekroczenia limitu czasu początkowej wyciszenia <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> if the <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> has detected only silence for a longer time period than was specified by its <ph id="ph3">&lt;see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" /&gt;</ph> property; otherwise <ph id="ph4">&lt;see langword="false." /&gt;</ph></source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph> Jeśli <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> wykrył tylko wyciszenia dłuższy okres czasu nie został określony przez jego <ph id="ph3">&lt;see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" /&gt;</ph> właściwość; w przeciwnym razie <ph id="ph4">&lt;see langword="false." /&gt;</ph></target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout">
          <source>The following example performs asynchronous speech recognition on a speech recognition grammar, using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType&gt;</ph> method with the in-process recognizer.</source>
          <target state="translated">Poniższy przykład przeprowadzają rozpoznawanie mowy asynchroniczne gramatyki rozpoznawania mowy przy użyciu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType&gt;</ph> metody z wewnątrzprocesowy aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout">
          <source>The example uses <ph id="ph1">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> objects to create the speech recognition grammar before building it into a <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">W przykładzie użyto <ph id="ph1">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> obiektów można utworzyć gramatyki rozpoznawania mowy przed zbudowaniem go do <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType&gt;</ph> event outputs information about the recognition operation to the console.</source>
          <target state="translated">Program obsługi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType&gt;</ph> zdarzeń wyświetla informacje na temat operacji rozpoznawania do konsoli.</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded">
          <source>Gets a value indicating whether the input stream ended.</source>
          <target state="translated">Pobiera wartość wskazującą, czy strumień wejściowy jest zakończona.</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> if the recognizer no longer has audio input; otherwise, <ph id="ph2">&lt;see langword="false" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph> Jeśli aparat rozpoznawania nie ma już wejście audio; w przeciwnym razie <ph id="ph2">&lt;see langword="false" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded">
          <source>The recognizer sets this property to <ph id="ph1">`true`</ph> when a file provides the input stream for the recognizer and the end of the file is reached.</source>
          <target state="translated">Aparat rozpoznawania ustawia tę właściwość na <ph id="ph1">`true`</ph> Jeśli plik zawiera strumień wejściowy przez aparat rozpoznawania i zostanie osiągnięty koniec pliku.</target>       </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded">
          <source>The end of the input stream can coincide with a successful recognition operation.</source>
          <target state="translated">Koniec strumienia wejściowego można pokrywa się z operacji rozpoznawania powiodło się.</target>       </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded">
          <source>For more information about using a file as the input stream, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;</ph> methods.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat używania pliku jako strumień wejściowy zobacz <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded">
          <source>The following example performs asynchronous speech recognition on a speech recognition grammar, using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType&gt;</ph> method with the in-process recognizer.</source>
          <target state="translated">Poniższy przykład przeprowadzają rozpoznawanie mowy asynchroniczne gramatyki rozpoznawania mowy przy użyciu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType&gt;</ph> metody z wewnątrzprocesowy aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded">
          <source>The example uses <ph id="ph1">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> objects to create the speech recognition grammar before building it into a <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">W przykładzie użyto <ph id="ph1">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> obiektów można utworzyć gramatyki rozpoznawania mowy przed zbudowaniem go do <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType&gt;</ph> event outputs information about the recognition operation to the console.</source>
          <target state="translated">Program obsługi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType&gt;</ph> zdarzeń wyświetla informacje na temat operacji rozpoznawania do konsoli.</target>       </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.Result">
          <source>Gets the recognition result.</source>
          <target state="translated">Pobiera wynik rozpoznawania.</target>       </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.Result">
          <source>The recognition result if the recognition operation succeeded; otherwise, <ph id="ph1">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated">Wynik rozpoznawania, jeśli operacja rozpoznawania zakończyła się pomyślnie; w przeciwnym razie <ph id="ph1">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.Result">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object derives from <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> and contains full information about a phrase returned by a recognition operation.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> Pochodną obiektu <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> i zawiera wszystkie informacje o frazę zwrócony przez operację rozpoznawania.</target>       </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.Result">
          <source>The following example performs asynchronous speech recognition on a speech recognition grammar, using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType&gt;</ph> method with the in-process recognizer.</source>
          <target state="translated">Poniższy przykład przeprowadzają rozpoznawanie mowy asynchroniczne gramatyki rozpoznawania mowy przy użyciu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType&gt;</ph> metody z wewnątrzprocesowy aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.Result">
          <source>The example uses <ph id="ph1">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> objects to create the speech recognition grammar before building it into a <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">W przykładzie użyto <ph id="ph1">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> obiektów można utworzyć gramatyki rozpoznawania mowy przed zbudowaniem go do <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.RecognizeCompletedEventArgs.Result">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType&gt;</ph> event outputs information about the recognition operation to the console.</source>
          <target state="translated">Program obsługi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType&gt;</ph> zdarzeń wyświetla informacje na temat operacji rozpoznawania do konsoli.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>