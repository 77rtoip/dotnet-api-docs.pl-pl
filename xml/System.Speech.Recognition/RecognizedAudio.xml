<Type Name="RecognizedAudio" FullName="System.Speech.Recognition.RecognizedAudio">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="7dc4d85aa67408409ab977c4f816c16375f572fd" />
    <Meta Name="ms.sourcegitcommit" Value="c0c07dbd19cd7017243f9ac36915755f79bc8da6" />
    <Meta Name="ms.translationtype" Value="MT" />
    <Meta Name="ms.contentlocale" Value="pl-PL" />
    <Meta Name="ms.lasthandoff" Value="11/27/2018" />
    <Meta Name="ms.locfileid" Value="52374226" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class RecognizedAudio" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit RecognizedAudio extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizedAudio" />
  <TypeSignature Language="VB.NET" Value="Public Class RecognizedAudio" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognizedAudio" />
  <TypeSignature Language="F#" Value="type RecognizedAudio = class" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8">
      <AttributeName>System.Serializable</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>
      <span data-ttu-id="9735a-101">Skojarzony audio reprezentuje dane wejściowe to znaczy <see cref="T:System.Speech.Recognition.RecognitionResult" />.</span>
      <span class="sxs-lookup">
        <span data-stu-id="9735a-101">Represents audio input that is associated with a <see cref="T:System.Speech.Recognition.RecognitionResult" />.</span>
      </span>
    </summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="9735a-102">Aparat rozpoznawania mowy generuje informacje o wejścia audio w ramach operacji rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="9735a-102">A speech recognizer generates information about the audio input as part of the recognition operation.</span></span> <span data-ttu-id="9735a-103">Dostępu dźwięk rozpoznany, należy użyć <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> właściwości lub <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A> metody <xref:System.Speech.Recognition.RecognitionResult>.</span><span class="sxs-lookup"><span data-stu-id="9735a-103">To access the recognized audio, use the <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> property or the <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A> method of the <xref:System.Speech.Recognition.RecognitionResult>.</span></span>  
  
 <span data-ttu-id="9735a-104">Wynik rozpoznawania może wygenerować program następujących zdarzeń i metod <xref:System.Speech.Recognition.SpeechRecognizer> i <xref:System.Speech.Recognition.SpeechRecognitionEngine> klasy:</span><span class="sxs-lookup"><span data-stu-id="9735a-104">A recognition result can be produced by the following events and methods of the <xref:System.Speech.Recognition.SpeechRecognizer> and <xref:System.Speech.Recognition.SpeechRecognitionEngine> classes:</span></span>  
  
-   <span data-ttu-id="9735a-105">Zdarzenia:</span><span class="sxs-lookup"><span data-stu-id="9735a-105">Events:</span></span>  
  
    -   <span data-ttu-id="9735a-106"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized?displayProperty=nameWithType> i <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized?displayProperty=nameWithType></span><span class="sxs-lookup"><span data-stu-id="9735a-106"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized?displayProperty=nameWithType> and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized?displayProperty=nameWithType></span></span>  
  
    -   <span data-ttu-id="9735a-107"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected?displayProperty=nameWithType> i <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected?displayProperty=nameWithType></span><span class="sxs-lookup"><span data-stu-id="9735a-107"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected?displayProperty=nameWithType> and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected?displayProperty=nameWithType></span></span>  
  
    -   <span data-ttu-id="9735a-108"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType> i <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType></span><span class="sxs-lookup"><span data-stu-id="9735a-108"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType> and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType></span></span>  
  
    -   <span data-ttu-id="9735a-109"><xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted?displayProperty=nameWithType> i <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted?displayProperty=nameWithType></span><span class="sxs-lookup"><span data-stu-id="9735a-109"><xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted?displayProperty=nameWithType> and <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted?displayProperty=nameWithType></span></span>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType>  
  
-   <span data-ttu-id="9735a-110">Metody:</span><span class="sxs-lookup"><span data-stu-id="9735a-110">Methods:</span></span>  
  
    -   <span data-ttu-id="9735a-111"><xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A?displayProperty=nameWithType> i <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A?displayProperty=nameWithType></span><span class="sxs-lookup"><span data-stu-id="9735a-111"><xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A?displayProperty=nameWithType> and <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A?displayProperty=nameWithType></span></span>  
  
    -   <span data-ttu-id="9735a-112"><xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A?displayProperty=nameWithType> i <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A?displayProperty=nameWithType></span><span class="sxs-lookup"><span data-stu-id="9735a-112"><xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A?displayProperty=nameWithType> and <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A?displayProperty=nameWithType></span></span>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A?displayProperty=nameWithType>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType>  
  
> [!IMPORTANT]
>  <span data-ttu-id="9735a-113">Wynik rozpoznawania, generowane przez rozpoznawanie mowy emulowanej nie zawiera rozpoznanego audio.</span><span class="sxs-lookup"><span data-stu-id="9735a-113">A recognition result produced by emulated speech recognition does not contain recognized audio.</span></span> <span data-ttu-id="9735a-114">Do takiego rozpoznawania wyniku jego <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> właściwość zwraca `null` i jego <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A> metoda zgłasza wyjątek.</span><span class="sxs-lookup"><span data-stu-id="9735a-114">For such a recognition result, its <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> property returns `null` and its <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A> method throws an exception.</span></span> <span data-ttu-id="9735a-115">Aby uzyskać więcej informacji na temat rozpoznawania mowy emulowanej zobacz `EmulateRecognize` i `EmulateRecognizeAsync` metody <xref:System.Speech.Recognition.SpeechRecognizer> i <xref:System.Speech.Recognition.SpeechRecognitionEngine> klasy.</span><span class="sxs-lookup"><span data-stu-id="9735a-115">For more information about emulated speech recognition, see the `EmulateRecognize` and `EmulateRecognizeAsync` methods of the <xref:System.Speech.Recognition.SpeechRecognizer> and <xref:System.Speech.Recognition.SpeechRecognitionEngine> classes.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="9735a-116">Następujące uchwyty przykład <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType>, lub <xref:System.Speech.Recognition.Grammar.SpeechRecognized?displayProperty=nameWithType> zdarzenia i dane wyjściowe do konsoli informacje na temat rozpoznawanym dźwięk, który jest skojarzony z wynikiem rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="9735a-116">The following example handles the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType>, or <xref:System.Speech.Recognition.Grammar.SpeechRecognized?displayProperty=nameWithType> event and outputs to the console information about the recognized audio that is associated with the recognition result.</span></span>  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  RecognitionResult result = e.Result;  
  
  Console.WriteLine("Grammar({0}): {1}",  
    result.Grammar.Name, result.Text);  
  
  if (e.Result.Audio != null)  
  {  
    RecognizedAudio audio = e.Result.Audio;  
  
    Console.WriteLine("   start time: {0}", audio.StartTime);  
    Console.WriteLine("   encoding format: {0}", audio.Format.EncodingFormat);  
    Console.WriteLine("   position: {0}, duration: {1}",  
      audio.AudioPosition, audio.Duration);  
  }  
  
  // Add event handler code here.  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
    <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
    <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
  </Docs>
  <Members>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedAudio.AudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan AudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioPosition : TimeSpan" Usage="System.Speech.Recognition.RecognizedAudio.AudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="9735a-117">Pobiera lokalizację w strumieniu wejściowym audio na początku rozpoznawanym audio.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-117">Gets the location in the input audio stream for the start of the recognized audio.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="9735a-118">Lokalizacja w strumieniu wejściowym audio uruchomienia rozpoznawanym audio.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-118">The location in the input audio stream for the start of the recognized audio.</span>
          </span>
        </value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="9735a-119">Ta właściwość odwołuje się do pozycji na początku rozpoznaną frazę w wygenerowanym strumienia audio urządzenia wejściowego.</span><span class="sxs-lookup"><span data-stu-id="9735a-119">This property references the position at the beginning of the recognized phrase in the input device's generated audio stream.</span></span> <span data-ttu-id="9735a-120">Z drugiej strony `RecognizerAudioPosition` właściwość <xref:System.Speech.Recognition.SpeechRecognitionEngine> i <xref:System.Speech.Recognition.SpeechRecognizer> klasy odwoływać się do pozycji aparat rozpoznawania dane wejściowe audio.</span><span class="sxs-lookup"><span data-stu-id="9735a-120">By contrast, the `RecognizerAudioPosition` property of the <xref:System.Speech.Recognition.SpeechRecognitionEngine> and <xref:System.Speech.Recognition.SpeechRecognizer> classes reference the recognizer's position within its audio input.</span></span> <span data-ttu-id="9735a-121">Te pozycje mogą być różne.</span><span class="sxs-lookup"><span data-stu-id="9735a-121">These positions can be different.</span></span> <span data-ttu-id="9735a-122">Aby uzyskać więcej informacji, zobacz [przy użyciu zdarzenia rozpoznawania mowy](https://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482).</span><span class="sxs-lookup"><span data-stu-id="9735a-122">For more information, see [Using Speech Recognition Events](https://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482).</span></span>  
  
 <span data-ttu-id="9735a-123"><xref:System.Speech.Recognition.RecognizedAudio.StartTime%2A> Właściwości pobiera czas systemowy na początku operacji rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="9735a-123">The <xref:System.Speech.Recognition.RecognizedAudio.StartTime%2A> property gets the system time at the start of the recognition operation.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="9735a-124">Następujące uchwyty przykład <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType> lub <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType> zdarzenia i dane wyjściowe do konsoli informacje na temat rozpoznawanym dźwięk, który jest skojarzony z wynikiem rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="9735a-124">The following example handles the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType> or <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType> event and outputs to the console information about the recognized audio that is associated with the recognition result.</span></span>  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  RecognitionResult result = e.Result;  
  
  Console.WriteLine("Grammar({0}): {1}",  
    result.Grammar.Name, result.Text);  
  
  if (e.Result.Audio != null)  
  {  
    RecognizedAudio audio = e.Result.Audio;  
  
    Console.WriteLine("   start time: {0}", audio.StartTime);  
    Console.WriteLine("   encoding format: {0}", audio.Format.EncodingFormat);  
    Console.WriteLine("   position: {0}, duration: {1}",  
      audio.AudioPosition, audio.Duration);  
  }  
  
  // Add event handler code here.  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
        <altmember cref="P:System.Speech.Recognition.RecognizedAudio.Duration" />
        <altmember cref="P:System.Speech.Recognition.RecognizedAudio.StartTime" />
      </Docs>
    </Member>
    <Member MemberName="Duration">
      <MemberSignature Language="C#" Value="public TimeSpan Duration { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan Duration" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedAudio.Duration" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Duration As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan Duration { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.Duration : TimeSpan" Usage="System.Speech.Recognition.RecognizedAudio.Duration" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="9735a-125">Pobiera czas trwania strumienia wejściowego audio rozpoznawanym audio.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-125">Gets the duration of the input audio stream for the recognized audio.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="9735a-126">Czas trwania w ramach strumienia wejściowego audio rozpoznawanym audio.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-126">The duration within the input audio stream for the recognized audio.</span>
          </span>
        </value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 <span data-ttu-id="9735a-127">Następujące uchwyty przykład <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType> lub <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType> zdarzenia i dane wyjściowe do konsoli informacje na temat rozpoznawanym dźwięk, który jest skojarzony z wynikiem rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="9735a-127">The following example handles the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType> or <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType> event and outputs to the console information about the recognized audio that is associated with the recognition result.</span></span>  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  RecognitionResult result = e.Result;  
  
  Console.WriteLine("Grammar({0}): {1}",  
    result.Grammar.Name, result.Text);  
  
  if (e.Result.Audio != null)  
  {  
    RecognizedAudio audio = e.Result.Audio;  
  
    Console.WriteLine("   start time: {0}", audio.StartTime);  
    Console.WriteLine("   encoding format: {0}", audio.Format.EncodingFormat);  
    Console.WriteLine("   position: {0}, duration: {1}",  
      audio.AudioPosition, audio.Duration);  
  }  
  
  // Add event handler code here.  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognizedAudio.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.RecognizedAudio.StartTime" />
      </Docs>
    </Member>
    <Member MemberName="Format">
      <MemberSignature Language="C#" Value="public System.Speech.AudioFormat.SpeechAudioFormatInfo Format { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.AudioFormat.SpeechAudioFormatInfo Format" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedAudio.Format" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Format As SpeechAudioFormatInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::AudioFormat::SpeechAudioFormatInfo ^ Format { System::Speech::AudioFormat::SpeechAudioFormatInfo ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Format : System.Speech.AudioFormat.SpeechAudioFormatInfo" Usage="System.Speech.Recognition.RecognizedAudio.Format" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Speech.AudioFormat.SpeechAudioFormatInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="9735a-128">Pobiera format audio przetwarzane przez aparat rozpoznawania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-128">Gets the format of the audio processed by a recognition engine.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="9735a-129">Format audio przetwarzane przez aparat rozpoznawania mowy.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-129">The format of the audio processed by the speech recognizer.</span>
          </span>
        </value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 <span data-ttu-id="9735a-130">Następujące uchwyty przykład <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType> lub <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType> zdarzenia i dane wyjściowe do konsoli informacje na temat rozpoznawanym dźwięk, który jest skojarzony z wynikiem rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="9735a-130">The following example handles the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType> or <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType> event and outputs to the console information about the recognized audio that is associated with the recognition result.</span></span>  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  RecognitionResult result = e.Result;  
  
  Console.WriteLine("Grammar({0}): {1}",  
    result.Grammar.Name, result.Text);  
  
  if (e.Result.Audio != null)  
  {  
    RecognizedAudio audio = e.Result.Audio;  
  
    Console.WriteLine("   start time: {0}", audio.StartTime);  
    Console.WriteLine("   encoding format: {0}", audio.Format.EncodingFormat);  
    Console.WriteLine("   position: {0}, duration: {1}",  
      audio.AudioPosition, audio.Duration);  
  }  
  
  // Add event handler code here.  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="N:System.Speech.AudioFormat" />
      </Docs>
    </Member>
    <Member MemberName="GetRange">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizedAudio GetRange (TimeSpan audioPosition, TimeSpan duration);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognizedAudio GetRange(valuetype System.TimeSpan audioPosition, valuetype System.TimeSpan duration) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognizedAudio.GetRange(System.TimeSpan,System.TimeSpan)" />
      <MemberSignature Language="VB.NET" Value="Public Function GetRange (audioPosition As TimeSpan, duration As TimeSpan) As RecognizedAudio" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognizedAudio ^ GetRange(TimeSpan audioPosition, TimeSpan duration);" />
      <MemberSignature Language="F#" Value="member this.GetRange : TimeSpan * TimeSpan -&gt; System.Speech.Recognition.RecognizedAudio" Usage="recognizedAudio.GetRange (audioPosition, duration)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizedAudio</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audioPosition" Type="System.TimeSpan" />
        <Parameter Name="duration" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="audioPosition">
          <span data-ttu-id="9735a-131">Punkt początkowy danych audio, które mają zostać zwrócone.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-131">The starting point of the audio data to be returned.</span>
          </span>
        </param>
        <param name="duration">
          <span data-ttu-id="9735a-132">Długość segmentu, który ma zostać zwrócona.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-132">The length of the segment to be returned.</span>
          </span>
        </param>
        <summary>
          <span data-ttu-id="9735a-133">Wybiera i zwraca część bieżącego rozpoznawane audio jako dane binarne.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-133">Selects and returns a section of the current recognized audio as binary data.</span>
          </span>
        </summary>
        <returns>
          <span data-ttu-id="9735a-134">Zwraca podsekcję obiektu rozpoznawanym audio, zgodnie z definicją <paramref name="audioPosition" /> i <paramref name="duration" />.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-134">Returns a subsection of the recognized audio, as defined by <paramref name="audioPosition" /> and <paramref name="duration" />.</span>
          </span>
        </returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 <span data-ttu-id="9735a-135">Poniższy przykład tworzy gramatyki rozpoznawania mowy, nazwę danych wejściowych, dodaje program obsługi <xref:System.Speech.Recognition.Grammar.SpeechRecognized> zdarzenia i ładuje gramatyki do rozpoznawania mowy w procesie.</span><span class="sxs-lookup"><span data-stu-id="9735a-135">The following example creates a speech recognition grammar for name input, adds a handler for the <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event, and loads the grammar into an in-process speech recognizer.</span></span> <span data-ttu-id="9735a-136">Następnie zapisuje dane audio część nazwy w danych wejściowych do pliku dźwiękowego.</span><span class="sxs-lookup"><span data-stu-id="9735a-136">Then it writes the audio information for the name portion of the input to an audio file.</span></span> <span data-ttu-id="9735a-137">Plik dźwiękowy jest używany jako dane wejściowe <xref:System.Speech.Synthesis.SpeechSynthesizer> obiektu, który świadczy frazę, która obejmuje nagrania audio.</span><span class="sxs-lookup"><span data-stu-id="9735a-137">The audio file is used as input to a <xref:System.Speech.Synthesis.SpeechSynthesizer> object, which speaks a phrase that includes the recorded audio.</span></span>  
  
```  
private static void AddNameGrammar(SpeechRecognitionEngine recognizer)  
{  
  GrammarBuilder builder = new GrammarBuilder();  
  builder.Append("My name is");  
  builder.AppendWildcard();  
  
  Grammar nameGrammar = new Grammar(builder);  
  nameGrammar.Name = "Name Grammar";  
  nameGrammar.SpeechRecognized +=  
    new EventHandler<SpeechRecognizedEventArgs>(  
      NameSpeechRecognized);  
  
  recognizer.LoadGrammar(nameGrammar);  
}  
  
// Handle the SpeechRecognized event of the name grammar.  
private static void NameSpeechRecognized(  
  object sender, SpeechRecognizedEventArgs e)  
{  
  Console.WriteLine("Grammar ({0}) recognized speech: {1}",  
    e.Result.Grammar.Name, e.Result.Text);  
  
  try  
  {  
  
    // The name phrase starts after the first three words.  
    if (e.Result.Words.Count < 4)  
    {  
  
      // Add code to check for an alternate that contains the wildcard.  
      return;  
    }  
  
    RecognizedAudio audio = e.Result.Audio;  
    TimeSpan start = e.Result.Words[3].AudioPosition;  
    TimeSpan duration = audio.Duration - start;  
  
    // Add code to verify and persist the audio.  
    string path = @"C:\temp\nameAudio.wav";  
    using (Stream outputStream = new FileStream(path, FileMode.Create))  
    {  
      RecognizedAudio nameAudio = audio.GetRange(start, duration);  
      nameAudio.WriteToWaveStream(outputStream);  
      outputStream.Close();  
    }  
  
    Thread testThread =  
      new Thread(new ParameterizedThreadStart(TestAudio));  
    testThread.Start(path);  
  }  
  catch (Exception ex)  
  {  
    Console.WriteLine("Exception thrown while processing audio:");  
    Console.WriteLine(ex.ToString());  
  }  
}  
  
// Use the speech synthesizer to play back the .wav file  
// that was created in the SpeechRecognized event handler.  
  
private static void TestAudio(object item)  
{  
  string path = item as string;  
  if (path != null && File.Exists(path))  
  {  
    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  
    PromptBuilder builder = new PromptBuilder();  
    builder.AppendText("Hello");  
    builder.AppendAudio(path);  
    synthesizer.Speak(builder);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.ArgumentOutOfRangeException">
          <span data-ttu-id="9735a-138">
            <paramref name="audioPosition" /> i <paramref name="duration" /> zdefiniować segment audio poza zakresem bieżącego segmentu.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-138">
              <paramref name="audioPosition" /> and <paramref name="duration" /> define a segment of audio outside the range of the current segment.</span>
          </span>
        </exception>
        <exception cref="T:System.InvalidOperationException">
          <span data-ttu-id="9735a-139">Bieżący rozpoznane audio nie zawiera żadnych danych.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-139">The current recognized audio contains no data.</span>
          </span>
        </exception>
        <altmember cref="M:System.Speech.Recognition.RecognizedAudio.WriteToWaveStream(System.IO.Stream)" />
        <altmember cref="M:System.Speech.Recognition.RecognizedAudio.WriteToAudioStream(System.IO.Stream)" />
      </Docs>
    </Member>
    <Member MemberName="StartTime">
      <MemberSignature Language="C#" Value="public DateTime StartTime { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.DateTime StartTime" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedAudio.StartTime" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property StartTime As DateTime" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property DateTime StartTime { DateTime get(); };" />
      <MemberSignature Language="F#" Value="member this.StartTime : DateTime" Usage="System.Speech.Recognition.RecognizedAudio.StartTime" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.DateTime</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <span data-ttu-id="9735a-140">Pobiera czas systemowy na początku operacji rozpoznawania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-140">Gets the system time at the start of the recognition operation.</span>
          </span>
        </summary>
        <value>
          <span data-ttu-id="9735a-141">Czas systemowy na początku operacji rozpoznawania.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-141">The system time at the start of the recognition operation.</span>
          </span>
        </value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="9735a-142"><xref:System.Speech.Recognition.RecognizedAudio.StartTime%2A> Właściwości pobiera czas systemowy na początku operacji rozpoznawania, która może być przydatny w obliczeniach opóźnienia i wydajność.</span><span class="sxs-lookup"><span data-stu-id="9735a-142">The <xref:System.Speech.Recognition.RecognizedAudio.StartTime%2A> property gets the system time at the start of the recognition operation, which can be useful for latency and performance calculations.</span></span>  
  
 <span data-ttu-id="9735a-143"><xref:System.Speech.Recognition.RecognizedAudio.AudioPosition%2A> Właściwości pobiera lokalizację w wygenerowanym strumienia audio urządzenia wejściowego.</span><span class="sxs-lookup"><span data-stu-id="9735a-143">The <xref:System.Speech.Recognition.RecognizedAudio.AudioPosition%2A> property gets the location in the input device's generated audio stream.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="9735a-144">Następujące uchwyty przykład <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType> lub <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType> zdarzenia i dane wyjściowe do konsoli informacje na temat rozpoznawanym dźwięk, który jest skojarzony z wynikiem rozpoznawania.</span><span class="sxs-lookup"><span data-stu-id="9735a-144">The following example handles the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType> or <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType> event and outputs to the console information about the recognized audio that is associated with the recognition result.</span></span>  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  RecognitionResult result = e.Result;  
  
  Console.WriteLine("Grammar({0}): {1}",  
    result.Grammar.Name, result.Text);  
  
  if (e.Result.Audio != null)  
  {  
    RecognizedAudio audio = e.Result.Audio;  
  
    Console.WriteLine("   start time: {0}", audio.StartTime);  
    Console.WriteLine("   encoding format: {0}", audio.Format.EncodingFormat);  
    Console.WriteLine("   position: {0}, duration: {1}",  
      audio.AudioPosition, audio.Duration);  
  }  
  
  // Add event handler code here.  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognizedAudio.AudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="WriteToAudioStream">
      <MemberSignature Language="C#" Value="public void WriteToAudioStream (System.IO.Stream outputStream);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void WriteToAudioStream(class System.IO.Stream outputStream) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognizedAudio.WriteToAudioStream(System.IO.Stream)" />
      <MemberSignature Language="VB.NET" Value="Public Sub WriteToAudioStream (outputStream As Stream)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void WriteToAudioStream(System::IO::Stream ^ outputStream);" />
      <MemberSignature Language="F#" Value="member this.WriteToAudioStream : System.IO.Stream -&gt; unit" Usage="recognizedAudio.WriteToAudioStream outputStream" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="outputStream" Type="System.IO.Stream" />
      </Parameters>
      <Docs>
        <param name="outputStream">
          <span data-ttu-id="9735a-145">Strumień, który będzie otrzymywać dane audio.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-145">The stream that will receive the audio data.</span>
          </span>
        </param>
        <summary>
          <span data-ttu-id="9735a-146">Zapisuje całą audio do strumienia jako nieprzetworzone dane.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-146">Writes the entire audio to a stream as raw data.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="9735a-147">Dane audio są zapisywane do `outputStream` w formacie binarnym.</span><span class="sxs-lookup"><span data-stu-id="9735a-147">Audio data is written to `outputStream` in binary form.</span></span> <span data-ttu-id="9735a-148">Brak informacji nagłówka jest dołączony.</span><span class="sxs-lookup"><span data-stu-id="9735a-148">No header information is included.</span></span>  
  
 <span data-ttu-id="9735a-149"><xref:System.Speech.Recognition.RecognizedAudio.WriteToAudioStream%2A> Metody w formacie Wave, ale nie zawiera nagłówek Wave.</span><span class="sxs-lookup"><span data-stu-id="9735a-149">The <xref:System.Speech.Recognition.RecognizedAudio.WriteToAudioStream%2A> method uses the Wave format, but does not include the Wave header.</span></span> <span data-ttu-id="9735a-150">Aby dołączyć Nagłówek Wave, należy użyć <xref:System.Speech.Recognition.RecognizedAudio.WriteToWaveStream%2A> metody.</span><span class="sxs-lookup"><span data-stu-id="9735a-150">To include the Wave header, use the <xref:System.Speech.Recognition.RecognizedAudio.WriteToWaveStream%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.RecognizedAudio.GetRange(System.TimeSpan,System.TimeSpan)" />
        <altmember cref="M:System.Speech.Recognition.RecognizedAudio.WriteToWaveStream(System.IO.Stream)" />
      </Docs>
    </Member>
    <Member MemberName="WriteToWaveStream">
      <MemberSignature Language="C#" Value="public void WriteToWaveStream (System.IO.Stream outputStream);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void WriteToWaveStream(class System.IO.Stream outputStream) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognizedAudio.WriteToWaveStream(System.IO.Stream)" />
      <MemberSignature Language="VB.NET" Value="Public Sub WriteToWaveStream (outputStream As Stream)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void WriteToWaveStream(System::IO::Stream ^ outputStream);" />
      <MemberSignature Language="F#" Value="member this.WriteToWaveStream : System.IO.Stream -&gt; unit" Usage="recognizedAudio.WriteToWaveStream outputStream" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="outputStream" Type="System.IO.Stream" />
      </Parameters>
      <Docs>
        <param name="outputStream">
          <span data-ttu-id="9735a-151">Strumień, który będzie otrzymywać dane audio.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-151">The stream that will receive the audio data.</span>
          </span>
        </param>
        <summary>
          <span data-ttu-id="9735a-152">Zapisuje audio w strumieniu w formacie Wave.</span>
          <span class="sxs-lookup">
            <span data-stu-id="9735a-152">Writes audio to a stream in Wave format.</span>
          </span>
        </summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="9735a-153">Dane audio są zapisywane do `outputStream` w formacie Wave, który zawiera nagłówek format (RIFF) pliku wymiany zasobów.</span><span class="sxs-lookup"><span data-stu-id="9735a-153">Audio data is written to `outputStream` in Wave format, which includes a resource interchange file format (RIFF) header.</span></span>  
  
 <span data-ttu-id="9735a-154"><xref:System.Speech.Recognition.RecognizedAudio.WriteToAudioStream%2A> Metoda używa tego samego formatu binarnego, ale nie zawiera nagłówek Wave.</span><span class="sxs-lookup"><span data-stu-id="9735a-154">The <xref:System.Speech.Recognition.RecognizedAudio.WriteToAudioStream%2A> method uses the same binary format, but does not include the Wave header.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="9735a-155">Poniższy przykład tworzy gramatyki rozpoznawania mowy, nazwę danych wejściowych, dodaje program obsługi <xref:System.Speech.Recognition.Grammar.SpeechRecognized> zdarzenia i ładuje gramatyki do rozpoznawania mowy w procesie.</span><span class="sxs-lookup"><span data-stu-id="9735a-155">The following example creates a speech recognition grammar for name input, adds a handler for the <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event, and loads the grammar into an in-process speech recognizer.</span></span> <span data-ttu-id="9735a-156">Następnie zapisuje dane audio część nazwy w danych wejściowych do pliku dźwiękowego.</span><span class="sxs-lookup"><span data-stu-id="9735a-156">Then it writes the audio information for the name portion of the input to an audio file.</span></span> <span data-ttu-id="9735a-157">Plik dźwiękowy jest używany jako dane wejściowe <xref:System.Speech.Synthesis.SpeechSynthesizer> obiektu, który świadczy frazę, która obejmuje nagrania audio.</span><span class="sxs-lookup"><span data-stu-id="9735a-157">The audio file is used as input to a <xref:System.Speech.Synthesis.SpeechSynthesizer> object, which speaks a phrase that includes the recorded audio.</span></span>  
  
```  
private static void AddNameGrammar(SpeechRecognitionEngine recognizer)  
{  
  GrammarBuilder builder = new GrammarBuilder();  
  builder.Append("My name is");  
  builder.AppendWildcard();  
  
  Grammar nameGrammar = new Grammar(builder);  
  nameGrammar.Name = "Name Grammar";  
  nameGrammar.SpeechRecognized +=  
    new EventHandler<SpeechRecognizedEventArgs>(  
      NameSpeechRecognized);  
  
  recognizer.LoadGrammar(nameGrammar);  
}  
  
// Handle the SpeechRecognized event of the name grammar.  
private static void NameSpeechRecognized(  
  object sender, SpeechRecognizedEventArgs e)  
{  
  Console.WriteLine("Grammar ({0}) recognized speech: {1}",  
    e.Result.Grammar.Name, e.Result.Text);  
  
  try  
  {  
    // The name phrase starts after the first three words.  
    if (e.Result.Words.Count < 4)  
    {  
  
      // Add code to check for an alternate that contains the   
wildcard.  
      return;  
    }  
  
    RecognizedAudio audio = e.Result.Audio;  
    TimeSpan start = e.Result.Words[3].AudioPosition;  
    TimeSpan duration = audio.Duration - start;  
  
    // Add code to verify and persist the audio.  
    string path = @"C:\temp\nameAudio.wav";  
    using (Stream outputStream = new FileStream(path, FileMode.Create))  
    {  
      RecognizedAudio nameAudio = audio.GetRange(start, duration);  
      nameAudio.WriteToWaveStream(outputStream);  
      outputStream.Close();  
    }  
  
    Thread testThread =  
      new Thread(new ParameterizedThreadStart(TestAudio));  
    testThread.Start(path);  
  }  
  catch (Exception ex)  
  {  
    Console.WriteLine("Exception thrown while processing audio:");  
    Console.WriteLine(ex.ToString());  
  }  
}  
  
// Use the speech synthesizer to play back the .wav file  
// that was created in the SpeechRecognized event handler.  
  
private static void TestAudio(object item)  
{  
  string path = item as string;  
  if (path != null && File.Exists(path))  
  {  
    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  
    PromptBuilder builder = new PromptBuilder();  
    builder.AppendText("Hello");  
    builder.AppendAudio(path);  
    synthesizer.Speak(builder);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.RecognizedAudio.GetRange(System.TimeSpan,System.TimeSpan)" />
        <altmember cref="M:System.Speech.Recognition.RecognizedAudio.WriteToAudioStream(System.IO.Stream)" />
      </Docs>
    </Member>
  </Members>
</Type>