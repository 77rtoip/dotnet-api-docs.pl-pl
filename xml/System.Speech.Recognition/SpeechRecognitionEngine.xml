<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="SpeechRecognitionEngine.xml" source-language="en-US" target-language="pl-PL">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-15c36f0" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">02cd5861-7ce2-4a82-b358-31f8435a0ac564d271fac7ee774099403cbb7bec467f30d51b3f.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">64d271fac7ee774099403cbb7bec467f30d51b3f</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/03/2018</xliffext:ms.lasthandoff>
      <xliffext:moniker_ids xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">netframework-4.5.1,netframework-4.5.2,netframework-4.5,netframework-4.6.1,netframework-4.6.2,netframework-4.6,netframework-4.7.1,netframework-4.7</xliffext:moniker_ids>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Provides the means to access and manage an in-process speech recognition engine.</source>
          <target state="translated">Pozwala na uzyskanie dostępu i zarządzanie aparatu rozpoznawania mowy w procesie.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>You can create an instance of this class for any of the installed speech recognizers.</source>
          <target state="translated">Dla każdego aparatów rozpoznawania mowy zainstalowane, można utworzyć wystąpienia tej klasy.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To get information about which recognizers are installed, use the static <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> method.</source>
          <target state="translated">Aby uzyskać informacje o tym, które są zainstalowane aparatów rozpoznawania, użyj statycznych <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>This class is for running speech recognition engines in-process, and provides control over various aspects of speech recognition, as follows:</source>
          <target state="translated">Ta klasa jest przeznaczony do uruchamiania mowy rozpoznawania aparaty w procesie i zapewnia kontrolę nad różnych aspektów rozpoznawanie mowy w następujący sposób:</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To create an in-process speech recognizer, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A&gt;</ph> constructors.</source>
          <target state="translated">Aby utworzyć rozpoznawania mowy w procesie, użyj jednej z <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A&gt;</ph> konstruktorów.</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To manage speech recognition grammars, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt;</ph> methods, and the <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt;</ph> property.</source>
          <target state="translated">Aby zarządzać gramatyki rozpoznawania mowy, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt;</ph> metod i <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To configure the input to the recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;</ph>, or <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;</ph> method.</source>
          <target state="translated">Aby skonfigurować dane wejściowe dla aparatu rozpoznawania, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;</ph>, lub <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To perform speech recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> method.</source>
          <target state="translated">Aby przeprowadzić rozpoznawanie mowy, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To modify how recognition handles silence or unexpected input, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> properties.</source>
          <target state="translated">Aby zmodyfikować sposób rozpoznawania obsługi wyciszenia lub nieoczekiwane dane wejściowe, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To change the number of alternates the recognizer returns, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A&gt;</ph> property.</source>
          <target state="translated">Aby zmienić numer alternatyw zwraca aparat rozpoznawania, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer returns recognition results in a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated">Aparat rozpoznawania zwraca wyniki rozpoznawania w <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To synchronize changes to the recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Aby zsynchronizować zmiany aparat rozpoznawania, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer uses more than one thread to perform tasks.</source>
          <target state="translated">Aparat rozpoznawania używa więcej niż jeden wątek, do wykonywania zadań.</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To emulate input to the recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Aby emulować dane wejściowe dla aparatu rozpoznawania, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> object is for the sole use of the process that instantiated the object.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> Obiekt jest jedyny użyć procesu wystąpienia obiektu.</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> shares a single recognizer with any application that wants to use it.</source>
          <target state="translated">Z kolei <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> współużytkuje pojedynczego aparatu rozpoznawania z dowolnej aplikacji, która chce go używać.</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Always call <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A&gt;</ph> before you release your last reference to the speech recognizer.</source>
          <target state="translated">Wywoływanie zawsze <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A&gt;</ph> przed zwolnieniem ostatniego odwołania do rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Otherwise, the resources it is using will not be freed until the garbage collector calls the recognizer object's <ph id="ph1">`Finalize`</ph> method.</source>
          <target state="translated">W przeciwnym razie używa zasobów nie zostanie zwolniona, dopóki moduł garbage collector wywołuje obiekt aparatu rozpoznawania <ph id="ph1">`Finalize`</ph> metody.</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część prezentującą rozpoznawania mowy podstawowe aplikacji konsoli.</target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Because this example uses the <ph id="ph1">`Multiple`</ph> mode of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> method, it performs recognition until you close the console window or stop debugging.</source>
          <target state="translated">Ponieważ w tym przykładzie użyto <ph id="ph1">`Multiple`</ph> tryb <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> metoda wykonuje rozpoznawania do czasu zamknięcia okna konsoli lub zatrzymać debugowanie.</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> class.</source>
          <target state="translated">Inicjuje nowe wystąpienie klasy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> klasy.</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>You can construct a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance from any of the following:</source>
          <target state="translated">Można utworzyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> wystąpienia za pomocą dowolnego z następujących czynności:</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The default speech recognition engine for the system</source>
          <target state="translated">Aparat rozpoznawania mowy domyślne dla systemu</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>A specific speech recognition engine that you specify by name</source>
          <target state="translated">Aparat rozpoznawania mowy określonych, który jest określany na podstawie nazwy</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The default speech recognition engine for a locale that you specify</source>
          <target state="translated">Aparat rozpoznawania mowy domyślny dla ustawień regionalnych, które określisz</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>A specific recognition engine that meets the criteria that you specify in a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerInfo&gt;</ph> object.</source>
          <target state="translated">Aparat rozpoznawania określonych, który spełnia kryteria określone w <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerInfo&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">Rozpoczęciem rozpoznawania mowy rozpoznawania, należy załadować gramatyki rozpoznawania mowy co najmniej jedną i skonfigurować dane wejściowe dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To load a grammar, call the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Aby załadować gramatyki, należy wywołać <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To configure the audio input, use one of the following methods:</source>
          <target state="translated">Aby skonfigurować wejście audio, użyj jednej z następujących metod:</target>       </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> class using the default speech recognizer for the system.</source>
          <target state="translated">Inicjuje nowe wystąpienie klasy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> przy użyciu aparatu rozpoznawania mowy domyślne systemu.</target>       </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor">
          <source>Before the speech recognizer can begin speech recognition, you must load at least one recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">Rozpoczęciem rozpoznawania mowy rozpoznawania mowy, należy załadować co najmniej jedną gramatykę rozpoznawania i skonfigurować dane wejściowe dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor">
          <source>To load a grammar, call the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Aby załadować gramatyki, należy wywołać <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor">
          <source>To configure the audio input, use one of the following methods:</source>
          <target state="translated">Aby skonfigurować wejście audio, użyj jednej z następujących metod:</target>       </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>The locale that the speech recognizer must support.</source>
          <target state="translated">Ustawienia regionalne muszą obsługiwać rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> class using the default speech recognizer for a specified locale.</source>
          <target state="translated">Inicjuje nowe wystąpienie klasy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> dla określonych ustawień regionalnych przy użyciu domyślnego rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Microsoft Windows and the System.Speech API accept all valid language-country codes.</source>
          <target state="translated">Microsoft Windows i interfejsu API System.Speech zaakceptować wszystkie prawidłowe kody języka kraju.</target>       </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>To perform speech recognition using the language specified in the <ph id="ph1">`CultureInfo`</ph> argument, a speech recognition engine that supports that language-country code must be installed.</source>
          <target state="translated">Aby przeprowadzić rozpoznawanie mowy przy użyciu języka określonego w <ph id="ph1">`CultureInfo`</ph> argument, który obsługuje kod kraju język musi być zainstalowany aparatu rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>The speech recognition engines that shipped with Microsoft Windows 7 work with the following language-country codes.</source>
          <target state="translated">Aparatów rozpoznawania mowy dostarczonych z programem Microsoft Windows 7 skontaktować się z następujących kodów kraju języka.</target>       </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>en-GB.</source>
          <target state="translated">en-GB.</target>       </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>English (United Kingdom)</source>
          <target state="translated">Angielski (brytyjski)</target>       </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>en-US.</source>
          <target state="translated">en-US.</target>       </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>English (United States)</source>
          <target state="translated">Angielski (Stany Zjednoczone)</target>       </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>de-DE.</source>
          <target state="translated">de-DE.</target>       </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>German (Germany)</source>
          <target state="translated">Niemiecki (Niemcy)</target>       </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>es-ES.</source>
          <target state="translated">es-ES.</target>       </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Spanish (Spain)</source>
          <target state="translated">Hiszpański (Hiszpania)</target>       </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>fr-FR.</source>
          <target state="translated">fr-FR.</target>       </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>French (France)</source>
          <target state="translated">Francuski (Francja)</target>       </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>ja-JP.</source>
          <target state="translated">ja-JP.</target>       </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Japanese (Japan)</source>
          <target state="translated">Japoński (Japonia)</target>       </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>zh-CN.</source>
          <target state="translated">zh-CN.</target>       </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Chinese (China)</source>
          <target state="translated">Chiński (Chiny)</target>       </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>zh-TW.</source>
          <target state="translated">zh-TW.</target>       </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Chinese (Taiwan)</source>
          <target state="translated">Chiński (Tajwan)</target>       </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Two-letter language codes such as "en", "fr", or "es" are also permitted.</source>
          <target state="translated">Język dwuliterowych kodów przykład "en", "fr" lub "es" również są dozwolone.</target>       </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">Rozpoczęciem rozpoznawania mowy rozpoznawania, należy załadować gramatyki rozpoznawania mowy co najmniej jedną i skonfigurować dane wejściowe dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>To load a grammar, call the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Aby załadować gramatyki, należy wywołać <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>To configure the audio input, use one of the following methods:</source>
          <target state="translated">Aby skonfigurować wejście audio, użyj jednej z następujących metod:</target>       </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>The following example shows part of a console application that demonstrates basic speech recognition, and initializes a speech recognizer for the en-US locale.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część aplikacja konsolowa, która przedstawia rozpoznawania mowy podstawowych oraz inicjuje dla ustawień regionalnych pl pl aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>None of the installed speech recognizers support the specified locale, or <ph id="ph1">&lt;paramref name="culture" /&gt;</ph> is the invariant culture.</source>
          <target state="translated">Żadne aparaty rozpoznawania mowy zainstalowanych obsługuje określonych ustawień regionalnych, lub <ph id="ph1">&lt;paramref name="culture" /&gt;</ph> jest niezmienna kultura.</target>       </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source><ph id="ph1">&lt;paramref name="Culture" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="Culture" /&gt;</ph> jest <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>The information for the specific speech recognizer.</source>
          <target state="translated">Informacje dotyczące aparatu rozpoznawania mowy określonych.</target>       </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> using the information in a <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.RecognizerInfo" /&gt;</ph> object to specify the recognizer to use.</source>
          <target state="translated">Inicjuje nowe wystąpienie klasy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> korzystając z informacji w <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.RecognizerInfo" /&gt;</ph> obiektu w celu określenia aparatu rozpoznawania do użycia.</target>       </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>You can create an instance of this class for any of the installed speech recognizers.</source>
          <target state="translated">Dla każdego aparatów rozpoznawania mowy zainstalowane, można utworzyć wystąpienia tej klasy.</target>       </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>To get information about which recognizers are installed, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> method.</source>
          <target state="translated">Aby uzyskać informacje o tym, które są zainstalowane aparatów rozpoznawania, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">Rozpoczęciem rozpoznawania mowy rozpoznawania, należy załadować gramatyki rozpoznawania mowy co najmniej jedną i skonfigurować dane wejściowe dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>To load a grammar, call the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Aby załadować gramatyki, należy wywołać <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>To configure the audio input, use one of the following methods:</source>
          <target state="translated">Aby skonfigurować wejście audio, użyj jednej z następujących metod:</target>       </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>The following example shows part of a console application that demonstrates basic speech recognition, and initializes a speech recognizer that supports the English language.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część aplikacji konsoli, która przedstawia rozpoznawania mowy podstawowych oraz inicjuje aparat rozpoznawania mowy obsługującego język angielski.</target>       </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>The token name of the speech recognizer to use.</source>
          <target state="translated">Nazwa tokenu aparatu rozpoznawania mowy do użycia.</target>       </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> class with a string parameter that specifies the name of the recognizer to use.</source>
          <target state="translated">Inicjuje nowe wystąpienie klasy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> klasy z parametrem ciąg określający nazwę aparatu rozpoznawania do użycia.</target>       </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>The token name of the recognizer is the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerInfo.Id%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerInfo&gt;</ph> object returned by the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt;</ph> property of the recognizer.</source>
          <target state="translated">Nazwa tokenu aparat rozpoznawania jest wartość <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerInfo.Id%2A&gt;</ph> właściwość <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerInfo&gt;</ph> obiektu zwróconego przez <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt;</ph> właściwości aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>To get a collection of all the installed recognizers, use the static <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> method.</source>
          <target state="translated">Aby uzyskać kolekcję wszystkich zainstalowanych aparatów rozpoznawania, użyj statycznych <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">Rozpoczęciem rozpoznawania mowy rozpoznawania, należy załadować gramatyki rozpoznawania mowy co najmniej jedną i skonfigurować dane wejściowe dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>To load a grammar, call the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Aby załadować gramatyki, należy wywołać <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>To configure the audio input, use one of the following methods:</source>
          <target state="translated">Aby skonfigurować wejście audio, użyj jednej z następujących metod:</target>       </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>The following example shows part of a console application that demonstrates basic speech recognition, and creates an instance of the Speech Recognizer 8.0 for Windows (English - US).</source>
          <target state="translated">W poniższym przykładzie przedstawiono część aplikacji konsoli, która przedstawia rozpoznawania mowy podstawowych oraz tworzy wystąpienie 8.0 aparatu rozpoznawania mowy dla systemu Windows (Polski — Stany Zjednoczone).</target>       </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>No speech recognizer with that token name is installed, or <ph id="ph1">&lt;paramref name="recognizerId" /&gt;</ph> is the empty string ("").</source>
          <target state="translated">Zainstalowano żadnego aparatu rozpoznawania mowy o tej nazwie tokenu, lub <ph id="ph1">&lt;paramref name="recognizerId" /&gt;</ph> jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source><ph id="ph1">&lt;paramref name="recognizerId" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="recognizerId" /&gt;</ph> jest <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat">
          <source>Gets the format of the audio being received by the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</source>
          <target state="translated">Pobiera format audio odbierane przez <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat">
          <source>The format of audio at the input to the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> instance, or <ph id="ph2">&lt;see langword="null" /&gt;</ph> if the input is not configured or set to the null input.</source>
          <target state="translated">Format audio w danych wejściowych na <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> wystąpienia, lub <ph id="ph2">&lt;see langword="null" /&gt;</ph> Jeśli dane wejściowe nie jest skonfigurowany lub wartość null danych wejściowych.</target>       </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat">
          <source>To configure the audio input, use one of the following methods:</source>
          <target state="translated">Aby skonfigurować wejście audio, użyj jednej z następujących metod:</target>       </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat">
          <source>The example below uses <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat%2A&gt;</ph> to obtain and display audio format data.</source>
          <target state="translated">Poniższym przykładzie użyto <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat%2A&gt;</ph> do wyświetlania danych audio format.</target>       </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel">
          <source>Gets the level of the audio being received by the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</source>
          <target state="translated">Pobiera poziom dźwięku odbierane przez <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel">
          <source>The audio level of the input to the speech recognizer, from 0 through 100.</source>
          <target state="translated">Poziom audio w danych wejściowych rozpoznawania mowy od 0 do 100.</target>       </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel">
          <source>The value 0 represents silence, and 100 represents the maximum input volume.</source>
          <target state="translated">Wartość 0 oznacza wyciszenia, a maksymalna głośność reprezentuje 100.</target>       </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> reports the level of its audio input.</source>
          <target state="translated">Wywoływane, gdy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> raportuje poziomu jego wejście audio.</target>       </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> raises this event multiple times per second.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> Zgłasza zdarzenie, to wiele razy w ciągu sekundy.</target>       </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>The frequency with which the event is raised depends on the computer on which the application is running.</source>
          <target state="translated">Częstotliwość, z którym zdarzenia zależy od komputera, na którym jest uruchomiona aplikacja.</target>       </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>To get the audio level at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ph>.</source>
          <target state="translated">Aby uzyskać poziom audio w czasie zdarzenia, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</ph> właściwości skojarzonego <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>To get the current audio level of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A&gt;</ph> property.</source>
          <target state="translated">Aby uzyskać bieżący poziom audio w danych wejściowych aparat rozpoznawania, należy użyć aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>When you create an <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Po utworzeniu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated&gt;</ph> delegata, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>The following example adds a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated&gt;</ph> event to a <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> object.</source>
          <target state="translated">Poniższy przykład umożliwia dodanie obsługi dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated&gt;</ph> zdarzenia <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>The handler outputs the new audio level to the console.</source>
          <target state="translated">Program obsługi generuje nowy poziom audio do konsoli.</target>       </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>Gets the current location in the audio stream being generated by the device that is providing input to the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</source>
          <target state="translated">Pobiera bieżącą lokalizację w strumieniem audio generowany przez urządzenie, który dostarcza dane wejściowe <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>The current location in the audio stream being generated by the input device.</source>
          <target state="translated">Bieżąca lokalizacja strumieniem audio generowany przez urządzenia wejściowego.</target>       </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> property references the input device's position in its generated audio stream.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> Właściwość odwołuje się do pozycji urządzenia wejściowego w jego wygenerowanego strumieniem audio.</target>       </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> property references the recognizer's position within its audio input.</source>
          <target state="translated">Z kolei <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> właściwość odwołuje się do pozycji aparat rozpoznawania w jego wejście audio.</target>       </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>These positions can be different.</source>
          <target state="translated">Te pozycje mogą być różne.</target>       </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> property.</source>
          <target state="translated">Na przykład jeśli aparat rozpoznawania otrzymał wejściowych, do których nie ma jeszcze generowane w wyniku rozpoznawania, a następnie wartość <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> właściwości jest mniejsza niż wartość <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>In the following example, the in-process speech recognizer uses a dictation grammar to match speech input.</source>
          <target state="translated">W poniższym przykładzie rozpoznawania mowy w trakcie używa gramatyki dyktowania w celu dopasowania danych wejściowych mowy.</target>       </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> event writes to the console the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph>, and  <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A&gt;</ph> when the speech recognizer detects speech at its input.</source>
          <target state="translated">Program obsługi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> zapisuje zdarzenie w konsoli <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A&gt;</ph> podczas rozpoznawania mowy wykrywa mowy na jej danych wejściowych.</target>       </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> detects a problem in the audio signal.</source>
          <target state="translated">Wywoływane, gdy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> wykryje problem w sygnału dźwiękowego.</target>       </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred">
          <source>To get which problem occurred, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ph>.</source>
          <target state="translated">Aby uzyskać, jaki problem wystąpił, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</ph> właściwości skojarzonego <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred">
          <source>When you create an <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Po utworzeniu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred&gt;</ph> delegata, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred">
          <source>The following example defines an event handler that gathers information about an <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred&gt;</ph> event.</source>
          <target state="translated">W poniższym przykładzie zdefiniowano program obsługi zdarzeń, które zbiera informacje o <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioState">
          <source>Gets the state of the audio being received by the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</source>
          <target state="translated">Pobiera stan audio odbierane przez <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioState">
          <source>The state of the audio input to the speech recognizer.</source>
          <target state="translated">Stan wejście audio do rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioState">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;</ph> property represents the audio state with a member of the <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;</ph> Właściwość reprezentuje stan dźwięku z elementem członkowskim o <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> wyliczenia.</target>       </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>Raised when the state changes in the audio being received by the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</source>
          <target state="translated">Wywoływane, gdy zmian stanu, które usłyszysz odbierane przez <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>To get the audio state at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ph>.</source>
          <target state="translated">Aby pobrać stan dźwięku w czasie zdarzenia, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</ph> właściwości skojarzonego <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>To get the current audio state of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;</ph> property.</source>
          <target state="translated">Aby uzyskać bieżący stan audio w danych wejściowych aparat rozpoznawania, należy użyć aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>For more information about audio state, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat stanu audio, zobacz <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> wyliczenia.</target>       </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>When you create an <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Po utworzeniu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph> delegata, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>The following example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph> event to write the recognizer's new <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;</ph> to the console each time it changes, using a member of the <ph id="ph3">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated">W poniższym przykładzie użyto obsługi dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph> zdarzenie, aby zapisać aparat rozpoznawania na nowy <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;</ph> konsoli każdego czasu zmiany, przy użyciu członkiem <ph id="ph3">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> wyliczenia.</target>       </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>Gets or sets the time interval during which a <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> accepts input containing only background noise, before finalizing recognition.</source>
          <target state="translated">Pobiera lub ustawia przedział czasu, w którym <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> akceptuje wejściowych zawierających tylko szumu tła, przed zakończeniem rozpoznawania.</target>       </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>The duration of the time interval.</source>
          <target state="translated">Czas trwania interwału czasu.</target>       </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>Each speech recognizer has an algorithm to distinguish between silence and speech.</source>
          <target state="translated">Każdy aparat rozpoznawania mowy zawiera algorytm odróżnić wyciszenia mowy.</target>       </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>The recognizer classifies as background noise any non-silence input that does not match the initial rule of any of the recognizer's loaded and enabled speech recognition grammars.</source>
          <target state="translated">Aparat rozpoznawania klasyfikuje szumu tła żadnych innych niż wyciszenia wejściowej niezgodny początkowej reguły dowolnego aparat rozpoznawania załadowane i włączone gramatyki rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>If the recognizer receives only background noise and silence within the babble timeout interval, then the recognizer finalizes that recognition operation.</source>
          <target state="translated">Jeśli aparat rozpoznawania odbiera tylko hałas w tle i wyciszenia w babble — interwał limitu czasu, następnie aparat rozpoznawania Kończenie znajdujących się w tej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>For asynchronous recognition operations, the recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event, where the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=nameWithType&gt;</ph> property is <ph id="ph3">`true`</ph>, and the <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=nameWithType&gt;</ph> property is <ph id="ph5">`null`</ph>.</source>
          <target state="translated">Dla operacji asynchronicznych rozpoznawania zgłasza aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> zdarzeń, gdzie <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=nameWithType&gt;</ph> właściwość jest <ph id="ph3">`true`</ph>i <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=nameWithType&gt;</ph> jest właściwość <ph id="ph5">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>For synchronous recognition operations and emulation, the recognizer returns <ph id="ph1">`null`</ph>, instead of a valid <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</source>
          <target state="translated">Operacje synchroniczne rozpoznawania i emulacji zwraca aparat rozpoznawania <ph id="ph1">`null`</ph>, a nie jest prawidłowym <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>If the babble timeout period is set to 0, the recognizer does not perform a babble timeout check.</source>
          <target state="translated">Jeśli babble limit czasu jest ustawiona na 0, aparat rozpoznawania nie sprawdzić babble limitu czasu.</target>       </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>The timeout interval can be any non-negative value.</source>
          <target state="translated">Interwał limitu czasu może być wartością nieujemną.</target>       </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>The default is 0 seconds.</source>
          <target state="translated">Wartość domyślna to 0 sekund.</target>       </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>The following example shows part of a console application that demonstrates basic speech recognition that sets the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties of a <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> before initiating speech recognition.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część aplikacji konsoli, która przedstawia rozpoznawania mowy podstawowa, która ustawia <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> właściwości <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> przed zainicjowaniem rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>Handlers for the speech recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> events output event information to the console to demonstrate how the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties of a <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> affect recognition operations.</source>
          <target state="translated">Programy obsługi dla rozpoznawania mowy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> zdarzenia output informacji o zdarzeniu do konsoli, aby zademonstrować sposób <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> właściwości <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> wpływających na funkcjonowanie rozpoznawania.</target>       </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>This property is set to less than 0 seconds.</source>
          <target state="translated">Ta właściwość ma ustawioną mniejszy niż 0 sekund.</target>       </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> object.</source>
          <target state="translated">Usuwa <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Dispose">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> object.</source>
          <target state="translated">Usuwa <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> to release both managed and unmanaged resources; <ph id="ph2">&lt;see langword="false" /&gt;</ph> to release only unmanaged resources.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph> Aby zwolnić zasoby zarządzane i niezarządzane; <ph id="ph2">&lt;see langword="false" /&gt;</ph> aby zwolnić tylko zasoby niezarządzane.</target>       </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> object and releases resources used during the session.</source>
          <target state="translated">Usuwa <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> obiektu i zwalnia zasoby używane w podczas sesji.</target>       </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Emulates input to the speech recognizer, using text in place of audio for synchronous speech recognition.</source>
          <target state="translated">Emuluje dane wejściowe do rozpoznawania mowy, przy użyciu tekstu zamiast audio rozpoznawania mowy synchronicznego.</target>       </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>These methods bypass the system audio input and provide text to the recognizer as <ph id="ph1">&lt;xref:System.String&gt;</ph> objects or as an array of <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedWordUnit&gt;</ph> objects.</source>
          <target state="translated">Te metody obejścia wejście audio systemu i Przekaż do rozpoznawania jako <ph id="ph1">&lt;xref:System.String&gt;</ph> obiektów lub jako tablica <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedWordUnit&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>This can be helpful when you are testing or debugging an application or grammar.</source>
          <target state="translated">Może to być przydatne podczas testowania i debugowania aplikacji oraz błędy gramatyczne.</target>       </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>For example, you can use emulation to determine whether a word is in a grammar and what semantics are returned when the word is recognized.</source>
          <target state="translated">Na przykład można użyć emulacji do określenia czy wyraz jest w gramatyce i jakie semantyki są zwracane, gdy słowo jest rozpoznawana.</target>       </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;</ph> method to disable audio input to the speech recognition engine during emulation operations.</source>
          <target state="translated">Użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;</ph> metodę, aby wyłączyć wejście audio do aparatu rozpoznawania mowy podczas operacji emulacji.</target>       </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje aparatu rozpoznawania mowy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń tak, jakby nie jest emulowana operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Aparat rozpoznawania ignoruje nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</target>       </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object generated by the speech recognizer in response to emulated input has a value of <ph id="ph2">`null`</ph> for its <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> Obiektu wygenerowany przez aparat rozpoznawania mowy w odpowiedzi na dane wejściowe emulowanej ma wartość <ph id="ph2">`null`</ph> dla jego <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To emulate asynchronous recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> method.</source>
          <target state="translated">Aby emulować asynchroniczne rozpoznawanie, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The input for the recognition operation.</source>
          <target state="translated">Dane wejściowe dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for synchronous speech recognition.</source>
          <target state="translated">Emuluje wprowadzania frazę do rozpoznawania mowy, przy użyciu tekstu zamiast audio rozpoznawania mowy synchronicznego.</target>       </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Wynik operacji rozpoznawania lub <ph id="ph1">&lt;see langword="null" /&gt;</ph> Jeśli operacja nie powiedzie się lub nie włączono aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje aparatu rozpoznawania mowy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń tak, jakby nie jest emulowana operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter i znaków szerokości, stosując reguły gramatyki do wprowadzania frazy.</target>       </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
          <target state="translated">Aby uzyskać więcej informacji o tym typie porównanie, zobacz <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> wartości wyliczenia <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> i <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i Traktuj znaki interpunkcyjne jako dane wejściowe literału.</target>       </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The code example below is part of a console application that demonstrates emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">W poniższym przykładzie kodu jest częścią aplikacji konsoli, który demonstruje emulowanej danych wejściowych, wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The example generates the following output.</source>
          <target state="translated">Przykład generuje następujące dane wyjściowe.</target>       </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The recognizer has no speech recognition grammars loaded.</source>
          <target state="translated">Aparat rozpoznawania ma nie gramatyki rozpoznawania mowy załadowane.</target>       </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> jest <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">Tablica jednostki słowa zawierającego dane wejściowe dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</target>       </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>Emulates input of specific words to the speech recognizer, using text in place of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">Emuluje wprowadzania słów do rozpoznawania mowy, przy użyciu tekstu zamiast audio rozpoznawania mowy synchroniczne i określa sposób obsługi przez aparat rozpoznawania porównanie Unicode słów i gramatyki rozpoznawania mowy załadowany.</target>       </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Wynik operacji rozpoznawania lub <ph id="ph1">&lt;see langword="null" /&gt;</ph> Jeśli operacja nie powiedzie się lub nie włączono aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje aparatu rozpoznawania mowy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń tak, jakby nie jest emulowana operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Aparat rozpoznawania używa <ph id="ph1">`compareOptions`</ph> po stosuje reguły gramatyki do frazy wejściowych.</target>       </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> lub <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> ma wartość.</target>       </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer always ignores the character width and never ignores the Kana type.</source>
          <target state="translated">Aparat rozpoznawania zawsze ignoruje szerokość znaku i nigdy nie ignoruje typu znaki Kana.</target>       </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer also ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Aparat rozpoznawania również ignoruje nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</target>       </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> wyliczenia.</target>       </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer has no speech recognition grammars loaded.</source>
          <target state="translated">Aparat rozpoznawania ma nie gramatyki rozpoznawania mowy załadowane.</target>       </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> jest <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> contains one or more <ph id="ph2">&lt;see langword="null" /&gt;</ph> elements.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> zawiera co najmniej jeden <ph id="ph2">&lt;see langword="null" /&gt;</ph> elementów.</target>       </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> contains the <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph>, or <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> zawiera <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph>, lub <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph> flagi.</target>       </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">Wyrażenie wejściowych dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</target>       </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">Emuluje wprowadzania frazę do rozpoznawania mowy, przy użyciu tekstu zamiast audio rozpoznawania mowy synchroniczne i określa sposób obsługi przez aparat rozpoznawania Unicode porównanie frazę gramatyki rozpoznawania mowy załadowany.</target>       </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Wynik operacji rozpoznawania lub <ph id="ph1">&lt;see langword="null" /&gt;</ph> Jeśli operacja nie powiedzie się lub nie włączono aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje aparatu rozpoznawania mowy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń tak, jakby nie jest emulowana operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Aparat rozpoznawania używa <ph id="ph1">`compareOptions`</ph> po stosuje reguły gramatyki do frazy wejściowych.</target>       </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> lub <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> ma wartość.</target>       </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer always ignores the character width and never ignores the Kana type.</source>
          <target state="translated">Aparat rozpoznawania zawsze ignoruje szerokość znaku i nigdy nie ignoruje typu znaki Kana.</target>       </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer also ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Aparat rozpoznawania również ignoruje nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</target>       </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> wyliczenia.</target>       </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer has no speech recognition grammars loaded.</source>
          <target state="translated">Aparat rozpoznawania ma nie gramatyki rozpoznawania mowy załadowane.</target>       </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> jest <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> contains the <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph>, or <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> zawiera <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph>, lub <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph> flagi.</target>       </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Emulates input to the speech recognizer, using text in place of audio for asynchronous speech recognition.</source>
          <target state="translated">Emuluje dane wejściowe do rozpoznawania mowy, przy użyciu tekstu zamiast audio rozpoznawania mowy asynchronicznego.</target>       </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>These methods bypass the system audio input and provide text to the recognizer as <ph id="ph1">&lt;xref:System.String&gt;</ph> objects or as an array of <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedWordUnit&gt;</ph> objects.</source>
          <target state="translated">Te metody obejścia wejście audio systemu i Przekaż do rozpoznawania jako <ph id="ph1">&lt;xref:System.String&gt;</ph> obiektów lub jako tablica <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedWordUnit&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>This can be helpful when you are testing or debugging an application or grammar.</source>
          <target state="translated">Może to być przydatne podczas testowania i debugowania aplikacji oraz błędy gramatyczne.</target>       </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>For example, you can use emulation to determine whether a word is in a grammar and what semantics are returned when the word is recognized.</source>
          <target state="translated">Na przykład można użyć emulacji do określenia czy wyraz jest w gramatyce i jakie semantyki są zwracane, gdy słowo jest rozpoznawana.</target>       </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;</ph> method to disable audio input to the speech recognition engine during emulation operations.</source>
          <target state="translated">Użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;</ph> metodę, aby wyłączyć wejście audio do aparatu rozpoznawania mowy podczas operacji emulacji.</target>       </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje aparatu rozpoznawania mowy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń tak, jakby nie jest emulowana operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Po ukończeniu operacji asynchronicznej rozpoznawania aparat rozpoznawania zgłasza <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="298" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Aparat rozpoznawania ignoruje nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</target>       </trans-unit>
        <trans-unit id="299" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object generated by the speech recognizer in response to emulated input has a value of <ph id="ph2">`null`</ph> for its <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> Obiektu wygenerowany przez aparat rozpoznawania mowy w odpowiedzi na dane wejściowe emulowanej ma wartość <ph id="ph2">`null`</ph> dla jego <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="300" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To emulate synchronous recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph> method.</source>
          <target state="translated">Aby emulować rozpoznawania synchroniczne, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="301" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>The input for the recognition operation.</source>
          <target state="translated">Dane wejściowe dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="302" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for asynchronous speech recognition.</source>
          <target state="translated">Emuluje wprowadzania frazę do rozpoznawania mowy, przy użyciu tekstu zamiast audio rozpoznawania mowy asynchronicznego.</target>       </trans-unit>
        <trans-unit id="303" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje aparatu rozpoznawania mowy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń tak, jakby nie jest emulowana operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="304" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Po ukończeniu operacji asynchronicznej rozpoznawania aparat rozpoznawania zgłasza <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="305" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter i znaków szerokości, stosując reguły gramatyki do wprowadzania frazy.</target>       </trans-unit>
        <trans-unit id="306" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
          <target state="translated">Aby uzyskać więcej informacji o tym typie porównanie, zobacz <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> wartości wyliczenia <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> i <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="307" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i Traktuj znaki interpunkcyjne jako dane wejściowe literału.</target>       </trans-unit>
        <trans-unit id="308" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>The code example below is part of a console application that demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">W poniższym przykładzie kodu jest częścią aplikacji konsoli, która przedstawia asynchroniczne emulowanej danych wejściowych, wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="309" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>The example generates the following output.</source>
          <target state="translated">Przykład generuje następujące dane wyjściowe.</target>       </trans-unit>
        <trans-unit id="310" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>The recognizer has no speech recognition grammars loaded, or the recognizer has an asynchronous recognition operation that is not yet complete.</source>
          <target state="translated">Aparat rozpoznawania ma nie gramatyki rozpoznawania mowy załadowany lub aparat rozpoznawania ma operację asynchroniczną rozpoznawania, która nie jest jeszcze zakończona.</target>       </trans-unit>
        <trans-unit id="311" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> jest <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="312" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="313" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">Tablica jednostki słowa zawierającego dane wejściowe dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="314" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</target>       </trans-unit>
        <trans-unit id="315" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>Emulates input of specific words to the speech recognizer, using an array of <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.RecognizedWordUnit" /&gt;</ph> objects in place of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">Emuluje wprowadzania słów do rozpoznawania mowy, użycie tablicy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.RecognizedWordUnit" /&gt;</ph> obiektów zamiast audio rozpoznawania mowy asynchroniczne i określa sposób obsługi przez aparat rozpoznawania porównanie Unicode słów i załadować mowy rozpoznawanie gramatyki.</target>       </trans-unit>
        <trans-unit id="316" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje aparatu rozpoznawania mowy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń tak, jakby nie jest emulowana operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="317" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Po ukończeniu operacji asynchronicznej rozpoznawania aparat rozpoznawania zgłasza <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="318" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Aparat rozpoznawania używa <ph id="ph1">`compareOptions`</ph> po stosuje reguły gramatyki do frazy wejściowych.</target>       </trans-unit>
        <trans-unit id="319" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> lub <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> ma wartość.</target>       </trans-unit>
        <trans-unit id="320" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Aparatów rozpoznawania zawsze Ignoruj szerokość znaku i nigdy nie Ignoruj typu znaki Kana.</target>       </trans-unit>
        <trans-unit id="321" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i Traktuj znaki interpunkcyjne jako dane wejściowe literału.</target>       </trans-unit>
        <trans-unit id="322" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> wyliczenia.</target>       </trans-unit>
        <trans-unit id="323" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer has no speech recognition grammars loaded, or the recognizer has an asynchronous recognition operation that is not yet complete.</source>
          <target state="translated">Aparat rozpoznawania ma nie gramatyki rozpoznawania mowy załadowany lub aparat rozpoznawania ma operację asynchroniczną rozpoznawania, która nie jest jeszcze zakończona.</target>       </trans-unit>
        <trans-unit id="324" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> jest <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="325" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> contains one or more <ph id="ph2">&lt;see langword="null" /&gt;</ph> elements.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> zawiera co najmniej jeden <ph id="ph2">&lt;see langword="null" /&gt;</ph> elementów.</target>       </trans-unit>
        <trans-unit id="326" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> contains the <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph>, or <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> zawiera <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph>, lub <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph> flagi.</target>       </trans-unit>
        <trans-unit id="327" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">Wyrażenie wejściowych dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="328" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</target>       </trans-unit>
        <trans-unit id="329" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">Emuluje wprowadzania frazę do rozpoznawania mowy, przy użyciu tekstu zamiast audio rozpoznawania mowy asynchroniczne i określa sposób obsługi przez aparat rozpoznawania Unicode porównanie frazę gramatyki rozpoznawania mowy załadowany.</target>       </trans-unit>
        <trans-unit id="330" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje aparatu rozpoznawania mowy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń tak, jakby nie jest emulowana operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="331" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Po ukończeniu operacji asynchronicznej rozpoznawania aparat rozpoznawania zgłasza <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="332" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Aparat rozpoznawania używa <ph id="ph1">`compareOptions`</ph> po stosuje reguły gramatyki do frazy wejściowych.</target>       </trans-unit>
        <trans-unit id="333" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> lub <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> ma wartość.</target>       </trans-unit>
        <trans-unit id="334" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Aparatów rozpoznawania zawsze Ignoruj szerokość znaku i nigdy nie Ignoruj typu znaki Kana.</target>       </trans-unit>
        <trans-unit id="335" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i Traktuj znaki interpunkcyjne jako dane wejściowe literału.</target>       </trans-unit>
        <trans-unit id="336" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> wyliczenia.</target>       </trans-unit>
        <trans-unit id="337" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer has no speech recognition grammars loaded, or the recognizer has an asynchronous recognition operation that is not yet complete.</source>
          <target state="translated">Aparat rozpoznawania ma nie gramatyki rozpoznawania mowy załadowany lub aparat rozpoznawania ma operację asynchroniczną rozpoznawania, która nie jest jeszcze zakończona.</target>       </trans-unit>
        <trans-unit id="338" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> jest <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="339" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="340" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> contains the <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph>, or <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> zawiera <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph>, lub <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph> flagi.</target>       </trans-unit>
        <trans-unit id="341" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> finalizes an asynchronous recognition operation of emulated input.</source>
          <target state="translated">Wywoływane, gdy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> Kończenie znajdujących się w operacji asynchronicznych rozpoznawania emulowanej danych wejściowych.</target>       </trans-unit>
        <trans-unit id="342" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> method begins an asynchronous recognition operation.</source>
          <target state="translated">Każdy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metoda rozpoczyna operację asynchroniczną rozpoznawania.</target>       </trans-unit>
        <trans-unit id="343" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> raises the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event when it finalizes the asynchronous operation.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> Zgłasza <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> zdarzenie, gdy jego Kończenie znajdujących się w operacji asynchronicznej.</target>       </trans-unit>
        <trans-unit id="344" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> operation can raise the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> Może wiązać się z operacji <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, i <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzenia.</target>       </trans-unit>
        <trans-unit id="345" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event is the last such event that the recognizer raises for a given operation.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> Zdarzenie jest ostatni tych zdarzeń, że aparat rozpoznawania zgłasza dla danej operacji.</target>       </trans-unit>
        <trans-unit id="346" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>If emulated recognition was successful, you can access the recognition result using the either of the following:</source>
          <target state="translated">Rozpoznawanie emulowanej zakończyło się pomyślnie, można przejść do wyników rozpoznawania przy użyciu jednej z następujących czynności:</target>       </trans-unit>
        <trans-unit id="347" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt;</ph> property in the <ph id="ph2">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</ph> object in the handler for the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt;</ph> Właściwości w <ph id="ph2">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</ph> obiekt obsługi dla <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="348" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property in the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</ph> object in the handler for the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> właściwości w <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</ph> obiekt obsługi dla <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="349" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>If emulated recognition was not successful, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event is not raised and the <ph id="ph2">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt;</ph> will be null.</source>
          <target state="translated">Jeśli emulowanej rozpoznawania zakończyła się niepowodzeniem, <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> nie zdarzenia i <ph id="ph2">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt;</ph> będzie mieć wartość null.</target>       </trans-unit>
        <trans-unit id="350" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</ph> derives from <ph id="ph2">&lt;xref:System.ComponentModel.AsyncCompletedEventArgs&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</ph> pochodną <ph id="ph2">&lt;xref:System.ComponentModel.AsyncCompletedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="351" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</ph> derives from <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</ph> pochodną <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="352" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>When you create an <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Po utworzeniu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> delegata, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="353" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="354" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="355" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="356" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Poniższy przykład jest częścią aplikacji konsoli, który ładuje gramatyki rozpoznawania mowy i przedstawia asynchroniczne emulowanej danych wejściowych, wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="357" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>Gets or sets the interval of silence that the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> will accept at the end of unambiguous input before finalizing a recognition operation.</source>
          <target state="translated">Pobiera lub ustawia interwał wyciszenia, który <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> będzie akceptować na końcu danych wejściowych jednoznaczne przed zakończeniem operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="358" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>The duration of the interval of silence.</source>
          <target state="translated">Czas trwania interwału wyciszenia.</target>       </trans-unit>
        <trans-unit id="359" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>The speech recognizer uses this timeout interval when the recognition input is unambiguous.</source>
          <target state="translated">Aparat rozpoznawania mowy używa ten limit czasu podczas rozpoznawania danych wejściowych jest jednoznaczny.</target>       </trans-unit>
        <trans-unit id="360" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</source>
          <target state="translated">Na przykład dla gramatyki rozpoznawania mowy, która obsługuje rozpoznawanie albo "nowe gier, skontaktuj" lub "nowej gry", "nowe gier, skontaktuj" jest wejściem jednoznaczne i "nowej gry" jest niejednoznaczny danych wejściowych.</target>       </trans-unit>
        <trans-unit id="361" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>This property determines how long the speech recognition engine will wait for additional input before finalizing a recognition operation.</source>
          <target state="translated">Ta właściwość określa, jak długo aparat rozpoznawania mowy będzie czekać na dodatkowe dane wejściowe przed zakończeniem operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="362" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>The timeout interval can be from 0 seconds to 10 seconds, inclusive.</source>
          <target state="translated">Interwał limitu czasu może być z zakresu od 0 do 10 sekund włącznie.</target>       </trans-unit>
        <trans-unit id="363" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>The default is 150 milliseconds.</source>
          <target state="translated">Wartość domyślna wynosi 150 milisekund.</target>       </trans-unit>
        <trans-unit id="364" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>To set the timeout interval for ambiguous input, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> property.</source>
          <target state="translated">Aby ustawić interwał limitu czasu dla danych wejściowych niejednoznaczny, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="365" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>This property is set to less than 0 seconds or greater than 10 seconds.</source>
          <target state="translated">Ta właściwość ma wartość mniejszą niż 0 sekund lub większej niż 10 sekund.</target>       </trans-unit>
        <trans-unit id="366" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>Gets or sets the interval of silence that the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> will accept at the end of ambiguous input before finalizing a recognition operation.</source>
          <target state="translated">Pobiera lub ustawia interwał wyciszenia, który <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> będzie akceptować na końcu danych wejściowych niejednoznaczne przed zakończeniem operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="367" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>The duration of the interval of silence.</source>
          <target state="translated">Czas trwania interwału wyciszenia.</target>       </trans-unit>
        <trans-unit id="368" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>The speech recognizer uses this timeout interval when the recognition input is ambiguous.</source>
          <target state="translated">Aparat rozpoznawania mowy używa ten limit czasu podczas rozpoznawania danych wejściowych jest niejednoznaczna.</target>       </trans-unit>
        <trans-unit id="369" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</source>
          <target state="translated">Na przykład dla gramatyki rozpoznawania mowy, która obsługuje rozpoznawanie albo "nowe gier, skontaktuj" lub "nowej gry", "nowe gier, skontaktuj" jest wejściem jednoznaczne i "nowej gry" jest niejednoznaczny danych wejściowych.</target>       </trans-unit>
        <trans-unit id="370" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>This property determines how long the speech recognition engine will wait for additional input before finalizing a recognition operation.</source>
          <target state="translated">Ta właściwość określa, jak długo aparat rozpoznawania mowy będzie czekać na dodatkowe dane wejściowe przed zakończeniem operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="371" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>The timeout interval can be from 0 seconds to 10 seconds, inclusive.</source>
          <target state="translated">Interwał limitu czasu może być z zakresu od 0 do 10 sekund włącznie.</target>       </trans-unit>
        <trans-unit id="372" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>The default is 500 milliseconds.</source>
          <target state="translated">Wartość domyślna to 500 milisekund.</target>       </trans-unit>
        <trans-unit id="373" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>To set the timeout interval for unambiguous input, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> property.</source>
          <target state="translated">Aby ustawić interwał limitu czasu dla danych wejściowych jednoznaczne, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="374" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>This property is set to less than 0 seconds or greater than 10 seconds.</source>
          <target state="translated">Ta właściwość ma wartość mniejszą niż 0 sekund lub większej niż 10 sekund.</target>       </trans-unit>
        <trans-unit id="375" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.Grammars">
          <source>Gets a collection of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects that are loaded in this <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> instance.</source>
          <target state="translated">Pobiera kolekcję <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> obiektów, które są ładowane w tym <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> wystąpienia.</target>       </trans-unit>
        <trans-unit id="376" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.Grammars">
          <source>The collection of <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects.</source>
          <target state="translated">Kolekcja <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="377" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.Grammars">
          <source>The following example outputs information to the console for each speech recognition grammar that is currently loaded by a speech recognizer.</source>
          <target state="translated">Poniższy przykład danych wyjściowych informacji do konsoli dla każdego gramatyki rozpoznawania mowy, który jest aktualnie załadowany przez aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="378" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.Grammars">
          <source>Copy the grammar collection to avoid errors if the collection is modified while this method enumerates the elements of the collection.</source>
          <target state="translated">Skopiuj kolekcji gramatyki, aby uniknąć błędów, jeśli kolekcja zostanie zmodyfikowana w czasie tej metody wylicza elementy kolekcji.</target>       </trans-unit>
        <trans-unit id="379" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>Gets or sets the time interval during which a <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> accepts input containing only silence before finalizing recognition.</source>
          <target state="translated">Pobiera lub ustawia przedział czasu, w którym <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> akceptuje wejściowych zawierających tylko wyciszenia przed zakończeniem rozpoznawania.</target>       </trans-unit>
        <trans-unit id="380" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>The duration of the interval of silence.</source>
          <target state="translated">Czas trwania interwału wyciszenia.</target>       </trans-unit>
        <trans-unit id="381" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>Each speech recognizer has an algorithm to distinguish between silence and speech.</source>
          <target state="translated">Każdy aparat rozpoznawania mowy zawiera algorytm odróżnić wyciszenia mowy.</target>       </trans-unit>
        <trans-unit id="382" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>If the recognizer input is silence during the initial silence timeout period, then the recognizer finalizes that recognition operation.</source>
          <target state="translated">Jeśli dane wejściowe aparatu rozpoznawania jest wyciszenia podczas początkowej wyciszenia limitu czasu aparatu rozpoznawania Kończenie znajdujących się w tej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="383" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>For asynchronous recognition operations and emulation, the recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event, where the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=nameWithType&gt;</ph> property is <ph id="ph3">`true`</ph>, and the <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=nameWithType&gt;</ph> property is <ph id="ph5">`null`</ph>.</source>
          <target state="translated">Operacje asynchroniczne rozpoznawanie i emulacji zgłasza aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> zdarzeń, gdy <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=nameWithType&gt;</ph> właściwość jest <ph id="ph3">`true`</ph>i <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=nameWithType&gt;</ph> jest właściwość <ph id="ph5">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="384" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>For synchronous recognition operations and emulation, the recognizer returns <ph id="ph1">`null`</ph>, instead of a valid <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</source>
          <target state="translated">Operacje synchroniczne rozpoznawania i emulacji zwraca aparat rozpoznawania <ph id="ph1">`null`</ph>, a nie jest prawidłowym <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="385" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>If the initial silence timeout interval is set to 0, the recognizer does not perform an initial silence timeout check.</source>
          <target state="translated">Jeśli interwał limitu czasu początkowej wyciszenia jest ustawiony na 0, aparat rozpoznawania nie sprawdzić początkowej wyciszenia limitu czasu.</target>       </trans-unit>
        <trans-unit id="386" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>The timeout interval can be any non-negative value.</source>
          <target state="translated">Interwał limitu czasu może być wartością nieujemną.</target>       </trans-unit>
        <trans-unit id="387" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>The default is 0 seconds.</source>
          <target state="translated">Wartość domyślna to 0 sekund.</target>       </trans-unit>
        <trans-unit id="388" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część prezentującą rozpoznawania mowy podstawowe aplikacji konsoli.</target>       </trans-unit>
        <trans-unit id="389" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>The example sets the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties of a <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> before initiating speech recognition.</source>
          <target state="translated">Ustawia przykład <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> właściwości <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> przed zainicjowaniem rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="390" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>Handlers for the speech recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> events output event information to the console to demonstrate how the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties of a <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> properties affect recognition operations.</source>
          <target state="translated">Programy obsługi dla rozpoznawania mowy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> zdarzenia output informacji o zdarzeniu do konsoli, aby zademonstrować sposób <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> właściwości <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> właściwości wpływających na funkcjonowanie rozpoznawania.</target>       </trans-unit>
        <trans-unit id="391" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>This property is set to less than 0 seconds.</source>
          <target state="translated">Ta właściwość ma ustawioną mniejszy niż 0 sekund.</target>       </trans-unit>
        <trans-unit id="392" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers">
          <source>Returns information for all of the installed speech recognizers on the current system.</source>
          <target state="translated">Zwraca informacje dla wszystkich aparatów rozpoznawania mowy zainstalowanych w systemie.</target>       </trans-unit>
        <trans-unit id="393" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers">
          <source>A read-only collection of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.RecognizerInfo" /&gt;</ph> objects that describe the installed recognizers.</source>
          <target state="translated">Kolekcja tylko do odczytu <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.RecognizerInfo" /&gt;</ph> obiektów, które opisują zainstalowanych aparatów rozpoznawania.</target>       </trans-unit>
        <trans-unit id="394" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers">
          <source>To get information about the current recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt;</ph> property.</source>
          <target state="translated">Aby uzyskać informacje dotyczące bieżącego aparatu rozpoznawania, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="395" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część prezentującą rozpoznawania mowy podstawowe aplikacji konsoli.</target>       </trans-unit>
        <trans-unit id="396" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers">
          <source>The example uses the collection returned by the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> method to find a speech recognizer that supports the English language.</source>
          <target state="translated">W przykładzie użyto kolekcji zwróconej przez <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> metody do znalezienia aparat rozpoznawania mowy obsługującego język angielski.</target>       </trans-unit>
        <trans-unit id="397" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The grammar object to load.</source>
          <target state="translated">Obiekt gramatyki do załadowania.</target>       </trans-unit>
        <trans-unit id="398" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>Synchronously loads a <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> object.</source>
          <target state="translated">Ładuje synchronicznie <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="399" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The recognizer throws an exception if the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">Aparat rozpoznawania zgłasza wyjątek, jeśli <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu jest już załadowany, jest ładowany asynchronicznie lub nie można załadować do dowolnego aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="400" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>You cannot load the same <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object into multiple instances of <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>.</source>
          <target state="translated">Nie można załadować takie same <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu do wielu wystąpień <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="401" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>Instead, create a new <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object for each <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance.</source>
          <target state="translated">Zamiast tego utwórz nową <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekt dla każdego <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> wystąpienia.</target>       </trans-unit>
        <trans-unit id="402" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Jeśli aparat rozpoznawania jest uruchomiona, aplikacje muszą używać <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> wstrzymania aparat rozpoznawania mowy przed ładowania, zwalnianie, włączanie lub wyłączanie gramatyki.</target>       </trans-unit>
        <trans-unit id="403" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>When you load a grammar, it is enabled by default.</source>
          <target state="translated">Podczas ładowania gramatyki jest włączona domyślnie.</target>       </trans-unit>
        <trans-unit id="404" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>To disable a loaded grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;</ph> property.</source>
          <target state="translated">Aby wyłączyć załadować gramatyki, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="405" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>To load a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object asynchronously, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Aby załadować <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> asynchronicznie obiektów, użyj <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="406" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część prezentującą rozpoznawania mowy podstawowe aplikacji konsoli.</target>       </trans-unit>
        <trans-unit id="407" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The example creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> and loads it into a speech recognizer.</source>
          <target state="translated">W przykładzie jest tworzony <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> i ładuje go do rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="408" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> jest <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="409" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> is not in a valid state.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> nie jest w prawidłowym stanie.</target>       </trans-unit>
        <trans-unit id="410" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">Rozpoznawanie mowy gramatyki do załadowania.</target>       </trans-unit>
        <trans-unit id="411" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>Asynchronously loads a speech recognition grammar.</source>
          <target state="translated">Asynchronicznie ładuje gramatyki rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="412" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>When the recognizer completes loading a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object, it raises a <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt;</ph> event.</source>
          <target state="translated">Gdy aparat rozpoznawania zakończeniu ładowania <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekt zgłasza <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="413" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The recognizer throws an exception if the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">Aparat rozpoznawania zgłasza wyjątek, jeśli <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu jest już załadowany, jest ładowany asynchronicznie lub nie można załadować do dowolnego aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="414" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>You cannot load the same <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object into multiple instances of <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>.</source>
          <target state="translated">Nie można załadować takie same <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu do wielu wystąpień <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="415" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>Instead, create a new <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object for each <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance.</source>
          <target state="translated">Zamiast tego utwórz nową <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekt dla każdego <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> wystąpienia.</target>       </trans-unit>
        <trans-unit id="416" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Jeśli aparat rozpoznawania jest uruchomiona, aplikacje muszą używać <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> wstrzymania aparat rozpoznawania mowy przed ładowania, zwalnianie, włączanie lub wyłączanie gramatyki.</target>       </trans-unit>
        <trans-unit id="417" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>When you load a grammar, it is enabled by default.</source>
          <target state="translated">Podczas ładowania gramatyki jest włączona domyślnie.</target>       </trans-unit>
        <trans-unit id="418" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>To disable a loaded grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;</ph> property.</source>
          <target state="translated">Aby wyłączyć załadować gramatyki, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="419" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>To load a speech recognition grammar synchronously, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> method.</source>
          <target state="translated">Aby załadować gramatyki rozpoznawania mowy synchronicznie, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="420" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> jest <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="421" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> is not in a valid state.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> nie jest w prawidłowym stanie.</target>       </trans-unit>
        <trans-unit id="422" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The asynchronous operation was canceled.</source>
          <target state="translated">Operacja asynchroniczna została anulowana.</target>       </trans-unit>
        <trans-unit id="423" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> finishes the asynchronous loading of a <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> object.</source>
          <target state="translated">Wywoływane, gdy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> zakończeniu asynchroniczne ładowanie <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="424" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>The recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method initiates an asynchronous operation.</source>
          <target state="translated">Aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metoda inicjuje operację asynchroniczną.</target>       </trans-unit>
        <trans-unit id="425" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> raises this event when it completes the operation.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> Zgłasza zdarzenie, to po zakończeniu tej operacji.</target>       </trans-unit>
        <trans-unit id="426" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>To get the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object that the recognizer loaded, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;</ph> property of the associated <ph id="ph3">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ph>.</source>
          <target state="translated">Aby uzyskać <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekt, aby załadować aparat rozpoznawania, użyj <ph id="ph2">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;</ph> właściwości skojarzonego <ph id="ph3">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="427" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>To get the current <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects the recognizer has loaded, use the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt;</ph> property.</source>
          <target state="translated">Aby uzyskać bieżącą <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekty aparat rozpoznawania został załadowany, używają aparat rozpoznawania <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="428" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Jeśli aparat rozpoznawania jest uruchomiona, aplikacje muszą używać <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> wstrzymania aparat rozpoznawania mowy przed ładowania, zwalnianie, włączanie lub wyłączanie gramatyki.</target>       </trans-unit>
        <trans-unit id="429" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>When you create a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Po utworzeniu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt;</ph> delegata, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="430" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="431" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="432" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="433" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>The following example creates an in-process speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</source>
          <target state="translated">Poniższy przykład tworzy rozpoznawania mowy w procesie, a następnie tworzy dwa typy gramatyki rozpoznawania słów i akceptowania dyktowania wolne.</target>       </trans-unit>
        <trans-unit id="434" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>The example constructs a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object from each of the completed speech recognition grammars, then asynchronously loads the <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance.</source>
          <target state="translated">Przykład tworzy <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu z każdej gramatyki rozpoznawania mowy ukończone asynchronicznie ładuje <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekty do <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> wystąpienia.</target>       </trans-unit>
        <trans-unit id="435" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>Handlers for the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events write to the console the name of the <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object that was used to perform the recognition and the text of the recognition result, respectively.</source>
          <target state="translated">Programy obsługi dla aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzenia zapisać konsolę nazwę <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekt używany do wykonywania uznania i tekst w wyniku rozpoznawania odpowiednio.</target>       </trans-unit>
        <trans-unit id="436" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates">
          <source>Gets or sets the maximum number of alternate recognition results that the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> returns for each recognition operation.</source>
          <target state="translated">Pobiera lub ustawia maksymalną liczbę wyników rozpoznawania alternatywnego, który <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> zwraca dla każdej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="437" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates">
          <source>The number of alternate results to return.</source>
          <target state="translated">Liczba alternatywny wyników do zwrócenia.</target>       </trans-unit>
        <trans-unit id="438" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> class contains the collection of <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> objects that represent possible interpretations of the input.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> Właściwość <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> klasy zawiera kolekcję <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> obiekty reprezentujące możliwe interpretacje danych wejściowych.</target>       </trans-unit>
        <trans-unit id="439" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates">
          <source>The default value for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A&gt;</ph> is 10.</source>
          <target state="translated">Wartość domyślna dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A&gt;</ph> wynosi 10.</target>       </trans-unit>
        <trans-unit id="440" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates">
          <source><ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates" /&gt;</ph> is set to a value less than 0.</source>
          <target state="translated"><ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates" /&gt;</ph> ma ustawioną wartość mniejszą niż 0.</target>       </trans-unit>
        <trans-unit id="441" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The name of the setting to return.</source>
          <target state="translated">Nazwa ustawienia do zwrócenia.</target>       </trans-unit>
        <trans-unit id="442" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Returns the values of settings for the recognizer.</source>
          <target state="translated">Zwraca wartości ustawień przez aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="443" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The value of the setting.</source>
          <target state="translated">Wartość ustawienia.</target>       </trans-unit>
        <trans-unit id="444" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Recognizer settings can contain string, 64-bit integer, or memory address data.</source>
          <target state="translated">Ustawienia aparatu rozpoznawania może zawierać ciągu, 64-bitową liczbą całkowitą lub dane adresów pamięci.</target>       </trans-unit>
        <trans-unit id="445" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The following table describes the settings that are defined for a Microsoft Speech API (SAPI)-compliant recognizer.</source>
          <target state="translated">W poniższej tabeli opisano ustawienia, które są zdefiniowane dla interfejsu API mowy firmy Microsoft (SAPI)-zgodne aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="446" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The following settings must have the same range for each recognizer that supports the setting.</source>
          <target state="translated">Następujące ustawienia należy skonfigurować każdy aparat rozpoznawania, który obsługuje ustawienie tego samego zakresu.</target>       </trans-unit>
        <trans-unit id="447" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>A SAPI-compliant recognizer is not required to support these settings and can support other settings.</source>
          <target state="translated">Zgodne SAPI aparat rozpoznawania nie jest wymagany do obsługi tych ustawień i może obsługiwać inne ustawienia.</target>       </trans-unit>
        <trans-unit id="448" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Name</source>
          <target state="translated">Nazwa</target>       </trans-unit>
        <trans-unit id="449" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Description</source>
          <target state="translated">Opis</target>       </trans-unit>
        <trans-unit id="450" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Specifies the recognizer's CPU consumption.</source>
          <target state="translated">Określa użycie procesora CPU przez aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="451" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The range is from 0 to 100.</source>
          <target state="translated">Zakres wynosi od 0 do 100.</target>       </trans-unit>
        <trans-unit id="452" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The default value is 50.</source>
          <target state="translated">Wartością domyślną jest 50.</target>       </trans-unit>
        <trans-unit id="453" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Indicates the length of silence at the end of unambiguous input before the speech recognizer completes a recognition operation.</source>
          <target state="translated">Wskazuje długość wyciszenia na końcu danych wejściowych jednoznaczne ukończenia operacji rozpoznawania rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="454" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The range is from 0 to 10,000 milliseconds (ms).</source>
          <target state="translated">Zakres wynosi od 0 do 10 000 w milisekundach (ms).</target>       </trans-unit>
        <trans-unit id="455" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>This setting corresponds to the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> property.</source>
          <target state="translated">To ustawienie odpowiada aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="456" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Default = 150ms.</source>
          <target state="translated">Domyślne = 150ms.</target>       </trans-unit>
        <trans-unit id="457" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Indicates the length of silence at the end of ambiguous input before the speech recognizer completes a recognition operation.</source>
          <target state="translated">Wskazuje długość wyciszenia na końcu danych wejściowych niejednoznaczne ukończenia operacji rozpoznawania rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="458" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The range is from 0 to 10,000ms.</source>
          <target state="translated">Zakres wynosi od 0 do 10,000ms.</target>       </trans-unit>
        <trans-unit id="459" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>This setting corresponds to the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> property.</source>
          <target state="translated">To ustawienie odpowiada aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="460" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Default = 500ms.</source>
          <target state="translated">Domyślnie 500 MS.</target>       </trans-unit>
        <trans-unit id="461" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Indicates whether adaptation of the acoustic model is ON (value = <ph id="ph1">`1`</ph>) or OFF (value = <ph id="ph2">`0`</ph>).</source>
          <target state="translated">Wskazuje, czy dostosowania modelu akustycznego jest ON (wartość = <ph id="ph1">`1`</ph>) lub OFF (wartość = <ph id="ph2">`0`</ph>).</target>       </trans-unit>
        <trans-unit id="462" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The default value is <ph id="ph1">`1`</ph> (ON).</source>
          <target state="translated">Wartość domyślna to <ph id="ph1">`1`</ph> (dalej).</target>       </trans-unit>
        <trans-unit id="463" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Indicates whether background adaptation is ON (value = <ph id="ph1">`1`</ph>) or OFF (value = <ph id="ph2">`0`</ph>), and persists the setting in the registry.</source>
          <target state="translated">Wskazuje, czy adaptacja w tle jest ON (wartość = <ph id="ph1">`1`</ph>) lub OFF (wartość = <ph id="ph2">`0`</ph>), będzie się powtarzał ustawienie w rejestrze.</target>       </trans-unit>
        <trans-unit id="464" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The default value is <ph id="ph1">`1`</ph> (ON).</source>
          <target state="translated">Wartość domyślna to <ph id="ph1">`1`</ph> (dalej).</target>       </trans-unit>
        <trans-unit id="465" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>To update a setting for the recognizer, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> methods.</source>
          <target state="translated">Aby zaktualizować ustawienia przez aparat rozpoznawania, użyj jednej z <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="466" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The following example is part of a console application that outputs the values for a number of the settings defined for the recognizer that supports the en-US locale.</source>
          <target state="translated">Poniższy przykład jest częścią aplikacji konsoli, która wyświetla wartości dla wielu ustawień zdefiniowanych przez aparat rozpoznawania, który obsługuje ustawień regionalnych pl pl.</target>       </trans-unit>
        <trans-unit id="467" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The example generates the following output.</source>
          <target state="translated">Przykład generuje następujące dane wyjściowe.</target>       </trans-unit>
        <trans-unit id="468" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> jest <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="469" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="470" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The recognizer does not have a setting by that name.</source>
          <target state="translated">Aparat rozpoznawania nie ma ustawienie o takiej nazwie.</target>       </trans-unit>
        <trans-unit id="471" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Starts a synchronous speech recognition operation.</source>
          <target state="translated">Rozpoczyna operację rozpoznawania mowy synchronicznego.</target>       </trans-unit>
        <trans-unit id="472" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>These methods perform a single, synchronous recognition operation.</source>
          <target state="translated">Te metody operacji rozpoznawania jednej, synchronicznego.</target>       </trans-unit>
        <trans-unit id="473" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer performs this operation against its loaded and enabled speech recognition grammars.</source>
          <target state="translated">Aparat rozpoznawania wykonuje tę operację przed jego gramatyki rozpoznawania mowy załadowany i włączona.</target>       </trans-unit>
        <trans-unit id="474" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>During a call to this method, the recognizer can raise the following events:</source>
          <target state="translated">Podczas wywoływania tej metody aparat rozpoznawania wywołuje następujące zdarzenia:</target>       </trans-unit>
        <trans-unit id="475" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="476" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania wykrywa danych wejściowych, którą można zidentyfikować jako mowy.</target>       </trans-unit>
        <trans-unit id="477" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="478" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Wywoływane, gdy dane wejściowe tworzy niejednoznaczne dopasowanie z jednej aktywnej gramatyki.</target>       </trans-unit>
        <trans-unit id="479" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="480" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania Kończenie znajdujących się w operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="481" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer does not raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event when using one of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> methods.</source>
          <target state="translated">Aparat rozpoznawania nie wygenerował <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> zdarzenie, gdy przy użyciu jednej z <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="482" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> methods return a <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object, or <ph id="ph3">`null`</ph> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> Metody zwracają <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> obiekt, lub <ph id="ph3">`null`</ph> Jeśli operacja nie powiedzie się lub nie włączono aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="483" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>A synchronous recognition operation can fail for the following reasons:</source>
          <target state="translated">Operacja synchroniczna rozpoznawania może się nie powieść z następujących powodów:</target>       </trans-unit>
        <trans-unit id="484" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Speech is not detected before the timeout intervals expire for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties, or for the <ph id="ph3">`initialSilenceTimeout`</ph> parameter of the <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> method.</source>
          <target state="translated">Mowy nie wykrywa odstępach czasu wygaśnięcia dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> właściwości lub <ph id="ph3">`initialSilenceTimeout`</ph> parametr <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="485" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognition engine detects speech but finds no matches in any of its loaded and enabled <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Aparat rozpoznawania wykrywa mowy, ale znajduje żadnych dopasowań w dowolnej z załadowanych i włączona <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="486" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To modify how the recognizer handles the timing of speech or silence with respect to recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> properties.</source>
          <target state="translated">Aby zmodyfikować sposób obsługi przez aparat rozpoznawania czas mowy wyciszenia względem rozpoznawania, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="487" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> must have at least one <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object loaded before performing recognition.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> Musi mieć co najmniej jeden <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekt załadowany przed przeprowadzeniem rozpoznawania.</target>       </trans-unit>
        <trans-unit id="488" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To load a speech recognition grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Aby załadować gramatyki rozpoznawania mowy, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="489" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To perform asynchronous recognition, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Aby przeprowadzić rozpoznawanie asynchroniczne, użyj jednej z <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="490" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>Performs a synchronous speech recognition operation.</source>
          <target state="translated">Wykonuje operację rozpoznawania mowy synchronicznego.</target>       </trans-unit>
        <trans-unit id="491" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>The recognition result for the input, or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Wynik rozpoznawania dla danych wejściowych, lub <ph id="ph1">&lt;see langword="null" /&gt;</ph> Jeśli operacja nie powiedzie się lub nie włączono aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="492" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>This method performs a single recognition operation.</source>
          <target state="translated">Ta metoda wykonuje operację pojedynczego rozpoznawania.</target>       </trans-unit>
        <trans-unit id="493" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>The recognizer performs this operation against its loaded and enabled speech recognition grammars.</source>
          <target state="translated">Aparat rozpoznawania wykonuje tę operację przed jego gramatyki rozpoznawania mowy załadowany i włączona.</target>       </trans-unit>
        <trans-unit id="494" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>During a call to this method, the recognizer can raise the following events:</source>
          <target state="translated">Podczas wywoływania tej metody aparat rozpoznawania wywołuje następujące zdarzenia:</target>       </trans-unit>
        <trans-unit id="495" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="496" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania wykrywa danych wejściowych, którą można zidentyfikować jako mowy.</target>       </trans-unit>
        <trans-unit id="497" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="498" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Wywoływane, gdy dane wejściowe tworzy niejednoznaczne dopasowanie z jednej aktywnej gramatyki.</target>       </trans-unit>
        <trans-unit id="499" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="500" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania Kończenie znajdujących się w operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="501" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>The recognizer does not raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event when using this method.</source>
          <target state="translated">Aparat rozpoznawania nie wygenerował <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> zdarzeń przy użyciu tej metody.</target>       </trans-unit>
        <trans-unit id="502" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize&gt;</ph> method returns a <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object, or <ph id="ph3">`null`</ph> if the operation is not successful.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize&gt;</ph> Metoda zwraca <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> obiekt, lub <ph id="ph3">`null`</ph> Jeśli operacja nie powiedzie.</target>       </trans-unit>
        <trans-unit id="503" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>A synchronous recognition operation can fail for the following reasons:</source>
          <target state="translated">Operacja synchroniczna rozpoznawania może się nie powieść z następujących powodów:</target>       </trans-unit>
        <trans-unit id="504" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>Speech is not detected before the timeout intervals expire for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties.</source>
          <target state="translated">Mowy nie wykrywa odstępach czasu wygaśnięcia dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="505" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>The recognition engine detects speech but finds no matches in any of its loaded and enabled <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Aparat rozpoznawania wykrywa mowy, ale znajduje żadnych dopasowań w dowolnej z załadowanych i włączona <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="506" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>To perform asynchronous recognition, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Aby przeprowadzić rozpoznawanie asynchroniczne, użyj jednej z <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="507" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część prezentującą rozpoznawania mowy podstawowe aplikacji konsoli.</target>       </trans-unit>
        <trans-unit id="508" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>The example creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>, loads it into an in-process speech recognizer, and performs one recognition operation.</source>
          <target state="translated">W przykładzie jest tworzony <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>ładuje go do rozpoznawania mowy w trakcie i wykonuje jednej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="509" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The interval of time a speech recognizer accepts input containing only silence before finalizing recognition.</source>
          <target state="translated">Przedział czasu, który akceptuje rozpoznawania mowy wejściowych zawierających tylko wyciszenia przed zakończeniem rozpoznawania.</target>       </trans-unit>
        <trans-unit id="510" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>Performs a synchronous speech recognition operation with a specified initial silence timeout period.</source>
          <target state="translated">Wykonuje operację rozpoznawania mowy synchroniczne okres limitu czasu określonego wyciszenia początkowej.</target>       </trans-unit>
        <trans-unit id="511" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The recognition result for the input, or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Wynik rozpoznawania dla danych wejściowych, lub <ph id="ph1">&lt;see langword="null" /&gt;</ph> Jeśli operacja nie powiedzie się lub nie włączono aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="512" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>If the speech recognition engine detects speech within the time interval specified by <ph id="ph1">`initialSilenceTimeout`</ph> argument, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%28System.TimeSpan%29&gt;</ph> performs a single recognition operation and then terminates.</source>
          <target state="translated">Jeśli aparat rozpoznawania mowy wykrywa mowy w czasie określonym przez <ph id="ph1">`initialSilenceTimeout`</ph> argumentu, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%28System.TimeSpan%29&gt;</ph> wykonuje operację pojedynczego rozpoznawania, a następnie kończy.</target>       </trans-unit>
        <trans-unit id="513" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The <ph id="ph1">`initialSilenceTimeout`</ph> parameter supersedes the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> property.</source>
          <target state="translated"><ph id="ph1">`initialSilenceTimeout`</ph> Parametru zastępuje aparat rozpoznawania <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="514" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>During a call to this method, the recognizer can raise the following events:</source>
          <target state="translated">Podczas wywoływania tej metody aparat rozpoznawania wywołuje następujące zdarzenia:</target>       </trans-unit>
        <trans-unit id="515" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="516" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania wykrywa danych wejściowych, którą można zidentyfikować jako mowy.</target>       </trans-unit>
        <trans-unit id="517" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="518" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Wywoływane, gdy dane wejściowe tworzy niejednoznaczne dopasowanie z jednej aktywnej gramatyki.</target>       </trans-unit>
        <trans-unit id="519" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="520" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania Kończenie znajdujących się w operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="521" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The recognizer does not raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event when using this method.</source>
          <target state="translated">Aparat rozpoznawania nie wygenerował <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> zdarzeń przy użyciu tej metody.</target>       </trans-unit>
        <trans-unit id="522" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize&gt;</ph> method returns a <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object, or <ph id="ph3">`null`</ph> if the operation is not successful.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize&gt;</ph> Metoda zwraca <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> obiekt, lub <ph id="ph3">`null`</ph> Jeśli operacja nie powiedzie.</target>       </trans-unit>
        <trans-unit id="523" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>A synchronous recognition operation can fail for the following reasons:</source>
          <target state="translated">Operacja synchroniczna rozpoznawania może się nie powieść z następujących powodów:</target>       </trans-unit>
        <trans-unit id="524" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>Speech is not detected before the timeout intervals expire for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> or for the <ph id="ph2">`initialSilenceTimeout`</ph> parameter.</source>
          <target state="translated">Mowy nie wykrywa odstępach czasu wygaśnięcia dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> lub <ph id="ph2">`initialSilenceTimeout`</ph> parametru.</target>       </trans-unit>
        <trans-unit id="525" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The recognition engine detects speech but finds no matches in any of its loaded and enabled <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Aparat rozpoznawania wykrywa mowy, ale znajduje żadnych dopasowań w dowolnej z załadowanych i włączona <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="526" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>To perform asynchronous recognition, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Aby przeprowadzić rozpoznawanie asynchroniczne, użyj jednej z <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="527" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część prezentującą rozpoznawania mowy podstawowe aplikacji konsoli.</target>       </trans-unit>
        <trans-unit id="528" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The example creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>, loads it into an in-process speech recognizer, and performs one recognition operation.</source>
          <target state="translated">W przykładzie jest tworzony <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>ładuje go do rozpoznawania mowy w trakcie i wykonuje jednej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="529" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Starts an asynchronous speech recognition operation.</source>
          <target state="translated">Rozpoczyna operację rozpoznawania mowy asynchronicznego.</target>       </trans-unit>
        <trans-unit id="530" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>These methods perform single or multiple, asynchronous recognition operations.</source>
          <target state="translated">Te metody wykonywania pojedyncze lub wielokrotne, operacje asynchroniczne rozpoznawania.</target>       </trans-unit>
        <trans-unit id="531" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer performs each operation against its loaded and enabled speech recognition grammars.</source>
          <target state="translated">Aparat rozpoznawania wykonuje każdej operacji przed jego gramatyki rozpoznawania mowy załadowany i włączona.</target>       </trans-unit>
        <trans-unit id="532" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>During a call to this method, the recognizer can raise the following events:</source>
          <target state="translated">Podczas wywoływania tej metody aparat rozpoznawania wywołuje następujące zdarzenia:</target>       </trans-unit>
        <trans-unit id="533" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="534" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania wykrywa danych wejściowych, którą można zidentyfikować jako mowy.</target>       </trans-unit>
        <trans-unit id="535" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="536" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Wywoływane, gdy dane wejściowe tworzy niejednoznaczne dopasowanie z jednej aktywnej gramatyki.</target>       </trans-unit>
        <trans-unit id="537" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="538" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania Kończenie znajdujących się w operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="539" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="540" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Raised when a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> operation finishes.</source>
          <target state="translated">Wywoływane, gdy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> zakończenie operacji.</target>       </trans-unit>
        <trans-unit id="541" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To retrieve the result of an asynchronous recognition operation, attach an event handler to the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Aby uzyskać wynik operacji asynchronicznej rozpoznawania, Dołącz program obsługi zdarzeń dla aparatu rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="542" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer raises this event whenever it successfully completes a synchronous or asynchronous recognition operation.</source>
          <target state="translated">Aparat rozpoznawania zgłasza tego zdarzenia przy każdym pomyślnym zakończeniu operacji rozpoznawania synchroniczna lub asynchroniczna.</target>       </trans-unit>
        <trans-unit id="543" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>If recognition was not successful, the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</ph> property on <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> object, which you can access in the handler for the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event, will be <ph id="ph4">`null`</ph>.</source>
          <target state="translated">Jeśli rozpoznawania zakończyła się niepowodzeniem, <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</ph> właściwość <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> obiektu, który można uzyskać dostępu do programu obsługi dla <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> będzie zdarzenia <ph id="ph4">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="544" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>An asynchronous recognition operation can fail for the following reasons:</source>
          <target state="translated">Operacja asynchronicznego rozpoznawania może się nie powieść z następujących powodów:</target>       </trans-unit>
        <trans-unit id="545" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Speech is not detected before the timeout intervals expire for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties.</source>
          <target state="translated">Mowy nie wykrywa odstępach czasu wygaśnięcia dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="546" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognition engine detects speech but finds no matches in any of its loaded and enabled <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Aparat rozpoznawania wykrywa mowy, ale znajduje żadnych dopasowań w dowolnej z załadowanych i włączona <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="547" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> must have at least one <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object loaded before performing recognition.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> Musi mieć co najmniej jeden <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekt załadowany przed przeprowadzeniem rozpoznawania.</target>       </trans-unit>
        <trans-unit id="548" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To load a speech recognition grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Aby załadować gramatyki rozpoznawania mowy, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="549" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To modify how the recognizer handles the timing of speech or silence with respect to recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> properties.</source>
          <target state="translated">Aby zmodyfikować sposób obsługi przez aparat rozpoznawania czas mowy wyciszenia względem rozpoznawania, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="550" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To perform synchronous recognition, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> methods.</source>
          <target state="translated">Aby przeprowadzić rozpoznawanie synchroniczne, użyj jednej z <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="551" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>Performs a single, asynchronous speech recognition operation.</source>
          <target state="translated">Wykonuje operację rozpoznawania mowy pojedynczego, asynchronicznego.</target>       </trans-unit>
        <trans-unit id="552" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>This method performs a single, asynchronous recognition operation.</source>
          <target state="translated">Ta metoda wykonuje operację rozpoznawania pojedynczego, asynchronicznego.</target>       </trans-unit>
        <trans-unit id="553" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>The recognizer performs the operation against its loaded and enabled speech recognition grammars.</source>
          <target state="translated">Aparat rozpoznawania wykonuje operację względem jego gramatyki rozpoznawania mowy załadowany i włączona.</target>       </trans-unit>
        <trans-unit id="554" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>During a call to this method, the recognizer can raise the following events:</source>
          <target state="translated">Podczas wywoływania tej metody aparat rozpoznawania wywołuje następujące zdarzenia:</target>       </trans-unit>
        <trans-unit id="555" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="556" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania wykrywa danych wejściowych, którą można zidentyfikować jako mowy.</target>       </trans-unit>
        <trans-unit id="557" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="558" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Wywoływane, gdy dane wejściowe tworzy niejednoznaczne dopasowanie z jednej aktywnej gramatyki.</target>       </trans-unit>
        <trans-unit id="559" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="560" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania Kończenie znajdujących się w operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="561" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="562" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>Raised when a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> operation finishes.</source>
          <target state="translated">Wywoływane, gdy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> zakończenie operacji.</target>       </trans-unit>
        <trans-unit id="563" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>To retrieve the result of an asynchronous recognition operation, attach an event handler to the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Aby uzyskać wynik operacji asynchronicznej rozpoznawania, Dołącz program obsługi zdarzeń dla aparatu rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="564" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>The recognizer raises this event whenever it successfully completes a synchronous or asynchronous recognition operation.</source>
          <target state="translated">Aparat rozpoznawania zgłasza tego zdarzenia przy każdym pomyślnym zakończeniu operacji rozpoznawania synchroniczna lub asynchroniczna.</target>       </trans-unit>
        <trans-unit id="565" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>If recognition was not successful, the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</ph> property on <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> object, which you can access in the handler for the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event, will be <ph id="ph4">`null`</ph>.</source>
          <target state="translated">Jeśli rozpoznawania zakończyła się niepowodzeniem, <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</ph> właściwość <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> obiektu, który można uzyskać dostępu do programu obsługi dla <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> będzie zdarzenia <ph id="ph4">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="566" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>To perform synchronous recognition, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> methods.</source>
          <target state="translated">Aby przeprowadzić rozpoznawanie synchroniczne, użyj jednej z <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="567" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>The following example shows part of a console application that demonstrates basic asynchronous speech recognition.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część prezentującą rozpoznawania mowy asynchroniczne podstawowe aplikacji konsoli.</target>       </trans-unit>
        <trans-unit id="568" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>The example creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>, loads it into an in-process speech recognizer, and performs one asynchronous recognition operation.</source>
          <target state="translated">W przykładzie jest tworzony <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>ładuje go do rozpoznawania mowy w trakcie i wykonuje jedną operację asynchroniczną rozpoznawania.</target>       </trans-unit>
        <trans-unit id="569" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>Event handlers are included to demonstrate the events that the recognizer raises during the operation.</source>
          <target state="translated">Aby pokazać zdarzenia, które wywołuje aparat rozpoznawania podczas operacji znajdują się procedury obsługi zdarzeń.</target>       </trans-unit>
        <trans-unit id="570" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Indicates whether to perform one or multiple recognition operations.</source>
          <target state="translated">Wskazuje, czy wykonywanie jednego lub wielu operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="571" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Performs one or more asynchronous speech recognition operations.</source>
          <target state="translated">Wykonuje jeden lub więcej operacji rozpoznawania mowy asynchronicznego.</target>       </trans-unit>
        <trans-unit id="572" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>If <ph id="ph1">`mode`</ph> is <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeMode.Multiple&gt;</ph>, the recognizer continues performing asynchronous recognition operations until the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;</ph> or <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;</ph> method is called.</source>
          <target state="translated">Jeśli <ph id="ph1">`mode`</ph> jest <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeMode.Multiple&gt;</ph>, aparat rozpoznawania kontynuuje wykonywanie operacji asynchronicznych rozpoznawania do <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;</ph> lub <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;</ph> metoda jest wywoływana.</target>       </trans-unit>
        <trans-unit id="573" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>During a call to this method, the recognizer can raise the following events:</source>
          <target state="translated">Podczas wywoływania tej metody aparat rozpoznawania wywołuje następujące zdarzenia:</target>       </trans-unit>
        <trans-unit id="574" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="575" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania wykrywa danych wejściowych, którą można zidentyfikować jako mowy.</target>       </trans-unit>
        <trans-unit id="576" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="577" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Wywoływane, gdy dane wejściowe tworzy niejednoznaczne dopasowanie z jednej aktywnej gramatyki.</target>       </trans-unit>
        <trans-unit id="578" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="579" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania Kończenie znajdujących się w operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="580" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="581" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Raised when a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> operation finishes.</source>
          <target state="translated">Wywoływane, gdy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> zakończenie operacji.</target>       </trans-unit>
        <trans-unit id="582" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>To retrieve the result of an asynchronous recognition operation, attach an event handler to the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Aby uzyskać wynik operacji asynchronicznej rozpoznawania, Dołącz program obsługi zdarzeń dla aparatu rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="583" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>The recognizer raises this event whenever it successfully completes a synchronous or asynchronous recognition operation.</source>
          <target state="translated">Aparat rozpoznawania zgłasza tego zdarzenia przy każdym pomyślnym zakończeniu operacji rozpoznawania synchroniczna lub asynchroniczna.</target>       </trans-unit>
        <trans-unit id="584" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>If recognition was not successful, the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</ph> property on <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> object, which you can access in the handler for the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event, will be <ph id="ph4">`null`</ph>.</source>
          <target state="translated">Jeśli rozpoznawania zakończyła się niepowodzeniem, <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</ph> właściwość <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> obiektu, który można uzyskać dostępu do programu obsługi dla <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> będzie zdarzenia <ph id="ph4">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="585" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>An asynchronous recognition operation can fail for the following reasons:</source>
          <target state="translated">Operacja asynchronicznego rozpoznawania może się nie powieść z następujących powodów:</target>       </trans-unit>
        <trans-unit id="586" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Speech is not detected before the timeout intervals expire for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties.</source>
          <target state="translated">Mowy nie wykrywa odstępach czasu wygaśnięcia dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="587" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>The recognition engine detects speech but finds no matches in any of its loaded and enabled <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Aparat rozpoznawania wykrywa mowy, ale znajduje żadnych dopasowań w dowolnej z załadowanych i włączona <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="588" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>To perform synchronous recognition, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> methods.</source>
          <target state="translated">Aby przeprowadzić rozpoznawanie synchroniczne, użyj jednej z <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="589" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>The following example shows part of a console application that demonstrates basic asynchronous speech recognition.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część prezentującą rozpoznawania mowy asynchroniczne podstawowe aplikacji konsoli.</target>       </trans-unit>
        <trans-unit id="590" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>The example creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>, loads it into an in-process speech recognizer, and performs multiple asynchronous recognition operations.</source>
          <target state="translated">W przykładzie jest tworzony <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>ładuje go do rozpoznawania mowy w trakcie i wykonuje wiele operacji asynchronicznych rozpoznawania.</target>       </trans-unit>
        <trans-unit id="591" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>The asynchronous operations are cancelled after 30 seconds.</source>
          <target state="translated">Operacje asynchroniczne są anulowane po 30 sekund.</target>       </trans-unit>
        <trans-unit id="592" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Event handlers are included to demonstrate the events that the recognizer raises during the operation.</source>
          <target state="translated">Aby pokazać zdarzenia, które wywołuje aparat rozpoznawania podczas operacji znajdują się procedury obsługi zdarzeń.</target>       </trans-unit>
        <trans-unit id="593" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>Terminates asynchronous recognition without waiting for the current recognition operation to complete.</source>
          <target state="translated">Kończy asynchroniczne rozpoznawanie bez oczekiwania na ukończenie bieżącej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="594" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>This method immediately finalizes asynchronous recognition.</source>
          <target state="translated">Ta metoda natychmiast Kończenie znajdujących się w asynchronicznej rozpoznawania.</target>       </trans-unit>
        <trans-unit id="595" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>If the current asynchronous recognition operation is receiving input, the input is truncated and the operation completes with the existing input.</source>
          <target state="translated">Jeśli bieżąca operacja asynchroniczne rozpoznawanie otrzymuje dane wejściowe, dane wejściowe został obcięty i zakończeniu operacji przy użyciu istniejących danych wejściowych.</target>       </trans-unit>
        <trans-unit id="596" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>The recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event when an asynchronous operation is canceled, and sets the <ph id="ph3">&lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt;</ph> property of the <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> to <ph id="ph5">`true`</ph>.</source>
          <target state="translated">Generuje aparatu rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> zdarzenie, gdy operacja asynchroniczna została anulowana i ustawia <ph id="ph3">&lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt;</ph> właściwość <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> do <ph id="ph5">`true`</ph>.</target>       </trans-unit>
        <trans-unit id="597" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>This method cancels asynchronous operations initiated by the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Ta metoda umożliwia anulowanie operacji asynchronicznych inicjowane przez <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="598" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>To stop asynchronous recognition without truncating the input, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;</ph> method.</source>
          <target state="translated">Aby zatrzymać asynchroniczne rozpoznawanie bez obcinanie danych wejściowych, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="599" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>The following example shows part of a console application that demonstrates the use of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;</ph> method.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część prezentującą użycie z aplikacji konsoli <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="600" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>The example creates and loads a speech recognition grammar, initiates a continuing asynchronous recognition operation, and then pauses 2 seconds before it cancels the operation.</source>
          <target state="translated">Przykład tworzy i ładuje gramatyki rozpoznawania mowy, inicjuje kontynuowanie operacji asynchronicznych rozpoznawania i wstrzymuje działanie 2 sekundy przed anuluje operację.</target>       </trans-unit>
        <trans-unit id="601" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>The recognizer receives input from the file, c:\temp\audioinput\sample.wav.</source>
          <target state="translated">Aparat rozpoznawania odbiera dane wejściowe z pliku c:\temp\audioinput\sample.wav.</target>       </trans-unit>
        <trans-unit id="602" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>Event handlers are included to demonstrate the events that the recognizer raises during the operation.</source>
          <target state="translated">Aby pokazać zdarzenia, które wywołuje aparat rozpoznawania podczas operacji znajdują się procedury obsługi zdarzeń.</target>       </trans-unit>
        <trans-unit id="603" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>Stops asynchronous recognition after the current recognition operation completes.</source>
          <target state="translated">Zatrzymuje rozpoznawania asynchronicznych po zakończeniu bieżącej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="604" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>This method finalizes asynchronous recognition without truncating input.</source>
          <target state="translated">Ta metoda Kończenie znajdujących się w asynchroniczne rozpoznawanie bez obcinanie danych wejściowych.</target>       </trans-unit>
        <trans-unit id="605" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>If the current asynchronous recognition operation is receiving input, the recognizer continues accepting input until the current recognition operation is completed.</source>
          <target state="translated">Jeśli bieżąca operacja asynchroniczne rozpoznawanie otrzymuje dane wejściowe, aparat rozpoznawania nadal akceptowanie danych wejściowych ukończenie bieżącej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="606" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>The recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event when an asynchronous operation is stopped, and sets the <ph id="ph3">&lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt;</ph> property of the <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> to <ph id="ph5">`true`</ph>.</source>
          <target state="translated">Generuje aparatu rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> zdarzenie, gdy operacja asynchroniczna została zatrzymana i ustawia <ph id="ph3">&lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt;</ph> właściwość <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> do <ph id="ph5">`true`</ph>.</target>       </trans-unit>
        <trans-unit id="607" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>This method stops asynchronous operations initiated by the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Ta metoda zatrzymuje operacje asynchroniczne inicjowane przez <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="608" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>To immediately cancel asynchronous recognition with only the existing input, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;</ph> method.</source>
          <target state="translated">Aby natychmiast anulować asynchroniczne rozpoznawanie przy użyciu tylko istniejących danych wejściowych, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="609" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>The following example shows part of a console application that demonstrates the use of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;</ph> method.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część prezentującą użycie z aplikacji konsoli <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="610" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>The example creates and loads a speech recognition grammar, initiates a continuing asynchronous recognition operation, and then pauses 2 seconds before it stops the operation.</source>
          <target state="translated">Przykład tworzy i ładuje gramatyki rozpoznawania mowy, inicjuje kontynuowanie operacji asynchronicznych rozpoznawania i wstrzymuje działanie 2 sekundy przed jego zatrzymanie.</target>       </trans-unit>
        <trans-unit id="611" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>The recognizer receives input from the file, c:\temp\audioinput\sample.wav.</source>
          <target state="translated">Aparat rozpoznawania odbiera dane wejściowe z pliku c:\temp\audioinput\sample.wav.</target>       </trans-unit>
        <trans-unit id="612" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>Event handlers are included to demonstrate the events that the recognizer raises during the operation.</source>
          <target state="translated">Aby pokazać zdarzenia, które wywołuje aparat rozpoznawania podczas operacji znajdują się procedury obsługi zdarzeń.</target>       </trans-unit>
        <trans-unit id="613" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> finalizes an asynchronous recognition operation.</source>
          <target state="translated">Wywoływane, gdy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> Kończenie znajdujących się w operacji asynchronicznych rozpoznawania.</target>       </trans-unit>
        <trans-unit id="614" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> object's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> method initiates an asynchronous recognition operation.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> Obiektu <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> metoda inicjuje operację asynchroniczną rozpoznawania.</target>       </trans-unit>
        <trans-unit id="615" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>When the recognizer finalizes the asynchronous operation, it raises this event.</source>
          <target state="translated">Gdy aparat rozpoznawania Kończenie znajdujących się operację asynchroniczną, uruchamia to zdarzenie.</target>       </trans-unit>
        <trans-unit id="616" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>Using the handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event, you can access the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> in the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> object.</source>
          <target state="translated">Przy użyciu programu obsługi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> zdarzeń, można uzyskać dostęp <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> w <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="617" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>If recognition was not successful, <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> will be <ph id="ph2">`null`</ph>.</source>
          <target state="translated">Jeśli rozpoznawania zakończyła się niepowodzeniem, <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> będzie <ph id="ph2">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="618" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>To determine whether a timeout or an interruption in audio input caused recognition to fail, you can access the properties for <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A&gt;</ph>, or <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A&gt;</ph>.</source>
          <target state="translated">Aby ustalić, czy rozpoznawanie niepowodzenie przyczyną przekroczenie limitu czasu lub przerw w wejściowych danych audio, można uzyskać dostępu do właściwości <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A&gt;</ph>, lub <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="619" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>See the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> class for more information.</source>
          <target state="translated">Zobacz <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> klasy, aby uzyskać więcej informacji.</target>       </trans-unit>
        <trans-unit id="620" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>To obtain details on the best rejected recognition candidates, attach a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> event.</source>
          <target state="translated">Aby uzyskać szczegółowe informacje o najbardziej odpowiednich odrzucone rozpoznawania, Dołącz obsługi dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="621" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>When you create a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Po utworzeniu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> delegata, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="622" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="623" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="624" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="625" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category" or "Display albums gospel".</source>
          <target state="translated">Poniższy przykład rozpoznaje "wyrażenia takie jak wyświetlać listę artystów w kategorii jazz" lub "gospel albumów".</target>       </trans-unit>
        <trans-unit id="626" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event to display information about the results of recognition in the console.</source>
          <target state="translated">W przykładzie użyto obsługi dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> zdarzeń, aby wyświetlić informacje o wynikach rozpoznawania w konsoli.</target>       </trans-unit>
        <trans-unit id="627" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>Gets the current location of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> in the audio input that it is processing.</source>
          <target state="translated">Pobiera bieżącą lokalizację <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> w wejściowych danych audio, który przetwarzania.</target>       </trans-unit>
        <trans-unit id="628" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>The position of the recognizer in the audio input that it is processing.</source>
          <target state="translated">Pozycja rozpoznawania w wejściowych danych audio, który przetwarzania.</target>       </trans-unit>
        <trans-unit id="629" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>The audio position is specific to each speech recognizer.</source>
          <target state="translated">Pozycja audio jest specyficzne dla każdego rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="630" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>The zero value of an input stream is established when it is enabled.</source>
          <target state="translated">Wartość zero strumień wejściowy jest ustanawiane, jeśli jest włączona.</target>       </trans-unit>
        <trans-unit id="631" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> property references the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> object's position within its audio input.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> Odwołań do właściwości <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> położenie obiektu w jego wejście audio.</target>       </trans-unit>
        <trans-unit id="632" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> property references the input device's position in its generated audio stream.</source>
          <target state="translated">Z kolei <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> właściwość odwołuje się do pozycji urządzenia wejściowego w jego wygenerowanego strumieniem audio.</target>       </trans-unit>
        <trans-unit id="633" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>These positions can be different.</source>
          <target state="translated">Te pozycje mogą być różne.</target>       </trans-unit>
        <trans-unit id="634" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> property.</source>
          <target state="translated">Na przykład jeśli aparat rozpoznawania otrzymał wejściowych, do których nie ma jeszcze generowane w wyniku rozpoznawania, a następnie wartość <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> właściwości jest mniejsza niż wartość <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="635" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo">
          <source>Gets information about the current instance of <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</source>
          <target state="translated">Pobiera informacje o bieżące wystąpienie klasy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="636" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo">
          <source>Information about the current speech recognizer.</source>
          <target state="translated">Informacje o bieżącym rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="637" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo">
          <source>To get information about all of the installed speech recognizers for the current system, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> method.</source>
          <target state="translated">Aby uzyskać informacje na temat wszystkich aparatów rozpoznawania mowy zainstalowanych dla bieżącego systemu, należy użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="638" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo">
          <source>The following example gets a partial list of data for the current in-process speech recognition engine.</source>
          <target state="translated">Poniższy przykład pobiera skróconą listę danych dla bieżącego aparatu rozpoznawania mowy w procesie.</target>       </trans-unit>
        <trans-unit id="639" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo">
          <source>For more information, see <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerInfo&gt;</ph>.</source>
          <target state="translated">Aby uzyskać więcej informacji, zobacz <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerInfo&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="640" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>Raised when a running <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> pauses to accept modifications.</source>
          <target state="translated">Wywoływane, gdy uruchomione <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> wstrzymuje działanie, aby zaakceptować zmiany.</target>       </trans-unit>
        <trans-unit id="641" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>Applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> to pause a running instance of <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> before modifying its settings or its <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Aplikacje muszą używać <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> wstrzymania działającego wystąpienia <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> przed zmodyfikowaniem ustawienia lub jego <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="642" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> raises this event when it is ready to accept modifications.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> Zgłasza to zdarzenie, gdy będzie gotowy do akceptowania modyfikacje.</target>       </trans-unit>
        <trans-unit id="643" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>For example, while the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> is paused, you can load, unload, enable, and disable <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects, and modify values for the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> properties.</source>
          <target state="translated">Na przykład <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> jest wstrzymana, możesz można załadować, zwolnienie, włączania i wyłączania <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów i zmodyfikować wartości <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, i <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="644" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>For more information, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Aby uzyskać więcej informacji, zobacz <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="645" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>When you create a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Po utworzeniu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> delegata, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="646" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="647" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="648" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="649" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>The following example shows a console application that loads and unloads <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">W poniższym przykładzie przedstawiono aplikacji konsoli, który ładuje i zwalnia <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="650" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>The application uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> method to request the speech recognition engine to pause so it can receive an update.</source>
          <target state="translated">Aplikacja używa <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> metoda żądania wstrzymania, więc może ona odbierać aktualizacji aparatu rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="651" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>The application then loads or unloads a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">Aplikacja, a następnie ładuje lub zwalnia <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="652" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>At each update, a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event writes the name and status of the currently loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the console.</source>
          <target state="translated">W każdej aktualizacji obsługi dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> zapisuje zdarzenia, nazwy i stan aktualnie załadowanych <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekty do konsoli.</target>       </trans-unit>
        <trans-unit id="653" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</source>
          <target state="translated">Jak gramatyki jest załadowany i zwolniony, najpierw rozpoznaje nazwy farmy zwierząt, nazwy farmy zwierząt oraz nazwy owoców, a następnie tylko nazwy owoców.</target>       </trans-unit>
        <trans-unit id="654" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Requests that the recognizer pauses to update its state.</source>
          <target state="translated">Żądania, że aparat rozpoznawania wstrzymuje można zaktualizować stanu.</target>       </trans-unit>
        <trans-unit id="655" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Use this method to synchronize changes to the recognizer.</source>
          <target state="translated">Użyj tej metody, aby zsynchronizować zmiany dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="656" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>For example, if you load or unload a speech recognition grammar while the recognizer is processing input, use this method and the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event to synchronize your application behavior with the state of the recognizer.</source>
          <target state="translated">Na przykład, jeśli załadować lub zwolnić gramatyki rozpoznawania mowy, gdy aparat rozpoznawania jest przetwarzania danych wejściowych, ta metoda i <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> zdarzenie, aby zsynchronizować Twoje zachowanie aplikacji z stanem aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="657" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>When this method is called, the recognizer pauses or completes asynchronous operations and generates a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Gdy ta metoda jest wywoływana, aparat rozpoznawania wstrzymuje lub zakończeniu operacji asynchronicznych i generuje <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="658" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>A <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event handler can then modify the state of the recognizer in between recognition operations.</source>
          <target state="translated">A <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> obsługi zdarzeń można zmodyfikować stanu rozpoznawania Between operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="659" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>When handling <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> events, the recognizer pauses until the event handler returns.</source>
          <target state="translated">Podczas obsługi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> zdarzenia, aparat rozpoznawania wstrzymuje działanie do momentu zwraca program obsługi zdarzeń.</target>       </trans-unit>
        <trans-unit id="660" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>If the input to the recognizer is changed before the recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event, the request is discarded.</source>
          <target state="translated">Jeśli dane wejściowe dla aparatu rozpoznawania zostało zmienione przed zgłasza aparatu rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> zdarzenia, żądania są usuwane.</target>       </trans-unit>
        <trans-unit id="661" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>When this method is called:</source>
          <target state="translated">Gdy ta metoda jest wywoływana:</target>       </trans-unit>
        <trans-unit id="662" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>If the recognizer is not processing input, the recognizer immediately generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Jeśli aparat rozpoznawania nie przetwarza danych wejściowych, aparat rozpoznawania natychmiast generuje <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="663" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>If the recognizer is processing input that consists of silence or background noise, the recognizer pauses the recognition operation and generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Jeśli aparat rozpoznawania jest przetwarzania danych wejściowych, który składa się z wyciszenia lub hałas w tle, aparat rozpoznawania wstrzymuje działanie rozpoznawania i generuje <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="664" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>If the recognizer is processing input that does not consist of silence or background noise, the recognizer completes the recognition operation and then generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Jeśli aparat rozpoznawania jest przetwarzania danych wejściowych, która składa się z wyciszenia lub hałas w tle, aparat rozpoznawania zakończeniu operacji rozpoznawania, a następnie generuje <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="665" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>While the recognizer is handling the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event:</source>
          <target state="translated">Gdy aparat rozpoznawania jest obsługa <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> zdarzeń:</target>       </trans-unit>
        <trans-unit id="666" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer does not process input, and the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> property remains the same.</source>
          <target state="translated">Aparat rozpoznawania nie przetwarza danych wejściowych, a wartość <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> właściwości jest taka sama.</target>       </trans-unit>
        <trans-unit id="667" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer continues to collect input, and the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> property can change.</source>
          <target state="translated">Aparat rozpoznawania kontynuuje zbieranie danych wejściowych i wartość <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> można zmienić właściwości.</target>       </trans-unit>
        <trans-unit id="668" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>Requests that the recognizer pauses to update its state.</source>
          <target state="translated">Żądania, że aparat rozpoznawania wstrzymuje można zaktualizować stanu.</target>       </trans-unit>
        <trans-unit id="669" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> is <ph id="ph4">`null`</ph>.</source>
          <target state="translated">Gdy aparat rozpoznawania generuje <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> zdarzenia <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> właściwość <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> jest <ph id="ph4">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="670" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>To provide a user token, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Aby dostarczyć token użytkownika, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="671" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Aby określić przesunięcie pozycji audio, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="672" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>The following example shows a console application that loads and unloads <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">W poniższym przykładzie przedstawiono aplikacji konsoli, który ładuje i zwalnia <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="673" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>The application uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> method to request the speech recognition engine to pause so it can receive an update.</source>
          <target state="translated">Aplikacja używa <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> metoda żądania wstrzymania, więc może ona odbierać aktualizacji aparatu rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="674" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>The application then loads or unloads a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">Aplikacja, a następnie ładuje lub zwalnia <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="675" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>At each update, a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event writes the name and status of the currently loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the console.</source>
          <target state="translated">W każdej aktualizacji obsługi dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> zapisuje zdarzenia, nazwy i stan aktualnie załadowanych <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekty do konsoli.</target>       </trans-unit>
        <trans-unit id="676" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</source>
          <target state="translated">Jak gramatyki jest załadowany i zwolniony, najpierw rozpoznaje nazwy farmy zwierząt, nazwy farmy zwierząt oraz nazwy owoców, a następnie tylko nazwy owoców.</target>       </trans-unit>
        <trans-unit id="677" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">Informacje zdefiniowane przez użytkownika, zawierający informacje dla tej operacji.</target>       </trans-unit>
        <trans-unit id="678" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)">
          <source>Requests that the recognizer pauses to update its state and provides a user token for the associated event.</source>
          <target state="translated">Żądania, który aparat rozpoznawania wstrzymuje można zaktualizować stanu oraz token użytkownika dla skojarzonego zdarzenia.</target>       </trans-unit>
        <trans-unit id="679" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
          <target state="translated">Gdy aparat rozpoznawania generuje <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> zdarzenia <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> właściwość <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> zawiera wartość <ph id="ph4">`userToken`</ph> parametru.</target>       </trans-unit>
        <trans-unit id="680" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Aby określić przesunięcie pozycji audio, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="681" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">Informacje zdefiniowane przez użytkownika, zawierający informacje dla tej operacji.</target>       </trans-unit>
        <trans-unit id="682" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>The offset from the current <ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition" /&gt;</ph> to delay the request.</source>
          <target state="translated">Przesunięcie od bieżącej <ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition" /&gt;</ph> opóźnienia żądania.</target>       </trans-unit>
        <trans-unit id="683" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>Requests that the recognizer pauses to update its state and provides an offset and a user token for the associated event.</source>
          <target state="translated">Żądania, który aparat rozpoznawania wstrzymuje można zaktualizować stanu oraz przesunięcia i token użytkownika dla skojarzonego zdarzenia.</target>       </trans-unit>
        <trans-unit id="684" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>The recognizer does not initiate the recognizer update request until the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> equals the current <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> plus <ph id="ph3">`audioPositionAheadToRaiseUpdate`</ph>.</source>
          <target state="translated">Aparat rozpoznawania nie zainicjował żądanie aktualizacji aparatu rozpoznawania do aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> jest równe bieżącego <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> plus <ph id="ph3">`audioPositionAheadToRaiseUpdate`</ph>.</target>       </trans-unit>
        <trans-unit id="685" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
          <target state="translated">Gdy aparat rozpoznawania generuje <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> zdarzenia <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> właściwość <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> zawiera wartość <ph id="ph4">`userToken`</ph> parametru.</target>       </trans-unit>
        <trans-unit id="686" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>The audio input stream.</source>
          <target state="translated">Strumień wejściowy audio.</target>       </trans-unit>
        <trans-unit id="687" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>The format of the audio input.</source>
          <target state="translated">Format wejście audio.</target>       </trans-unit>
        <trans-unit id="688" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>Configures the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> object to receive input from an audio stream.</source>
          <target state="translated">Konfiguruje <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> obiektu dla danych wejściowych z strumieniem audio.</target>       </trans-unit>
        <trans-unit id="689" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>If the recognizer reaches the end of the input stream during a recognition operation, the recognition operation finalizes with the available input.</source>
          <target state="translated">Jeśli aparat rozpoznawania osiągnie koniec strumienia wejściowego podczas operacji rozpoznawania, operacja rozpoznawania Kończenie znajdujących się przy użyciu dostępnych danych wejściowych.</target>       </trans-unit>
        <trans-unit id="690" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>Any subsequent recognition operations can generate an exception, unless you update the input to the recognizer.</source>
          <target state="translated">Żadnych operacji rozpoznawania kolejnych może wygenerować wyjątek, chyba że aktualizacji danych wejściowych dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="691" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część prezentującą rozpoznawania mowy podstawowe aplikacji konsoli.</target>       </trans-unit>
        <trans-unit id="692" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>The example uses input from an audio file, example.wav, that contains the phrases, "testing testing one two three" and "mister cooper", separated by a pause.</source>
          <target state="translated">W przykładzie użyto danych wejściowych z pliku audio example.wav, zawierający fraz "testowania jedną testowania dwa trzy" i "mister cooper", rozdzielając wstrzymaniu.</target>       </trans-unit>
        <trans-unit id="693" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>The example generates the following output.</source>
          <target state="translated">Przykład generuje następujące dane wyjściowe.</target>       </trans-unit>
        <trans-unit id="694" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice">
          <source>Configures the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> object to receive input from the default audio device.</source>
          <target state="translated">Konfiguruje <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> obiektu dla danych wejściowych z domyślnego urządzenia audio.</target>       </trans-unit>
        <trans-unit id="695" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część prezentującą rozpoznawania mowy podstawowe aplikacji konsoli.</target>       </trans-unit>
        <trans-unit id="696" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice">
          <source>The example uses output from the default audio device, performs multiple, asynchronous recognition operations, and exits when a user utters the phrase, "exit".</source>
          <target state="translated">Przykład korzysta z danych wyjściowych z domyślnego urządzenia audio, wykonuje wiele, operacje asynchroniczne rozpoznawanie i wyjść, gdy użytkownik utters frazy "exit".</target>       </trans-unit>
        <trans-unit id="697" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull">
          <source>Disables the input to the speech recognizer.</source>
          <target state="translated">Wyłącza dane wejściowe do rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="698" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull">
          <source>Configure the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> object for no input when using the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph> and <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> methods, or when taking a recognition engine temporarily off line.</source>
          <target state="translated">Skonfiguruj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> obiektu nie można wprowadzać przy użyciu <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph> i <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metody, lub w przypadku wykonywania aparatu rozpoznawania, tymczasowo wyłączony.</target>       </trans-unit>
        <trans-unit id="699" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)">
          <source>The path of the file to use as input.</source>
          <target state="translated">Ścieżka pliku do użycia jako dane wejściowe.</target>       </trans-unit>
        <trans-unit id="700" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)">
          <source>Configures the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> object to receive input from a Waveform audio format (.wav) file.</source>
          <target state="translated">Konfiguruje <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> obiektu dla danych wejściowych z pliku fali format audio (wav).</target>       </trans-unit>
        <trans-unit id="701" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)">
          <source>If the recognizer reaches the end of the input file during a recognition operation, the recognition operation finalizes with the available input.</source>
          <target state="translated">Jeśli aparat rozpoznawania dociera do końca pliku wejściowego podczas operacji rozpoznawania, operacja rozpoznawania Kończenie znajdujących się przy użyciu dostępnych danych wejściowych.</target>       </trans-unit>
        <trans-unit id="702" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)">
          <source>Any subsequent recognition operations can generate an exception, unless you update the input to the recognizer.</source>
          <target state="translated">Żadnych operacji rozpoznawania kolejnych może wygenerować wyjątek, chyba że aktualizacji danych wejściowych dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="703" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)">
          <source>The following example performs recognition on the audio in a .wav file and writes the recognized text to the console.</source>
          <target state="translated">Poniższy przykład przeprowadzają rozpoznawanie audio w pliku WAV i zapisuje rozpoznany konsoli.</target>       </trans-unit>
        <trans-unit id="704" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)">
          <source>The stream containing the audio data.</source>
          <target state="translated">Strumień, zawierający dane audio.</target>       </trans-unit>
        <trans-unit id="705" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)">
          <source>Configures the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> object to receive input from a stream that contains Waveform audio format (.wav) data.</source>
          <target state="translated">Konfiguruje <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> obiektu dla danych wejściowych z strumienia, który zawiera dane przebiegu format audio (wav).</target>       </trans-unit>
        <trans-unit id="706" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)">
          <source>If the recognizer reaches the end of the input stream during a recognition operation, the recognition operation finalizes with the available input.</source>
          <target state="translated">Jeśli aparat rozpoznawania osiągnie koniec strumienia wejściowego podczas operacji rozpoznawania, operacja rozpoznawania Kończenie znajdujących się przy użyciu dostępnych danych wejściowych.</target>       </trans-unit>
        <trans-unit id="707" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)">
          <source>Any subsequent recognition operations can generate an exception, unless you update the input to the recognizer.</source>
          <target state="translated">Żadnych operacji rozpoznawania kolejnych może wygenerować wyjątek, chyba że aktualizacji danych wejściowych dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="708" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> detects input that it can identify as speech.</source>
          <target state="translated">Wywoływane, gdy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> wykrywa danych wejściowych, którą można zidentyfikować jako mowy.</target>       </trans-unit>
        <trans-unit id="709" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>Each speech recognizer has an algorithm to distinguish between silence and speech.</source>
          <target state="translated">Każdy aparat rozpoznawania mowy zawiera algorytm odróżnić wyciszenia mowy.</target>       </trans-unit>
        <trans-unit id="710" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>When the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> performs a speech recognition operation, it raises the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> event when its algorithm identifies the input as speech.</source>
          <target state="translated">Gdy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> wykonuje operację rozpoznawania mowy zgłasza <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> zdarzenie, gdy jego algorytmu identyfikuje danych wejściowych jako mowy.</target>       </trans-unit>
        <trans-unit id="711" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> object indicates location in the input stream where the recognizer detected speech.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</ph> Właściwości skojarzonego <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> obiektu wskazuje lokalizację, w przypadku wykrycia przez aparat rozpoznawania mowy strumień wejściowy.</target>       </trans-unit>
        <trans-unit id="712" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> raises the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> event before it raises any of the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>, or <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> events.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> Zgłasza <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> zdarzeń przed zgłasza żadnego z <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>, lub <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> zdarzenia.</target>       </trans-unit>
        <trans-unit id="713" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>For more information see the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Aby uzyskać więcej informacji, zobacz <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="714" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>When you create a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Po utworzeniu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> delegata, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="715" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="716" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="717" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="718" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>The following example is part of a console application for choosing origin and destination cities for a flight.</source>
          <target state="translated">Poniższy przykład jest częścią aplikacji konsoli dotyczące wybierania miast źródło i miejsce docelowe w locie.</target>       </trans-unit>
        <trans-unit id="719" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>The application recognizes phrases such as "I want to fly from Miami to Chicago."</source>
          <target state="translated">Aplikacja rozpoznaje fraz, takie jak "Chcę udać z Miami do Chicago."</target>       </trans-unit>
        <trans-unit id="720" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>The example uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> event to report the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> each time speech is detected.</source>
          <target state="translated">W przykładzie użyto <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> zdarzeń do raportu <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> każdego mowy czas wykrycia.</target>       </trans-unit>
        <trans-unit id="721" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> has recognized a word or words that may be a component of multiple complete phrases in a grammar.</source>
          <target state="translated">Wywoływane, gdy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> rozpoznał wyrazów, które mogą być składnika wiele wyrażeń pełną w gramatyce.</target>       </trans-unit>
        <trans-unit id="722" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> generates numerous <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph> events as it attempts to identify an input phrase.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> Generuje wiele <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph> zdarzeń, ponieważ próbuje określić wyrażenie wejściowe.</target>       </trans-unit>
        <trans-unit id="723" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>You can access the text of partially recognized phrases in the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</ph> object in the handler for the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph> event.</source>
          <target state="translated">Dostęp można uzyskać tekstu częściowo rozpoznanym fraz w <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> właściwość <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</ph> obiekt obsługi dla <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="724" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>Typically, handling these events is useful only for debugging.</source>
          <target state="translated">Obsługa tych zdarzeń jest zazwyczaj przydatne tylko w przypadku debugowania.</target>       </trans-unit>
        <trans-unit id="725" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</ph> derives from <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</ph> pochodną <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="726" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>For more information see the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> property and the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Aby uzyskać więcej informacji, zobacz <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> właściwości i <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph>, i <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="727" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>When you create a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Po utworzeniu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph> delegata, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="728" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="729" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="730" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="731" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category".</source>
          <target state="translated">Poniższy przykład rozpoznaje fraz, takie jak "Wyświetlana lista artystów w kategorii jazz".</target>       </trans-unit>
        <trans-unit id="732" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>The example uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph> event to display incomplete phrase fragments in the console as they are recognized.</source>
          <target state="translated">W przykładzie użyto <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph> zdarzeń, aby wyświetlić fragmenty niepełne wyrażenie w konsoli, jak są rozpoznawane.</target>       </trans-unit>
        <trans-unit id="733" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> receives input that does not match any of its loaded and enabled <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects.</source>
          <target state="translated">Wywoływane, gdy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> odbiera dane wejściowe, który nie pasuje do żadnego załadowany i włączone <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="734" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>The recognizer raises this event if it determines that input does not match with sufficient confidence any of its loaded and enabled <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Aparat rozpoznawania zgłasza to zdarzenie, gdy ustali, że dane wejściowe nie jest zgodna z wystarczający poziom zaufania załadowany i włączone <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="735" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the rejected <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> Właściwość <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> zawiera odrzucone <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="736" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>You can use the handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> event to retrieve recognition <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> that were rejected and their <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> scores.</source>
          <target state="translated">Można użyć programu obsługi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> zdarzenie, aby pobrać rozpoznawania <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> które zostały odrzucone i ich <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> wyniki.</target>       </trans-unit>
        <trans-unit id="737" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>If your application is using a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance, you can modify the confidence level at which speech input is accepted or rejected with one of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> methods.</source>
          <target state="translated">Jeśli aplikacja korzysta <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> wystąpienia, można zmodyfikować poziom ufności, w których mowy danych wejściowych jest zaakceptowane lub odrzucone z jednym z <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="738" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>You can modify how the speech recognition responds to non-speech input using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> properties.</source>
          <target state="translated">Można zmodyfikować sposób rozpoznawania mowy odpowiadania na nie mowy przy użyciu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="739" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>When you create a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Po utworzeniu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> delegata, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="740" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="741" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="742" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="743" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category" or "Display albums gospel".</source>
          <target state="translated">Poniższy przykład rozpoznaje "wyrażenia takie jak wyświetlać listę artystów w kategorii jazz" lub "gospel albumów".</target>       </trans-unit>
        <trans-unit id="744" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> to produce a successful recognition.</source>
          <target state="translated">W przykładzie użyto obsługi dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> zdarzeń, aby wyświetlić powiadomienie w konsoli podczas wprowadzania mowy nie można dopasować do zawartości gramatyki o wystarczającej ilości <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> wygenerowało rozpoznawania powiodło się.</target>       </trans-unit>
        <trans-unit id="745" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>The handler also displays recognition result <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> that were rejected because of low confidence scores.</source>
          <target state="translated">Program obsługi jest również wyświetlana wyniku rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> które zostały odrzucone z powodu wyniki niski zaufania.</target>       </trans-unit>
        <trans-unit id="746" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> receives input that matches any of its loaded and enabled <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects.</source>
          <target state="translated">Wywoływane, gdy <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> odbiera wejścia odpowiadającego załadowany i włączone <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="747" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>You can initiate a recognition operation using the one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Możesz zainicjować operacji rozpoznawania, przy użyciu jednej z <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> lub <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="748" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>The recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event if it determines that input matches one of its loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects with a sufficient level of confidence to constitute recognition.</source>
          <target state="translated">Generuje aparatu rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń, gdy ustali, że danych wejściowych odpowiada jednej z jej załadować <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiekty o wystarczający poziom ufności stanowić rozpoznawania.</target>       </trans-unit>
        <trans-unit id="749" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the accepted <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> Właściwość <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> zawiera zaakceptowane <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="750" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>Handlers of <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events can obtain the recognized phrase as well as a list of recognition <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> with lower confidence scores.</source>
          <target state="translated">Programy obsługi z <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzenia można uzyskać rozpoznaną frazę, a także listę rozpoznawania <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> z niższym wyniki zaufania.</target>       </trans-unit>
        <trans-unit id="751" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>If your application is using a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance, you can modify the confidence level at which speech input is accepted or rejected with one of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> methods.</source>
          <target state="translated">Jeśli aplikacja korzysta <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> wystąpienia, można zmodyfikować poziom ufności, w których mowy danych wejściowych jest zaakceptowane lub odrzucone z jednym z <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="752" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>You can modify how the speech recognition responds to non-speech input using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> properties.</source>
          <target state="translated">Można zmodyfikować sposób rozpoznawania mowy odpowiadania na nie mowy przy użyciu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="753" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>When the recognizer receives input that matches a grammar, the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object can raise its <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Gdy aparat rozpoznawania otrzymuje wejścia odpowiadającego gramatyki, <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu może wiązać się z jego <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="754" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object's <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event is raised prior to the speech recognizer's <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> Obiektu <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> zdarzenie jest wywoływane przed rozpoznawania mowy <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="755" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>Any tasks specific to a particular grammar should always be performed by a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Wszystkie zadania, które są specyficzne dla konkretnego gramatyki zawsze powinny być wykonywane przez program obsługi <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="756" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>When you create a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Po utworzeniu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> delegata, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="757" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="758" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływany przy każdym wystąpieniu zdarzenia, o ile nie usunięto delegata.</target>       </trans-unit>
        <trans-unit id="759" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="760" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>The following example is part of a console application that creates speech recognition grammar, constructs a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object, and loads it into the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> to perform recognition.</source>
          <target state="translated">Poniższy przykład jest częścią aplikacji konsoli, która tworzy gramatyka rozpoznawania mowy konstrukcje <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu i załaduje go do <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> przeprowadzać rozpoznawania.</target>       </trans-unit>
        <trans-unit id="761" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>The example demonstrates speech input to a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">W przykładzie pokazano dane wejściowe mowy <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, wyników rozpoznawania skojarzone i skojarzone zdarzenia wygenerowane przez aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="762" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>Spoken input such as "I want to fly from Chicago to Miami" will trigger a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Używany danych wejściowych, takie jak "Chcę udać z Chicago do Miami" wyzwoli <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="763" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>Speaking the phrase "Fly me from Houston to Chicago " will not trigger a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Mówiąc frazę "Udać me z Houston do Chicago" nie powoduje wyzwolenia <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń.</target>       </trans-unit>
        <trans-unit id="764" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event to display successfully recognized phrases and the semantics they contain in the console.</source>
          <target state="translated">W przykładzie użyto obsługi dla <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> zdarzeń do wyświetlenia pomyślnie rozpoznane fraz i semantyki zawierają w konsoli.</target>       </trans-unit>
        <trans-unit id="765" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars">
          <source>Unloads all <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects from the recognizer.</source>
          <target state="translated">Zwalnia wszystkie <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> obiektów z aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="766" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars">
          <source>If the recognizer is currently loading a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> asynchronously, this method waits until the <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> is loaded, before it unloads all of the <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects from the <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance.</source>
          <target state="translated">Aparat rozpoznawania jest obecnie ładowania <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> asynchronicznie, ta metoda będzie czekać <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> został załadowany, zanim wszystkie zwalnia <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów z <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> wystąpienia.</target>       </trans-unit>
        <trans-unit id="767" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars">
          <source>To unload a specific grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;</ph> method.</source>
          <target state="translated">Aby zwolnić określonego gramatyki, użyj <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="768" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars">
          <source>The following example shows part of a console application that demonstrates the synchronous loading and unloading of speech recognition grammars.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część aplikacji konsoli, który demonstruje synchroniczne ładowanie i zwalnianie gramatyki rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="769" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>The grammar object to unload.</source>
          <target state="translated">Obiekt gramatyki do zwolnienia.</target>       </trans-unit>
        <trans-unit id="770" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>Unloads a specified <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> object from the <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> instance.</source>
          <target state="translated">Zwalnia określony <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> obiekt z <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> wystąpienia.</target>       </trans-unit>
        <trans-unit id="771" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> to pause the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance before loading, unloading,  enabling, or disabling a <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">Jeśli aparat rozpoznawania jest uruchomiona, aplikacje muszą używać <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> wstrzymania <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> wystąpienia przed ładowania, zwalnianie, włączanie lub wyłączanie <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektu.</target>       </trans-unit>
        <trans-unit id="772" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>To unload all <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt;</ph> method.</source>
          <target state="translated">Aby zwolnić wszystkie <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów, użyj <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="773" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>The following example shows part of a console application that demonstrates the synchronous loading and unloading of speech recognition grammars.</source>
          <target state="translated">W poniższym przykładzie przedstawiono część aplikacji konsoli, który demonstruje synchroniczne ładowanie i zwalnianie gramatyki rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="774" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> jest <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="775" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>The grammar is not loaded in this recognizer, or this recognizer is currently loading the grammar asynchronously.</source>
          <target state="translated">Gramatyka nie został załadowany w tego aparatu rozpoznawania, lub tego aparatu rozpoznawania obecnie trwa ładowanie gramatyki asynchronicznie.</target>       </trans-unit>
        <trans-unit id="776" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Updates the value of a setting for the recognizer.</source>
          <target state="translated">Aktualizuje wartość ustawienia aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="777" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Recognizer settings can contain string, 64-bit integer, or memory address data.</source>
          <target state="translated">Ustawienia aparatu rozpoznawania może zawierać ciągu, 64-bitową liczbą całkowitą lub dane adresów pamięci.</target>       </trans-unit>
        <trans-unit id="778" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The following table describes the settings that are defined for a Microsoft Speech API (SAPI)-compliant recognizer.</source>
          <target state="translated">W poniższej tabeli opisano ustawienia, które są zdefiniowane dla interfejsu API mowy firmy Microsoft (SAPI)-zgodne aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="779" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The following settings must have the same range for each recognizer that supports the setting.</source>
          <target state="translated">Następujące ustawienia należy skonfigurować każdy aparat rozpoznawania, który obsługuje ustawienie tego samego zakresu.</target>       </trans-unit>
        <trans-unit id="780" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>A SAPI-compliant recognizer is not required to support these settings and can support other settings.</source>
          <target state="translated">Zgodne SAPI aparat rozpoznawania nie jest wymagany do obsługi tych ustawień i może obsługiwać inne ustawienia.</target>       </trans-unit>
        <trans-unit id="781" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Name</source>
          <target state="translated">Nazwa</target>       </trans-unit>
        <trans-unit id="782" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Description</source>
          <target state="translated">Opis</target>       </trans-unit>
        <trans-unit id="783" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Specifies the recognizer's CPU consumption.</source>
          <target state="translated">Określa użycie procesora CPU przez aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="784" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The range is from 0 to 100.</source>
          <target state="translated">Zakres wynosi od 0 do 100.</target>       </trans-unit>
        <trans-unit id="785" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The default value is 50.</source>
          <target state="translated">Wartością domyślną jest 50.</target>       </trans-unit>
        <trans-unit id="786" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Indicates the length of silence at the end of unambiguous input before the speech recognizer completes a recognition operation.</source>
          <target state="translated">Wskazuje długość wyciszenia na końcu danych wejściowych jednoznaczne ukończenia operacji rozpoznawania rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="787" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The range is from 0 to 10,000 milliseconds (ms).</source>
          <target state="translated">Zakres wynosi od 0 do 10 000 w milisekundach (ms).</target>       </trans-unit>
        <trans-unit id="788" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>This setting corresponds to the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> property.</source>
          <target state="translated">To ustawienie odpowiada aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="789" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Default = 150ms.</source>
          <target state="translated">Domyślne = 150ms.</target>       </trans-unit>
        <trans-unit id="790" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Indicates the length of silence in milliseconds (ms) at the end of ambiguous input before the speech recognizer completes a recognition operation.</source>
          <target state="translated">Wskazuje długość wyciszenia w milisekundach (ms) na końcu danych wejściowych niejednoznaczne ukończenia operacji rozpoznawania rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="791" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The range is from 0 to 10,000ms.</source>
          <target state="translated">Zakres wynosi od 0 do 10,000ms.</target>       </trans-unit>
        <trans-unit id="792" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>This setting corresponds to the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> property.</source>
          <target state="translated">To ustawienie odpowiada aparat rozpoznawania <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="793" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Default = 500ms.</source>
          <target state="translated">Domyślnie 500 MS.</target>       </trans-unit>
        <trans-unit id="794" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Indicates whether adaptation of the acoustic model is ON (value = <ph id="ph1">`1`</ph>) or OFF (value = <ph id="ph2">`0`</ph>).</source>
          <target state="translated">Wskazuje, czy dostosowania modelu akustycznego jest ON (wartość = <ph id="ph1">`1`</ph>) lub OFF (wartość = <ph id="ph2">`0`</ph>).</target>       </trans-unit>
        <trans-unit id="795" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The default value is <ph id="ph1">`1`</ph> (ON).</source>
          <target state="translated">Wartość domyślna to <ph id="ph1">`1`</ph> (dalej).</target>       </trans-unit>
        <trans-unit id="796" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Indicates whether background adaptation is ON (value = <ph id="ph1">`1`</ph>) or OFF (value = <ph id="ph2">`0`</ph>), and persists the setting in the registry.</source>
          <target state="translated">Wskazuje, czy adaptacja w tle jest ON (wartość = <ph id="ph1">`1`</ph>) lub OFF (wartość = <ph id="ph2">`0`</ph>), będzie się powtarzał ustawienie w rejestrze.</target>       </trans-unit>
        <trans-unit id="797" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The default value is <ph id="ph1">`1`</ph> (ON).</source>
          <target state="translated">Wartość domyślna to <ph id="ph1">`1`</ph> (dalej).</target>       </trans-unit>
        <trans-unit id="798" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To return one of the recognizer's settings, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting%2A&gt;</ph> method.</source>
          <target state="translated">Aby przywrócić jedno z ustawień aparat rozpoznawania, za pomocą <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting%2A&gt;</ph> metody.</target>       </trans-unit>
        <trans-unit id="799" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>With the exception of <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, property values set using the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> methods remain in effect only for the current instance of <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, after which they revert to their default settings.</source>
          <target state="translated">Z wyjątkiem produktów <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, wartości właściwości ustawiane przy użyciu <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> metody pozostaną aktywne tylko dla bieżącego wystąpienia elementu <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, po którym ich przywrócić ustawienia domyślne.</target>       </trans-unit>
        <trans-unit id="800" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>You can modify how the speech recognition responds to non-speech input using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> properties.</source>
          <target state="translated">Można zmodyfikować sposób rozpoznawania mowy odpowiadania na nie mowy przy użyciu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, i <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> właściwości.</target>       </trans-unit>
        <trans-unit id="801" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>The name of the setting to update.</source>
          <target state="translated">Nazwa ustawienia do aktualizacji.</target>       </trans-unit>
        <trans-unit id="802" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>The new value for the setting.</source>
          <target state="translated">Nowa wartość ustawienia.</target>       </trans-unit>
        <trans-unit id="803" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>Updates the specified setting for the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> with the specified integer value.</source>
          <target state="translated">Aktualizuje określony ustawienie <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> z określonej liczby całkowitej.</target>       </trans-unit>
        <trans-unit id="804" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>With the exception of <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, property values set using the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> method remain in effect only for the current instance of <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, after which they revert to their default settings.</source>
          <target state="translated">Z wyjątkiem produktów <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, wartości właściwości ustawiane przy użyciu <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> metody pozostaną aktywne tylko dla bieżącego wystąpienia elementu <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, po którym ich przywrócić ustawienia domyślne.</target>       </trans-unit>
        <trans-unit id="805" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>See <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> for descriptions of supported settings.</source>
          <target state="translated">Zobacz <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> opisy obsługiwanych ustawień.</target>       </trans-unit>
        <trans-unit id="806" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>The following example is part of a console application that outputs the values for a number of the settings defined for the recognizer that supports the en-US locale.</source>
          <target state="translated">Poniższy przykład jest częścią aplikacji konsoli, która wyświetla wartości dla wielu ustawień zdefiniowanych przez aparat rozpoznawania, który obsługuje ustawień regionalnych pl pl.</target>       </trans-unit>
        <trans-unit id="807" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>The example updates the confidence level settings, and then queries the recognizer to check the updated values.</source>
          <target state="translated">Przykład zaktualizowanie ustawień poziomu zaufania i tworzy następnie kwerendę rozpoznawania pisma Sprawdź zaktualizowane wartości.</target>       </trans-unit>
        <trans-unit id="808" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>The example generates the following output.</source>
          <target state="translated">Przykład generuje następujące dane wyjściowe.</target>       </trans-unit>
        <trans-unit id="809" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> jest <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="810" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="811" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>The recognizer does not have a setting by that name.</source>
          <target state="translated">Aparat rozpoznawania nie ma ustawienie o takiej nazwie.</target>       </trans-unit>
        <trans-unit id="812" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source>The name of the setting to update.</source>
          <target state="translated">Nazwa ustawienia do aktualizacji.</target>       </trans-unit>
        <trans-unit id="813" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source>The new value for the setting.</source>
          <target state="translated">Nowa wartość ustawienia.</target>       </trans-unit>
        <trans-unit id="814" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source>Updates the specified speech recognition engine setting with the specified string value.</source>
          <target state="translated">Aktualizuje ustawienia aparatu rozpoznawania mowy określonego określona wartość ciągu.</target>       </trans-unit>
        <trans-unit id="815" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source>With the exception of <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, property values set using the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> method remain in effect only for the current instance of <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, after which they revert to their default settings.</source>
          <target state="translated">Z wyjątkiem produktów <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, wartości właściwości ustawiane przy użyciu <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> metody pozostaną aktywne tylko dla bieżącego wystąpienia elementu <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, po którym ich przywrócić ustawienia domyślne.</target>       </trans-unit>
        <trans-unit id="816" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source>See <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> for descriptions of supported settings.</source>
          <target state="translated">Zobacz <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> opisy obsługiwanych ustawień.</target>       </trans-unit>
        <trans-unit id="817" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> jest <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="818" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="819" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source>The recognizer does not have a setting by that name.</source>
          <target state="translated">Aparat rozpoznawania nie ma ustawienie o takiej nazwie.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>