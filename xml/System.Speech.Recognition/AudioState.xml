<Type Name="AudioState" FullName="System.Speech.Recognition.AudioState">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="c25020d12cfa99f187a1ed73cc6b5083cfbc0240" />
    <Meta Name="ms.sourcegitcommit" Value="d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b" />
    <Meta Name="ms.translationtype" Value="MT" />
    <Meta Name="ms.contentlocale" Value="pl-PL" />
    <Meta Name="ms.lasthandoff" Value="04/03/2018" />
    <Meta Name="ms.locfileid" Value="30578014" />
  </Metadata>
  <TypeSignature Language="C#" Value="public enum AudioState" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed AudioState extends System.Enum" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.AudioState" />
  <TypeSignature Language="VB.NET" Value="Public Enum AudioState" />
  <TypeSignature Language="C++ CLI" Value="public enum class AudioState" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Enum</BaseTypeName>
  </Base>
  <Docs>
    <summary>Zawiera listę możliwych stanów wejście audio do aparatu rozpoznawania mowy.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Można uzyskać stanu wejściowego audio aparat rozpoznawania mowy z <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A?displayProperty=nameWithType> i <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A?displayProperty=nameWithType> właściwości. <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged?displayProperty=nameWithType> i <xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged?displayProperty=nameWithType> zdarzenia są wywoływane, gdy stan zmiany aparat rozpoznawania mowy wejściowe audio.  
  
   
  
## Examples  
 W poniższym przykładzie pokazano obsługi zdarzeń, który obsługuje zmieniania stanu audio rozpoznawania mowy.  
  
```csharp  
  
private SpeechRecognitionEngine sre;  
  
// Initializes the speech recognition engine.  
private void Initialize()  
{  
  sre = new SpeechRecognitionEngine();  
  
  // Add a handler for the AudioStateChanged event.  
  sre.AudioStateChanged += new EventHandler<AudioStateChangedEventArgs>(sre_AudioStateChanged);  
  
  // Add other initialization code here.  
}  
  
  // Handle the AudioStateChanged event.  
  void sre_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  
{  
  AudioState newState = e.AudioState;  
  
  // Handle event here.  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
    <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
    <altmember cref="T:System.Speech.Recognition.AudioStateChangedEventArgs" />
  </Docs>
  <Members>
    <Member MemberName="Silence">
      <MemberSignature Language="C#" Value="Silence" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype System.Speech.Recognition.AudioState Silence = int32(1)" />
      <MemberSignature Language="DocId" Value="F:System.Speech.Recognition.AudioState.Silence" />
      <MemberSignature Language="VB.NET" Value="Silence" />
      <MemberSignature Language="C++ CLI" Value="Silence" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.AudioState</ReturnType>
      </ReturnValue>
      <MemberValue>1</MemberValue>
      <Docs>
        <summary>Odbieranie wyciszenia lub szumu tła z systemem innym niż mowy.</summary>
      </Docs>
    </Member>
    <Member MemberName="Speech">
      <MemberSignature Language="C#" Value="Speech" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype System.Speech.Recognition.AudioState Speech = int32(2)" />
      <MemberSignature Language="DocId" Value="F:System.Speech.Recognition.AudioState.Speech" />
      <MemberSignature Language="VB.NET" Value="Speech" />
      <MemberSignature Language="C++ CLI" Value="Speech" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.AudioState</ReturnType>
      </ReturnValue>
      <MemberValue>2</MemberValue>
      <Docs>
        <summary>Odbieranie danych wejściowych mowy.</summary>
      </Docs>
    </Member>
    <Member MemberName="Stopped">
      <MemberSignature Language="C#" Value="Stopped" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype System.Speech.Recognition.AudioState Stopped = int32(0)" />
      <MemberSignature Language="DocId" Value="F:System.Speech.Recognition.AudioState.Stopped" />
      <MemberSignature Language="VB.NET" Value="Stopped" />
      <MemberSignature Language="C++ CLI" Value="Stopped" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.AudioState</ReturnType>
      </ReturnValue>
      <MemberValue>0</MemberValue>
      <Docs>
        <summary>Nie przetwarza wejściowych danych audio.</summary>
      </Docs>
    </Member>
  </Members>
</Type>