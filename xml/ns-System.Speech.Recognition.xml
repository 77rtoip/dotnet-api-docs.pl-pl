<Namespace Name="System.Speech.Recognition">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="be08311c812e33ac449fae40c2d2494af9dc7fe5" />
    <Meta Name="ms.sourcegitcommit" Value="d0bb31ec8354fa58c62c2a646057eec11d3e2150" />
    <Meta Name="ms.translationtype" Value="MT" />
    <Meta Name="ms.contentlocale" Value="pl-PL" />
    <Meta Name="ms.lasthandoff" Value="08/17/2018" />
    <Meta Name="ms.locfileid" Value="30746249" />
  </Metadata>
  <Docs>
    <summary>
      <see cref="N:System.Speech.Recognition" /> Przestrzeń nazw zawiera typy technologii Windows Desktop mowy do implementowania funkcji rozpoznawania mowy.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Oprogramowanie technologii mowy pulpitu Windows oferuje infrastrukturę rozpoznawania mowy podstawowa, która digitizes sygnały akustyczne i odzyskuje słów i elementy mowy z wejścia audio.  
  
 Aplikacje używają <xref:System.Speech.Recognition> przestrzeń nazw do uzyskania dostępu i rozszerzenie tej technologii rozpoznawania mowy podstawowe, definiując algorytmy identyfikacji i działające na określonych frazy lub wzorce programu word i zarządzając działanie tej funkcji rozpoznawania mowy infrastruktura.  
  
 **Utwórz gramatyki**  
  
 Możesz utworzyć gramatyki, które składają się z zestawu reguł lub ograniczenia słów i fraz, które rozpoznają aplikacji jest definiowana jako istotnych danych wejściowych. Za pomocą konstruktora dla <xref:System.Speech.Recognition.Grammar> klasy, można utworzyć obiekt gramatyki w czasie wykonywania z <xref:System.Speech.Recognition.GrammarBuilder> lub <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> wystąpień z pliku, ciągu lub strumienia, który zawiera definicję gramatyki.  
  
 Za pomocą <xref:System.Speech.Recognition.GrammarBuilder> i <xref:System.Speech.Recognition.Choices> klasy, można programowo tworzyć gramatyki o niewielkim średniej złożoności, który może służyć do wykonywania rozpoznawania obsługę wielu typowych scenariuszy. Aby utworzyć gramatyki programowe, które są zgodne z [mowy rozpoznawania gramatyki specyfikacji 1.0 (SRGS)](http://go.microsoft.com/fwlink/?LinkId=201761) i korzystać z zalet tworzenia elastyczność SRGS, użyj typów <xref:System.Speech.Recognition.SrgsGrammar> przestrzeni nazw. Możesz również utworzyć gramatyki SRGS formatu XML przy użyciu dowolnego tekstu w edytorze i umożliwia utworzenie wyniku <xref:System.Speech.Recognition.GrammarBuilder>, <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> , lub <xref:System.Speech.Recognition.Grammar> obiektów.  
  
 Ponadto <xref:System.Speech.Recognition.DictationGrammar> klasy zawiera gramatykę szczególny obsługi modelu konwencjonalne dyktowanie.  
  
 Zobacz [tworzenie gramatyki](http://msdn.microsoft.com/library/dbea278c-21a5-4816-aee7-5fd88ef993dd) w [System mowy przewodnik programowania w programie .NET Framework 4.0](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043) uzyskać więcej informacji i przykładów.  
  
 **Zarządzanie aparatów rozpoznawania mowy**  
  
 Wystąpienia elementu <xref:System.Speech.Recognition.SpeechRecognizer> i <xref:System.Speech.Recognition.SpeechRecognitionEngine> dostarczony wraz z <xref:System.Speech.Recognition.Grammar> obiekty dostarczają podstawowy dostęp do aparatów rozpoznawania mowy, technologii mowy pulpitu Windows.  
  
 Możesz użyć <xref:System.Speech.Recognition.SpeechRecognizer> klasa do tworzenia aplikacji korzystających z technologii rozpoznawania mowy, które są dostarczane przez Windows, które można skonfigurować za pomocą klienta **Panelu sterowania**. Takie aplikacje akceptuje dane wejściowe za pośrednictwem mechanizmu wejściowe audio domyślnej na komputerze.  
  
 Aby uzyskać większą kontrolę nad konfiguracji i typ aparatu rozpoznawania, tworzenie aplikacji za pomocą <xref:System.Speech.Recognition.SpeechRecognitionEngine>, która działa w procesie. Za pomocą <xref:System.Speech.Recognition.SpeechRecognitionEngine> klasy, należy również dynamiczne Wybieranie dane wejściowe z urządzenia, pliki lub strumienie audio.  
  
 Zobacz [zainicjowania i zarządzania nim aparatu rozpoznawania mowy](http://msdn.microsoft.com/library/6eed5b59-1258-4013-8a4c-a1ddabd93ae4) w [System mowy przewodnik programowania w programie .NET Framework 4.0](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043) Aby uzyskać więcej informacji.  
  
 **Odpowiadanie na zdarzenia**  
  
 <xref:System.Speech.Recognition.SpeechRecognizer> i <xref:System.Speech.Recognition.SpeechRecognitionEngine> obiektów generowanie zdarzeń w odpowiedzi na dane wejściowe audio aparatu rozpoznawania mowy. `AudioLevelUpdated`, `AudioSignalProblemOccurred`, `AudioStateChanged` Zdarzenia są wywoływane w odpowiedzi na zmiany w przychodzących sygnałów. `SpeechDetected` Zdarzenie jest zgłaszane w przypadku aparatu rozpoznawania mowy identyfikuje przychodzących audio jako mowy. Generuje aparatu rozpoznawania mowy `SpeechRecognized` zdarzenie, kiedy odpowiada wejście mowy do jednej z jej załadować gramatyki i zgłasza `SpeechRecognitionRejected` podczas rozpoznawania mowy w danych wejściowych nie pasuje do żadnej z jej załadować gramatyki.  
  
 Inne rodzaje zdarzeń `LoadGrammarCompleted` zdarzeń, który wywołuje aparatu rozpoznawania mowy, po załadowaniu gramatyki. <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> Jest dostępna wyłącznie dla <xref:System.Speech.Recognition.SpeechRecognizer> klasy, która wywołuje zdarzenie po zmianie stanu rozpoznawania mowy Windows.  
  
 Możesz zarejestrować otrzymywać powiadomień dotyczących zdarzeń, które wywołuje aparat rozpoznawania mowy i tworzenie programów do obsługi przy użyciu `EventsArgs` klasy skojarzone z każdą z tych zdarzeń do programu zachowanie aplikacji, gdy zostanie wywołane zdarzenie.  
  
 Zobacz [przy użyciu zdarzenia rozpoznawania mowy](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482) w [System mowy przewodnik programowania w programie .NET Framework 4.0](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043) Aby uzyskać więcej informacji.  
  
 ]]></format>
    </remarks>
    <altmember cref="N:System.Speech.AudioFormat" />
    <altmember cref="N:System.Speech.Recognition.SrgsGrammar" />
    <altmember cref="N:System.Speech.Synthesis" />
    <altmember cref="N:System.Speech.Synthesis.TtsEngine" />
  </Docs>
</Namespace>