<Namespace Name="System.Speech.Recognition">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="be08311c812e33ac449fae40c2d2494af9dc7fe5" />
    <Meta Name="ms.sourcegitcommit" Value="df6cf590aa3087f6c7c202712eee781c6a3c8f96" />
    <Meta Name="ms.translationtype" Value="MT" />
    <Meta Name="ms.contentlocale" Value="pl-PL" />
    <Meta Name="ms.lasthandoff" Value="05/10/2018" />
    <Meta Name="ms.locfileid" Value="30746249" />
  </Metadata>
  <Docs>
    <summary>
      <see cref="N:System.Speech.Recognition" /> Przestrzeń nazw zawiera typy technologii Windows Desktop mowy wykonywania rozpoznawania mowy.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Oprogramowanie technologia mowy pulpitu systemu Windows udostępnia podstawowe mowy rozpoznawania infrastruktury digitizes sygnałów akustycznych i odzyskuje słów i elementy mowy z wejście audio.  
  
 Aplikacje używają <xref:System.Speech.Recognition> przestrzeni nazw dostępu i rozszerzenie tej technologii rozpoznawania mowy podstawowe, definiując algorytmów identyfikacji i działające na określone frazy lub wzorce programu word i zarządzając zachowania w czasie wykonywania tego mowy infrastruktura.  
  
 **Utwórz gramatyki**  
  
 Możesz utworzyć gramatyki, które składają się z zestawem reguł lub ograniczenia, aby zdefiniować słów i wyrażeń, które rozpoznają aplikacji jako dane wejściowe łatwy do rozpoznania. Za pomocą konstruktora dla <xref:System.Speech.Recognition.Grammar> klasy, można utworzyć obiekt gramatyki w czasie wykonywania z <xref:System.Speech.Recognition.GrammarBuilder> lub <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> wystąpień, lub z pliku, ciągu lub strumienia, który zawiera definicję gramatyki.  
  
 Przy użyciu <xref:System.Speech.Recognition.GrammarBuilder> i <xref:System.Speech.Recognition.Choices> klasy, można programowo utworzyć gramatyki z niskim celu średnia złożoności, który może służyć do wykonywania rozpoznawania dla wielu typowych scenariuszy. Aby utworzyć gramatyki programowo zgodnych ze standardami [mowy rozpoznawania gramatyki specyfikacji 1.0 (SRGS)](http://go.microsoft.com/fwlink/?LinkId=201761) i wykorzystać elastyczność tworzenia SRGS, użyj typów <xref:System.Speech.Recognition.SrgsGrammar> przestrzeni nazw. Także utworzyć gramatykach SRGS XML format przy użyciu dowolnego tekstu w edytorze i umożliwia utworzenie wyniku <xref:System.Speech.Recognition.GrammarBuilder>, <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> , lub <xref:System.Speech.Recognition.Grammar> obiektów.  
  
 Ponadto <xref:System.Speech.Recognition.DictationGrammar> klasa udostępnia specjalny przypadek gramatyki do obsługi modelu dyktowania z konwencjonalnej.  
  
 Zobacz [utworzyć Gramatyk](http://msdn.microsoft.com/library/dbea278c-21a5-4816-aee7-5fd88ef993dd) w [systemu mowy Programming Guide dla programu .NET Framework 4.0](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043) dodatkowe informacje i przykłady.  
  
 **Zarządzanie aparatów rozpoznawania mowy**  
  
 Wystąpienia <xref:System.Speech.Recognition.SpeechRecognizer> i <xref:System.Speech.Recognition.SpeechRecognitionEngine> dostarczony wraz z <xref:System.Speech.Recognition.Grammar> obiektów podaj podstawowy dostęp do aparatów rozpoznawania mowy technologii mowy pulpitu systemu Windows.  
  
 Można użyć <xref:System.Speech.Recognition.SpeechRecognizer> klasa do tworzenia aplikacji korzystających z technologii rozpoznawania mowy dostarczonymi przez system Windows, które można skonfigurować za pomocą klienta **Panelu sterowania**. Takie aplikacje akceptowanie danych wejściowych za pośrednictwem mechanizmu wejściowego audio domyślnej na komputerze.  
  
 Aby uzyskać większą kontrolę nad konfiguracją i typ aparatu rozpoznawania, tworzenie aplikacji przy użyciu <xref:System.Speech.Recognition.SpeechRecognitionEngine>, które są uruchamiane w procesie. Przy użyciu <xref:System.Speech.Recognition.SpeechRecognitionEngine> klasy, należy również dynamiczne Wybieranie dane wejściowe z urządzeń, plików i strumieni audio.  
  
 Zobacz [zainicjować i zarządzanie nimi aparat rozpoznawania mowy](http://msdn.microsoft.com/library/6eed5b59-1258-4013-8a4c-a1ddabd93ae4) w [systemu mowy Programming Guide dla programu .NET Framework 4.0](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043) Aby uzyskać więcej informacji.  
  
 **Odpowiadanie na zdarzenia**  
  
 <xref:System.Speech.Recognition.SpeechRecognizer> i <xref:System.Speech.Recognition.SpeechRecognitionEngine> obiektów generowanie zdarzeń w odpowiedzi na dane wejściowe audio aparat rozpoznawania mowy. `AudioLevelUpdated`, `AudioSignalProblemOccurred`, `AudioStateChanged` Zdarzenia są generowane w odpowiedzi na zmiany w przychodzącego sygnału. `SpeechDetected` Zdarzenie jest zgłaszane, gdy aparat rozpoznawania mowy określa dźwięku przychodzących jako mowy. Aparat rozpoznawania mowy zgłasza `SpeechRecognized` zdarzenie, gdy dane wejściowe mowy do jednej z jej załadować gramatyki jest zgodny i zgłasza `SpeechRecognitionRejected` podczas wprowadzania mowy nie pasuje do żadnego jej załadować gramatyki.  
  
 Inne rodzaje zdarzeń `LoadGrammarCompleted` zdarzeń, który aparat rozpoznawania mowy powoduje po załadowaniu gramatyki. <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> Jest na wyłączność dla <xref:System.Speech.Recognition.SpeechRecognizer> klasy, która wywołuje zdarzenie po zmianie stanu rozpoznawania mowy.  
  
 Możesz zarejestrować otrzymywać powiadomień dotyczących zdarzeń, które wywołuje aparat rozpoznawania mowy i utworzyć przy użyciu programów obsługi `EventsArgs` klas skojarzonych z każdym z tych zdarzeń programu zachowanie aplikacji, gdy zdarzenie jest wywoływane.  
  
 Zobacz [przy użyciu zdarzenia rozpoznawania mowy](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482) w [systemu mowy Programming Guide dla programu .NET Framework 4.0](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043) Aby uzyskać więcej informacji.  
  
 ]]></format>
    </remarks>
    <altmember cref="N:System.Speech.AudioFormat" />
    <altmember cref="N:System.Speech.Recognition.SrgsGrammar" />
    <altmember cref="N:System.Speech.Synthesis" />
    <altmember cref="N:System.Speech.Synthesis.TtsEngine" />
  </Docs>
</Namespace>