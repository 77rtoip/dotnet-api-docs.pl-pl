<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="ns-System.Speech.Recognition.xml" source-language="en-US" target-language="pl-PL">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-efd8310" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">5a83ea4b-dd12-480b-bfc8-267272ef1864be08311c812e33ac449fae40c2d2494af9dc7fe5.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">be08311c812e33ac449fae40c2d2494af9dc7fe5</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">df6cf590aa3087f6c7c202712eee781c6a3c8f96</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">05/10/2018</xliffext:ms.lasthandoff>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">&lt;see cref="N:System.Speech.Recognition" /&gt;</ph> namespace contains Windows Desktop Speech technology types for implementing speech recognition.</source>
          <target state="translated"><ph id="ph1">&lt;see cref="N:System.Speech.Recognition" /&gt;</ph> Przestrzeń nazw zawiera typy technologii Windows Desktop mowy wykonywania rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT">
          <source>The Windows Desktop Speech Technology software offers a basic speech recognition infrastructure that digitizes acoustical signals, and recovers words and speech elements from audio input.</source>
          <target state="translated">Oprogramowanie technologia mowy pulpitu systemu Windows udostępnia podstawowe mowy rozpoznawania infrastruktury digitizes sygnałów akustycznych i odzyskuje słów i elementy mowy z wejście audio.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications use the <ph id="ph1">&lt;xref:System.Speech.Recognition&gt;</ph> namespace to access and extend this basic speech recognition technology by defining algorithms for identifying and acting on specific phrases or word patterns, and by managing the runtime behavior of this speech infrastructure.</source>
          <target state="translated">Aplikacje używają <ph id="ph1">&lt;xref:System.Speech.Recognition&gt;</ph> przestrzeni nazw dostępu i rozszerzenie tej technologii rozpoznawania mowy podstawowe, definiując algorytmów identyfikacji i działające na określone frazy lub wzorce programu word i zarządzając zachowania w czasie wykonywania tego mowy infrastruktura.</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Create Grammars<ept id="p1">**</ept></source>
          <target state="translated"><bpt id="p1">**</bpt>Utwórz gramatyki<ept id="p1">**</ept></target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT">
          <source>You create grammars, which consist of a set of rules or constraints, to define words and phrases that your application will recognize as meaningful input.</source>
          <target state="translated">Możesz utworzyć gramatyki, które składają się z zestawem reguł lub ograniczenia, aby zdefiniować słów i wyrażeń, które rozpoznają aplikacji jako dane wejściowe łatwy do rozpoznania.</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using a constructor for the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> class, you can create a grammar object at runtime from <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> or <ph id="ph3">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> instances, or from a file, a string, or a stream that contains a definition of a grammar.</source>
          <target state="translated">Za pomocą konstruktora dla <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> klasy, można utworzyć obiekt gramatyki w czasie wykonywania z <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> lub <ph id="ph3">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> wystąpień, lub z pliku, ciągu lub strumienia, który zawiera definicję gramatyki.</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using the <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> classes, you can programmatically create grammars of low to medium complexity that can be used to perform recognition for many common scenarios.</source>
          <target state="translated">Przy użyciu <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> klasy, można programowo utworzyć gramatyki z niskim celu średnia złożoności, który może służyć do wykonywania rozpoznawania dla wielu typowych scenariuszy.</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT">
          <source>To create grammars programmatically that conform to the <bpt id="p1">[</bpt>Speech Recognition Grammar Specification 1.0 (SRGS)<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=201761)</ept> and take advantage of the authoring flexibility of SRGS, use the types of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SrgsGrammar&gt;</ph> namespace.</source>
          <target state="translated">Aby utworzyć gramatyki programowo zgodnych ze standardami <bpt id="p1">[</bpt>mowy rozpoznawania gramatyki specyfikacji 1.0 (SRGS)<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=201761)</ept> i wykorzystać elastyczność tworzenia SRGS, użyj typów <ph id="ph1">&lt;xref:System.Speech.Recognition.SrgsGrammar&gt;</ph> przestrzeni nazw.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can also create XML-format SRGS grammars using any text editor and use the result to create <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> , or <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Także utworzyć gramatykach SRGS XML format przy użyciu dowolnego tekstu w edytorze i umożliwia utworzenie wyniku <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> , lub <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT">
          <source>In addition, the <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> class provides a special-case grammar to support a conventional dictation model.</source>
          <target state="translated">Ponadto <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> klasa udostępnia specjalny przypadek gramatyki do obsługi modelu dyktowania z konwencjonalnej.</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Create Grammars<ept id="p1">](http://msdn.microsoft.com/library/dbea278c-21a5-4816-aee7-5fd88ef993dd)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information and examples.</source>
          <target state="translated">Zobacz <bpt id="p1">[</bpt>utworzyć Gramatyk<ept id="p1">](http://msdn.microsoft.com/library/dbea278c-21a5-4816-aee7-5fd88ef993dd)</ept> w <bpt id="p2">[</bpt>systemu mowy Programming Guide dla programu .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> dodatkowe informacje i przykłady.</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Manage Speech Recognition Engines<ept id="p1">**</ept></source>
          <target state="translated"><bpt id="p1">**</bpt>Zarządzanie aparatów rozpoznawania mowy<ept id="p1">**</ept></target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT">
          <source>Instances of <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> supplied with <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects provide the primary access to the speech recognition engines of the Windows Desktop Speech Technology.</source>
          <target state="translated">Wystąpienia <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> dostarczony wraz z <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> obiektów podaj podstawowy dostęp do aparatów rozpoznawania mowy technologii mowy pulpitu systemu Windows.</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class to create client applications that use the speech recognition technology provided by Windows, which you can configure through the <bpt id="p1">**</bpt>Control Panel<ept id="p1">**</ept>.</source>
          <target state="translated">Można użyć <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> klasa do tworzenia aplikacji korzystających z technologii rozpoznawania mowy dostarczonymi przez system Windows, które można skonfigurować za pomocą klienta <bpt id="p1">**</bpt>Panelu sterowania<ept id="p1">**</ept>.</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT">
          <source>Such applications accept input through a computer's default audio input mechanism.</source>
          <target state="translated">Takie aplikacje akceptowanie danych wejściowych za pośrednictwem mechanizmu wejściowego audio domyślnej na komputerze.</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more control over the configuration and type of recognition engine, build an application using <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, which runs in-process.</source>
          <target state="translated">Aby uzyskać większą kontrolę nad konfiguracją i typ aparatu rozpoznawania, tworzenie aplikacji przy użyciu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, które są uruchamiane w procesie.</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> class, you can also dynamically select audio input from devices, files, or streams.</source>
          <target state="translated">Przy użyciu <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> klasy, należy również dynamiczne Wybieranie dane wejściowe z urządzeń, plików i strumieni audio.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Initialize and Manage a Speech Recognition Engine<ept id="p1">](http://msdn.microsoft.com/library/6eed5b59-1258-4013-8a4c-a1ddabd93ae4)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information.</source>
          <target state="translated">Zobacz <bpt id="p1">[</bpt>zainicjować i zarządzanie nimi aparat rozpoznawania mowy<ept id="p1">](http://msdn.microsoft.com/library/6eed5b59-1258-4013-8a4c-a1ddabd93ae4)</ept> w <bpt id="p2">[</bpt>systemu mowy Programming Guide dla programu .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> Aby uzyskać więcej informacji.</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Respond to Events<ept id="p1">**</ept></source>
          <target state="translated"><bpt id="p1">**</bpt>Odpowiadanie na zdarzenia<ept id="p1">**</ept></target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> objects generate events in response to audio input to the speech recognition engine.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> i <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> obiektów generowanie zdarzeń w odpowiedzi na dane wejściowe audio aparat rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`AudioLevelUpdated`</ph>, <ph id="ph2">`AudioSignalProblemOccurred`</ph>, <ph id="ph3">`AudioStateChanged`</ph> events are raised in response to changes in the incoming signal.</source>
          <target state="translated"><ph id="ph1">`AudioLevelUpdated`</ph>, <ph id="ph2">`AudioSignalProblemOccurred`</ph>, <ph id="ph3">`AudioStateChanged`</ph> Zdarzenia są generowane w odpowiedzi na zmiany w przychodzącego sygnału.</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`SpeechDetected`</ph> event is raised when the speech recognition engine identifies incoming audio as speech.</source>
          <target state="translated"><ph id="ph1">`SpeechDetected`</ph> Zdarzenie jest zgłaszane, gdy aparat rozpoznawania mowy określa dźwięku przychodzących jako mowy.</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognition engine raises the <ph id="ph1">`SpeechRecognized`</ph> event when it matches speech input to one of its loaded grammars, and raises the <ph id="ph2">`SpeechRecognitionRejected`</ph> when speech input does not match any of its loaded grammars.</source>
          <target state="translated">Aparat rozpoznawania mowy zgłasza <ph id="ph1">`SpeechRecognized`</ph> zdarzenie, gdy dane wejściowe mowy do jednej z jej załadować gramatyki jest zgodny i zgłasza <ph id="ph2">`SpeechRecognitionRejected`</ph> podczas wprowadzania mowy nie pasuje do żadnego jej załadować gramatyki.</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT">
          <source>Other types of events include the <ph id="ph1">`LoadGrammarCompleted`</ph> event which a speech recognition engine raises when it has loaded a grammar.</source>
          <target state="translated">Inne rodzaje zdarzeń <ph id="ph1">`LoadGrammarCompleted`</ph> zdarzeń, który aparat rozpoznawania mowy powoduje po załadowaniu gramatyki.</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> is exclusive to the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class, which raises the event when the state of Windows Speech Recognition changes.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> Jest na wyłączność dla <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> klasy, która wywołuje zdarzenie po zmianie stanu rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can register to be notified for events that the speech recognition engine raises and create handlers using the <ph id="ph1">`EventsArgs`</ph> classes associated with each of these events to program your application's behavior when an event is raised.</source>
          <target state="translated">Możesz zarejestrować otrzymywać powiadomień dotyczących zdarzeń, które wywołuje aparat rozpoznawania mowy i utworzyć przy użyciu programów obsługi <ph id="ph1">`EventsArgs`</ph> klas skojarzonych z każdym z tych zdarzeń programu zachowanie aplikacji, gdy zdarzenie jest wywoływane.</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Using Speech Recognition Events<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information.</source>
          <target state="translated">Zobacz <bpt id="p1">[</bpt>przy użyciu zdarzenia rozpoznawania mowy<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept> w <bpt id="p2">[</bpt>systemu mowy Programming Guide dla programu .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> Aby uzyskać więcej informacji.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>